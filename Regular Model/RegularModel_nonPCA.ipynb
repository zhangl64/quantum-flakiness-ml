{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea5b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents (balance combination): 45\n",
      "Number of non-flaky documents (balance combination): 45\n",
      "Total number of documents (balance combination): 90\n",
      "Number of flaky documents (imbalance combination): 45\n",
      "Number of non-flaky documents (imbalance combination): 243\n",
      "Total number of documents (imbalance combination): 288\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Data Extraction and Vectorization\n",
    "\n",
    "# Parameters setup\n",
    "flakyZip = \"Dataset/flaky_files.zip\"\n",
    "nonFlakyZip = \"Dataset/reduced_nonflaky_files.zip\"\n",
    "imbalanceNonFlakyZip = \"Dataset/imbalance_nonflaky_files.zip\"\n",
    "\n",
    "# Create directories\n",
    "outDirbalance = \"results/balance_flaky_nonflaky/\"\n",
    "outDirimbalance = \"results/imbalance_nonflaky/\"\n",
    "os.makedirs(outDirbalance, exist_ok=True)\n",
    "os.makedirs(outDirimbalance, exist_ok=True)\n",
    "\n",
    "extractDirbalance = \"extracted/balance_flaky_nonflaky/\"\n",
    "extractDirimbalance = \"extracted/imbalance_nonflaky/\"\n",
    "os.makedirs(extractDirbalance, exist_ok=True)\n",
    "os.makedirs(extractDirimbalance, exist_ok=True)\n",
    "\n",
    "# Extract and read data once for balance combination\n",
    "flakyDirbalance = os.path.join(extractDirbalance, 'flaky')\n",
    "nonFlakyDirbalance = os.path.join(extractDirbalance, 'nonFlaky')\n",
    "os.makedirs(flakyDirbalance, exist_ok=True)\n",
    "os.makedirs(nonFlakyDirbalance, exist_ok=True)\n",
    "\n",
    "extract_zip(flakyZip, flakyDirbalance)\n",
    "extract_zip(nonFlakyZip, nonFlakyDirbalance)\n",
    "\n",
    "dataPointsFlakybalance = getDataPoints(flakyDirbalance)\n",
    "dataPointsNonFlakybalance = getDataPoints(nonFlakyDirbalance)\n",
    "dataPointsbalance = dataPointsFlakybalance + dataPointsNonFlakybalance\n",
    "\n",
    "# Print the number of datasets for balance combination\n",
    "print(f\"Number of flaky documents (balance combination): {len(dataPointsFlakybalance)}\")\n",
    "print(f\"Number of non-flaky documents (balance combination): {len(dataPointsNonFlakybalance)}\")\n",
    "print(f\"Total number of documents (balance combination): {len(dataPointsbalance)}\")\n",
    "\n",
    "dataLabelsListbalance = np.array([1]*len(dataPointsFlakybalance) + [0]*len(dataPointsNonFlakybalance))\n",
    "\n",
    "# Vectorize data once\n",
    "Z_balance = flastVectorization(dataPointsbalance, dim=100, eps=0.3)\n",
    "\n",
    "# Extract and read data once for imbalance non-flaky combination\n",
    "flakyDirimbalance = os.path.join(extractDirimbalance, 'flaky')\n",
    "nonFlakyDirimbalance = os.path.join(extractDirimbalance, 'nonFlaky')\n",
    "os.makedirs(flakyDirimbalance, exist_ok=True)\n",
    "os.makedirs(nonFlakyDirimbalance, exist_ok=True)\n",
    "\n",
    "extract_zip(flakyZip, flakyDirimbalance)\n",
    "extract_zip(imbalanceNonFlakyZip, nonFlakyDirimbalance)\n",
    "\n",
    "dataPointsFlakyimbalance = getDataPoints(flakyDirimbalance)\n",
    "dataPointsNonFlakyimbalance = getDataPoints(nonFlakyDirimbalance)\n",
    "dataPointsimbalance = dataPointsFlakyimbalance + dataPointsNonFlakyimbalance\n",
    "\n",
    "# Print the number of datasets for imbalance combination\n",
    "print(f\"Number of flaky documents (imbalance combination): {len(dataPointsFlakyimbalance)}\")\n",
    "print(f\"Number of non-flaky documents (imbalance combination): {len(dataPointsNonFlakyimbalance)}\")\n",
    "print(f\"Total number of documents (imbalance combination): {len(dataPointsimbalance)}\")\n",
    "\n",
    "dataLabelsListimbalance = np.array([1]*len(dataPointsFlakyimbalance) + [0]*len(dataPointsNonFlakyimbalance))\n",
    "\n",
    "Z_imbalance = flastVectorization(dataPointsimbalance, dim=100, eps=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e4252c",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e44d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Random Forest analysis for flaky vs smaller non-flaky files (balance combination)...\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best F1 Score: 0.7720743034055728\n",
      "Random Forest analysis completed for 5-folds. Results saved to: balance-params-rf-5-folds.csv\n",
      "\n",
      "Best results for Random Forest 5-fold on balance combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best F1 Score: 0.7720743034055728\n",
      "\n",
      "Starting Random Forest analysis for flaky vs imbalance non-flaky files (imbalance combination)...\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best F1 Score: 0.38461538461538464\n",
      "Random Forest analysis completed for 5-folds. Results saved to: imbalance-params-rf-5-folds.csv\n",
      "\n",
      "Best results for Random Forest 5-fold on imbalance combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best F1 Score: 0.38461538461538464\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "###############################################################################\n",
    "# Random Forest with GridSearchCV and Multiple Scoring Metrics including MCC\n",
    "\n",
    "\n",
    "\n",
    "def runRandomForest(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "    \n",
    "    # Define Random Forest model\n",
    "    rf_model = RandomForestClassifier()\n",
    "    \n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],  # Number of trees\n",
    "        'max_depth': [10, 20,30,50],  # Maximum depth of each tree\n",
    "        'min_samples_split': [5, 10],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [2, 5],  # Minimum number of samples required to be at a leaf node\n",
    "        \"criterion\": [\"gini\", \"entropy\"],  # Function to measure the quality of a split\n",
    "    }\n",
    "\n",
    "    # Custom scoring functions including MCC\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),  \n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': make_scorer(matthews_corrcoef)\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(rf_model, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for F1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-rf-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"n_estimators,max_depth,min_samples_split,min_samples_leaf,criterion,accuracy,precision,recall,f1,mcc,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            mcc = grid_search.cv_results_['mean_test_mcc'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['n_estimators']},{param['max_depth']},{param['min_samples_split']},{param['min_samples_leaf']},{param['criterion']},{accuracy},{precision},{recall},{f1},{mcc},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"Random Forest analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run Random Forest on balance combination\n",
    "print(\"\\nStarting Random Forest analysis for flaky vs smaller non-flaky files (balance combination)...\")\n",
    "best_params_5folds_balance, best_score_5folds_balance = runRandomForest(Z_balance, dataLabelsListbalance, outDirbalance, 5, \"balance\")\n",
    "\n",
    "print(\"\\nBest results for Random Forest 5-fold on balance combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_balance}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_balance}\")\n",
    "\n",
    "\n",
    "# Run Random Forest on imbalance non-flaky combination\n",
    "print(\"\\nStarting Random Forest analysis for flaky vs imbalance non-flaky files (imbalance combination)...\")\n",
    "best_params_5folds_imbalance, best_score_5folds_imbalance = runRandomForest(Z_imbalance, dataLabelsListimbalance, outDirimbalance, 5, \"imbalance\")\n",
    "\n",
    "print(\"\\nBest results for Random Forest 5-fold on imbalance combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_imbalance}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_imbalance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942cbd9",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f9cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (balance combination)...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "Best F1 Score: 0.7907953484424072\n",
      "Decision Tree analysis completed for 5-folds. Results saved to: balance-params-dt-5-folds.csv\n",
      "\n",
      "Best results for Decision Tree 5-fold on balance combination:\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "Best F1 Score: 0.7907953484424072\n",
      "\n",
      "Starting Decision Tree analysis for flaky vs imbalance non-flaky files (imbalance combination)...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Best F1 Score: 0.6054621848739495\n",
      "Decision Tree analysis completed for 5-folds. Results saved to: imbalance-params-dt-5-folds.csv\n",
      "\n",
      "Best results for Decision Tree 5-fold on imbalance combination:\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Best F1 Score: 0.6054621848739495\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with GridSearchCV and Multiple Scoring Metrics including MCC\n",
    "\n",
    "def mcc_scorer(estimator, X, y_true):\n",
    "    \"\"\"\n",
    "    Custom scorer function for Matthews Correlation Coefficient.\n",
    "    \"\"\"\n",
    "    y_pred = estimator.predict(X)\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "def runDecisionTree(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define Decision Tree model\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [ 10,20,30],\n",
    "        'min_samples_split': [2, 5, 10],  \n",
    "        'min_samples_leaf': [1, 2, 5, 10],  \n",
    "        'max_features': [None, 'sqrt', 'log2'], \n",
    "    }\n",
    "\n",
    "    # Custom scoring functions including MCC\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),  \n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': mcc_scorer  # Use the custom MCC scorer\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(\n",
    "        dt_model, \n",
    "        param_grid, \n",
    "        cv=skf, \n",
    "        scoring=scoring, \n",
    "        refit='f1', \n",
    "        verbose=1, \n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"criterion,max_depth,min_samples_split,min_samples_leaf,max_features,accuracy,precision,recall,f1,mcc,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            mcc = grid_search.cv_results_['mean_test_mcc'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['criterion']},{param['max_depth']},{param['min_samples_split']},{param['min_samples_leaf']},{param['max_features']},{accuracy},{precision},{recall},{f1},{mcc},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run Decision Tree on balance combination\n",
    "print(\"\\nStarting Decision Tree analysis for flaky vs smaller non-flaky files (balance combination)...\")\n",
    "best_params_5folds_balance, best_score_5folds_balance = runDecisionTree(\n",
    "    Z_balance, dataLabelsListbalance, outDirbalance, 5, \"balance\"\n",
    ")\n",
    "\n",
    "print(\"\\nBest results for Decision Tree 5-fold on balance combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_balance}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_balance}\")\n",
    "\n",
    "# Run Decision Tree on imbalance non-flaky combination\n",
    "print(\"\\nStarting Decision Tree analysis for flaky vs imbalance non-flaky files (imbalance combination)...\")\n",
    "best_params_5folds_imbalance, best_score_5folds_imbalance = runDecisionTree(\n",
    "    Z_imbalance, dataLabelsListimbalance, outDirimbalance, 5, \"imbalance\"\n",
    ")\n",
    "\n",
    "print(\"\\nBest results for Decision Tree 5-fold on imbalance combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_imbalance}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_imbalance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40df7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc05003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
