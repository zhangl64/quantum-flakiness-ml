{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84acd571",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb2d4796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 45\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 299\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty or invalid file skipped: {file_path}\")\n",
    "\n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "\n",
    "    return dataPointsList\n",
    "\n",
    "###############################################################################\n",
    "# Data Extraction and Vectorization\n",
    "\n",
    "# Parameters setup\n",
    "flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "nonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "outDir = \"smote-results\"\n",
    "os.makedirs(outDir, exist_ok=True)\n",
    "extractDir = \"smote-extracted\"\n",
    "os.makedirs(extractDir, exist_ok=True)\n",
    "\n",
    "# Extract the zip files\n",
    "flakyDir = os.path.join(extractDir, 'flaky')\n",
    "nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "os.makedirs(flakyDir, exist_ok=True)\n",
    "os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "\n",
    "extract_zip(flakyZip, flakyDir)\n",
    "extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "dataPointsFlaky = getDataPoints(flakyDir)\n",
    "dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "\n",
    "if len(dataPoints) == 0:\n",
    "    raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "# Create labels: 1 for flaky, 0 for non-flaky\n",
    "dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf94de6",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f791afe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KNN analysis with SMOTE for 3-fold cross-validation...\n",
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "Best Parameters with SMOTE: {'knn__metric': 'cosine', 'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n",
      "Best F1 Score from cross-validation: 0.5264550264550265\n",
      "Per-fold metrics saved to: smote-results\\knn-smote-fold-results-3-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.4506172839506173\n",
      "Final Recall: 0.6444444444444444\n",
      "Final Accuracy: 0.822962962962963\n",
      "Final F1 Score: 0.5264550264550265\n",
      "KNN analysis completed for 3-folds with SMOTE. Results saved to: smote-results\\knn-results-3-folds.csv\n",
      "\n",
      "Starting KNN analysis with SMOTE for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "Best Parameters with SMOTE: {'knn__metric': 'cosine', 'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n",
      "Best F1 Score from cross-validation: 0.5605882352941176\n",
      "Per-fold metrics saved to: smote-results\\knn-smote-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.5089393939393939\n",
      "Final Recall: 0.6444444444444444\n",
      "Final Accuracy: 0.8496610169491525\n",
      "Final F1 Score: 0.5605882352941176\n",
      "KNN analysis completed for 5-folds with SMOTE. Results saved to: smote-results\\knn-results-5-folds.csv\n",
      "\n",
      "Best results for KNN with SMOTE 3-fold cross-validation:\n",
      "Best Parameters: {'knn__metric': 'cosine', 'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n",
      "Best F1 Score: 0.5264550264550265\n",
      "\n",
      "Best results for KNN with SMOTE 5-fold cross-validation:\n",
      "Best Parameters: {'knn__metric': 'cosine', 'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n",
      "Best F1 Score: 0.5605882352941176\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "def runKNNWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    # Start timing for preparation (if needed)\n",
    "    # v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': 'f1'\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with CountVectorizer, SMOTE, and KNN\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Include vectorizer in pipeline\n",
    "        ('smote', SMOTE(random_state=42)),                 # SMOTE for oversampling\n",
    "        ('knn', KNeighborsClassifier())                    # KNN classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'knn__n_neighbors': [3, 5, 7, 9, 11, 15, 20],      # Number of neighbors for KNN\n",
    "        'knn__weights': ['uniform', 'distance'],           # Uniform or distance-based weighting\n",
    "        'knn__metric': ['euclidean', 'cosine']             # Distance metrics\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=skf, scoring=scoring,\n",
    "        refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE: {best_params}\")\n",
    "    print(f\"Best F1 Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combinations\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'n_neighbors': results['params'][idx].get('knn__n_neighbors'),\n",
    "            'weights': results['params'][idx].get('knn__weights'),\n",
    "            'metric': results['params'][idx].get('knn__metric'),\n",
    "            'accuracy': results['mean_test_accuracy'][idx],\n",
    "            'precision': results['mean_test_precision'][idx],\n",
    "            'recall': results['mean_test_recall'][idx],\n",
    "            'f1': results['mean_test_f1'][idx],\n",
    "            # Remove or adjust 'preparationTime' as 'vecTime' is undefined here\n",
    "            # 'preparationTime': vecTime / len(dataLabelsList)\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile = os.path.join(outDir, f\"knn-smote-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    outFile = os.path.join(outDir, f\"knn-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1}\\n\")\n",
    "\n",
    "    print(f\"KNN analysis completed for {n_splits}-folds with SMOTE. Results saved to: {outFile}\")\n",
    "\n",
    "    return best_params, final_f1\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for Both 3-Fold and 5-Fold\n",
    "\n",
    "# Ensure 'outDir' is defined\n",
    "outDir = \"smote-results\"\n",
    "os.makedirs(outDir, exist_ok=True)\n",
    "\n",
    "# Run KNN with SMOTE using 3-fold cross-validation\n",
    "print(\"Starting KNN analysis with SMOTE for 3-fold cross-validation...\")\n",
    "best_params_3folds, best_f1_3folds = runKNNWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=3)\n",
    "\n",
    "# Run KNN with SMOTE using 5-fold cross-validation\n",
    "print(\"\\nStarting KNN analysis with SMOTE for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds = runKNNWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for KNN with SMOTE 3-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_3folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_3folds}\")\n",
    "\n",
    "print(\"\\nBest results for KNN with SMOTE 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c826fa",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c857480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SVM analysis with SMOTE for 3-fold cross-validation...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters with SMOTE: {'svm__C': 0.01, 'svm__kernel': 'linear'}\n",
      "Best F1 Score from cross-validation: 0.6498745819397994\n",
      "Per-fold metrics saved to: smote-results\\svm-smote-fold-results-3-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.7473262032085563\n",
      "Final Recall: 0.6\n",
      "Final Accuracy: 0.9096296296296296\n",
      "Final F1 Score: 0.6498745819397994\n",
      "SVM analysis completed for 3-folds with SMOTE. Results saved to: smote-results\\svm-results-3-folds.csv\n",
      "\n",
      "Starting SVM analysis with SMOTE for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\haha9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters with SMOTE: {'svm__C': 0.1, 'svm__kernel': 'linear'}\n",
      "Best F1 Score from cross-validation: 0.6234188034188035\n",
      "Per-fold metrics saved to: smote-results\\svm-smote-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.7247474747474747\n",
      "Final Recall: 0.5777777777777777\n",
      "Final Accuracy: 0.9029378531073448\n",
      "Final F1 Score: 0.6234188034188035\n",
      "SVM analysis completed for 5-folds with SMOTE. Results saved to: smote-results\\svm-results-5-folds.csv\n",
      "\n",
      "Best results for SVM with SMOTE 3-fold cross-validation:\n",
      "Best Parameters: {'svm__C': 0.01, 'svm__kernel': 'linear'}\n",
      "Best F1 Score: 0.6498745819397994\n",
      "\n",
      "Best results for SVM with SMOTE 5-fold cross-validation:\n",
      "Best Parameters: {'svm__C': 0.1, 'svm__kernel': 'linear'}\n",
      "Best F1 Score: 0.6234188034188035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "def runSVMWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': 'f1'\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with SMOTE and SVM \n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Include vectorizer in pipeline\n",
    "        ('smote', SMOTE(random_state=42)),    # SMOTE for oversampling\n",
    "        ('svm', SVC(probability=True))        # SVM classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'svm__C': [0.01, 0.1, 1.0, 10.0, 100.0],    # Regularization parameter\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly', 'sigmoid']   # Kernel types\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE: {best_params}\")\n",
    "    print(f\"Best F1 Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combinations\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'C': results['params'][idx].get('svm__C'),\n",
    "            'kernel': results['params'][idx].get('svm__kernel'),\n",
    "            'accuracy': results['mean_test_accuracy'][idx],\n",
    "            'precision': results['mean_test_precision'][idx],\n",
    "            'recall': results['mean_test_recall'][idx],\n",
    "            'f1': results['mean_test_f1'][idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile = os.path.join(outDir, f\"svm-smote-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    outFile = os.path.join(outDir, f\"svm-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1}\\n\")\n",
    "\n",
    "    print(f\"SVM analysis completed for {n_splits}-folds with SMOTE. Results saved to: {outFile}\")\n",
    "\n",
    "    return best_params, final_f1\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for Both 3-Fold and 5-Fold\n",
    "\n",
    "# Run SVM with SMOTE using 3-fold cross-validation\n",
    "print(\"Starting SVM analysis with SMOTE for 3-fold cross-validation...\")\n",
    "best_params_3folds, best_f1_3folds = runSVMWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=3)\n",
    "\n",
    "# Run SVM with SMOTE using 5-fold cross-validation\n",
    "print(\"\\nStarting SVM analysis with SMOTE for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds = runSVMWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM with SMOTE 3-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_3folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_3folds}\")\n",
    "\n",
    "print(\"\\nBest results for SVM with SMOTE 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9fd5f4",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e032a4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Naive Bayes analysis with SMOTE for 3-fold cross-validation...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Parameters with SMOTE: {'nb__alpha': 1.0}\n",
      "Best F1 Score from cross-validation: 0.6524712002972873\n",
      "Per-fold metrics saved to: smote-results\\nb-smote-fold-results-3-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.7785353535353535\n",
      "Final Recall: 0.5777777777777778\n",
      "Final Accuracy: 0.9097306397306397\n",
      "Final F1 Score: 0.6524712002972873\n",
      "Naive Bayes analysis completed for 3-folds with SMOTE. Results saved to: smote-results\\nb-results-3-folds.csv\n",
      "\n",
      "Starting Naive Bayes analysis with SMOTE for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters with SMOTE: {'nb__alpha': 0.001}\n",
      "Best F1 Score from cross-validation: 0.6589043309631546\n",
      "Per-fold metrics saved to: smote-results\\nb-smote-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.795\n",
      "Final Recall: 0.5777777777777777\n",
      "Final Accuracy: 0.9163841807909605\n",
      "Final F1 Score: 0.6589043309631546\n",
      "Naive Bayes analysis completed for 5-folds with SMOTE. Results saved to: smote-results\\nb-results-5-folds.csv\n",
      "\n",
      "Best results for Naive Bayes with SMOTE 3-fold cross-validation:\n",
      "Best Parameters: {'nb__alpha': 1.0}\n",
      "Best F1 Score: 0.6524712002972873\n",
      "\n",
      "Best results for Naive Bayes with SMOTE 5-fold cross-validation:\n",
      "Best Parameters: {'nb__alpha': 0.001}\n",
      "Best F1 Score: 0.6589043309631546\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "def runNBWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': 'f1'\n",
    "    }\n",
    "\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Include vectorizer in pipeline\n",
    "        ('smote', SMOTE(random_state=42)),    # SMOTE for oversampling\n",
    "        ('nb', MultinomialNB())               # Naive Bayes classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'nb__alpha': [0.001, 0.01, 0.1, 1.0, 10.0]   # Smoothing parameter for Naive Bayes\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE: {best_params}\")\n",
    "    print(f\"Best F1 Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combinations\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'alpha': results['params'][idx].get('nb__alpha'),\n",
    "            'accuracy': results['mean_test_accuracy'][idx],\n",
    "            'precision': results['mean_test_precision'][idx],\n",
    "            'recall': results['mean_test_recall'][idx],\n",
    "            'f1': results['mean_test_f1'][idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile = os.path.join(outDir, f\"nb-smote-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    outFile = os.path.join(outDir, f\"nb-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1}\\n\")\n",
    "\n",
    "    print(f\"Naive Bayes analysis completed for {n_splits}-folds with SMOTE. Results saved to: {outFile}\")\n",
    "\n",
    "    return best_params, final_f1\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for Both 3-Fold and 5-Fold\n",
    "\n",
    "# Run Naive Bayes with SMOTE using 3-fold cross-validation\n",
    "print(\"Starting Naive Bayes analysis with SMOTE for 3-fold cross-validation...\")\n",
    "best_params_3folds, best_f1_3folds = runNBWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=3)\n",
    "\n",
    "# Run Naive Bayes with SMOTE using 5-fold cross-validation\n",
    "print(\"\\nStarting Naive Bayes analysis with SMOTE for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds = runNBWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Naive Bayes with SMOTE 3-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_3folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_3folds}\")\n",
    "\n",
    "print(\"\\nBest results for Naive Bayes with SMOTE 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6bbf78",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb569e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting XGBoost analysis with SMOTE for 3-fold cross-validation...\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "Best Parameters with SMOTE: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 300}\n",
      "Best F1 Score from cross-validation: 0.884802043422733\n",
      "Per-fold metrics saved to: smote-results\\xgb-smote-fold-results-3-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 1.0\n",
      "Final Recall: 0.8000000000000002\n",
      "Final Accuracy: 0.9698989898989899\n",
      "Final F1 Score: 0.884802043422733\n",
      "XGBoost analysis completed for 3-folds with SMOTE. Results saved to: smote-results\\xgb-results-3-folds.csv\n",
      "\n",
      "Starting XGBoost analysis with SMOTE for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best Parameters with SMOTE: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 7, 'xgb__n_estimators': 300}\n",
      "Best F1 Score from cross-validation: 0.86609243697479\n",
      "Per-fold metrics saved to: smote-results\\xgb-smote-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 1.0\n",
      "Final Recall: 0.7777777777777778\n",
      "Final Accuracy: 0.9664971751412429\n",
      "Final F1 Score: 0.86609243697479\n",
      "XGBoost analysis completed for 5-folds with SMOTE. Results saved to: smote-results\\xgb-results-5-folds.csv\n",
      "\n",
      "Best results for XGBoost with SMOTE 3-fold cross-validation:\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 300}\n",
      "Best F1 Score: 0.884802043422733\n",
      "\n",
      "Best results for XGBoost with SMOTE 5-fold cross-validation:\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 7, 'xgb__n_estimators': 300}\n",
      "Best F1 Score: 0.86609243697479\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "def runXGBWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': 'f1'\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with SMOTE and XGBoost (CountVectorizer is removed as data is already vectorized)\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Include vectorizer in pipeline\n",
    "        ('smote', SMOTE(random_state=42)),    # SMOTE for oversampling\n",
    "        ('xgb', XGBClassifier(eval_metric='logloss', random_state=42))  # XGBoost classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'xgb__n_estimators': [100, 150, 200, 300],   # Number of boosting rounds\n",
    "        'xgb__max_depth': [3, 5, 7, 10],             # Maximum depth of a tree\n",
    "        'xgb__learning_rate': [0.01, 0.1, 0.3, 0.5], # Learning rate\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE: {best_params}\")\n",
    "    print(f\"Best F1 Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combination\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'n_estimators': results['params'][idx].get('xgb__n_estimators'),\n",
    "            'max_depth': results['params'][idx].get('xgb__max_depth'),\n",
    "            'learning_rate': results['params'][idx].get('xgb__learning_rate'),\n",
    "            'accuracy': results['mean_test_accuracy'][idx],\n",
    "            'precision': results['mean_test_precision'][idx],\n",
    "            'recall': results['mean_test_recall'][idx],\n",
    "            'f1': results['mean_test_f1'][idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile = os.path.join(outDir, f\"xgb-smote-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    outFile = os.path.join(outDir, f\"xgb-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1}\\n\")\n",
    "\n",
    "    print(f\"XGBoost analysis completed for {n_splits}-folds with SMOTE. Results saved to: {outFile}\")\n",
    "\n",
    "    return best_params, final_f1\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for Both 3-Fold and 5-Fold\n",
    "\n",
    "# Run XGBoost with SMOTE using 3-fold cross-validation\n",
    "print(\"Starting XGBoost analysis with SMOTE for 3-fold cross-validation...\")\n",
    "best_params_3folds, best_f1_3folds = runXGBWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=3)\n",
    "\n",
    "# Run XGBoost with SMOTE using 5-fold cross-validation\n",
    "print(\"\\nStarting XGBoost analysis with SMOTE for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds = runXGBWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for XGBoost with SMOTE 3-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_3folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_3folds}\")\n",
    "\n",
    "print(\"\\nBest results for XGBoost with SMOTE 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb851b8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd465761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Random Forest analysis with SMOTE for 3-fold cross-validation...\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best Parameters with SMOTE: {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "Best F1 Score from cross-validation: 0.8099616858237547\n",
      "Per-fold metrics saved to: smote-results\\rf-smote-fold-results-3-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.8206349206349207\n",
      "Final Recall: 0.7999999999999999\n",
      "Final Accuracy: 0.943063973063973\n",
      "Final F1 Score: 0.8099616858237547\n",
      "Random Forest analysis completed for 3-folds with SMOTE. Results saved to: smote-results\\rf-results-3-folds.csv\n",
      "\n",
      "Starting Random Forest analysis with SMOTE for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters with SMOTE: {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}\n",
      "Best F1 Score from cross-validation: 0.8258169934640522\n",
      "Per-fold metrics saved to: smote-results\\rf-smote-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.8575396825396824\n",
      "Final Recall: 0.7999999999999999\n",
      "Final Accuracy: 0.9497740112994351\n",
      "Final F1 Score: 0.8258169934640522\n",
      "Random Forest analysis completed for 5-folds with SMOTE. Results saved to: smote-results\\rf-results-5-folds.csv\n",
      "\n",
      "Best results for Random Forest with SMOTE 3-fold cross-validation:\n",
      "Best Parameters: {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "Best F1 Score: 0.8099616858237547\n",
      "\n",
      "Best results for Random Forest with SMOTE 5-fold cross-validation:\n",
      "Best Parameters: {'rf__criterion': 'entropy', 'rf__max_depth': 30, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}\n",
      "Best F1 Score: 0.8258169934640522\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "def runRFWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': 'f1'\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with SMOTE and Random Forest\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Include vectorizer in pipeline\n",
    "        ('smote', SMOTE(random_state=42)),                 # SMOTE for oversampling\n",
    "        ('rf', RandomForestClassifier(random_state=42))    # Random Forest classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'rf__n_estimators': [10, 50, 100],               # Number of trees in the forest\n",
    "        'rf__max_depth': [10, 30, 50],                   # Maximum depth of the tree\n",
    "        'rf__min_samples_split': [2, 5],                 # Minimum number of samples required to split a node\n",
    "        'rf__min_samples_leaf': [1, 2],                  # Minimum number of samples required at a leaf node\n",
    "        'rf__criterion': ['gini', 'entropy']             # Function to measure the quality of a split\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE: {best_params}\")\n",
    "    print(f\"Best F1 Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combinations\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'n_estimators': results['params'][idx].get('rf__n_estimators'),\n",
    "            'max_depth': results['params'][idx].get('rf__max_depth'),\n",
    "            'min_samples_split': results['params'][idx].get('rf__min_samples_split'),\n",
    "            'min_samples_leaf': results['params'][idx].get('rf__min_samples_leaf'),\n",
    "            'criterion': results['params'][idx].get('rf__criterion'),\n",
    "            'accuracy': results['mean_test_accuracy'][idx],\n",
    "            'precision': results['mean_test_precision'][idx],\n",
    "            'recall': results['mean_test_recall'][idx],\n",
    "            'f1': results['mean_test_f1'][idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile = os.path.join(outDir, f\"rf-smote-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    outFile = os.path.join(outDir, f\"rf-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1}\\n\")\n",
    "\n",
    "    print(f\"Random Forest analysis completed for {n_splits}-folds with SMOTE. Results saved to: {outFile}\")\n",
    "\n",
    "    return best_params, final_f1\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for Both 3-Fold and 5-Fold\n",
    "\n",
    "# Run Random Forest with SMOTE using 3-fold cross-validation\n",
    "print(\"Starting Random Forest analysis with SMOTE for 3-fold cross-validation...\")\n",
    "best_params_3folds, best_f1_3folds = runRFWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=3)\n",
    "\n",
    "# Run Random Forest with SMOTE using 5-fold cross-validation\n",
    "print(\"\\nStarting Random Forest analysis with SMOTE for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds = runRFWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Random Forest with SMOTE 3-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_3folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_3folds}\")\n",
    "\n",
    "print(\"\\nBest results for Random Forest with SMOTE 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef3f6e",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6504957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis with SMOTE for 3-fold cross-validation...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best Parameters with SMOTE: {'dt__criterion': 'entropy', 'dt__max_depth': 10, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 2}\n",
      "Best F1 Score from cross-validation: 0.8475533661740559\n",
      "Per-fold metrics saved to: smote-results\\dt-smote-fold-results-3-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.9410256410256409\n",
      "Final Recall: 0.7777777777777777\n",
      "Final Accuracy: 0.9598653198653198\n",
      "Final F1 Score: 0.8475533661740559\n",
      "Decision Tree analysis completed for 3-folds with SMOTE. Results saved to: smote-results\\dt-results-3-folds.csv\n",
      "\n",
      "Starting Decision Tree analysis with SMOTE for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters with SMOTE: {'dt__criterion': 'gini', 'dt__max_depth': 10, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "Best F1 Score from cross-validation: 0.8313037495700035\n",
      "Per-fold metrics saved to: smote-results\\dt-smote-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.8772222222222222\n",
      "Final Recall: 0.8\n",
      "Final Accuracy: 0.9531073446327684\n",
      "Final F1 Score: 0.8313037495700035\n",
      "Decision Tree analysis completed for 5-folds with SMOTE. Results saved to: smote-results\\dt-results-5-folds.csv\n",
      "\n",
      "Best results for Decision Tree with SMOTE 3-fold cross-validation:\n",
      "Best Parameters: {'dt__criterion': 'entropy', 'dt__max_depth': 10, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 2}\n",
      "Best F1 Score: 0.8475533661740559\n",
      "\n",
      "Best results for Decision Tree with SMOTE 5-fold cross-validation:\n",
      "Best Parameters: {'dt__criterion': 'gini', 'dt__max_depth': 10, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "Best F1 Score: 0.8313037495700035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "def runDTWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1': 'f1'\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with SMOTE and Decision Tree\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Include vectorizer in pipeline\n",
    "        ('smote', SMOTE(random_state=42)),                 # SMOTE for oversampling\n",
    "        ('dt', DecisionTreeClassifier(random_state=42))    # Decision Tree classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'dt__max_depth': [10, 30, 50],                   # Maximum depth of the tree\n",
    "        'dt__min_samples_split': [2, 5],                 # Minimum number of samples required to split a node\n",
    "        'dt__min_samples_leaf': [1, 2],                  # Minimum number of samples required at a leaf node\n",
    "        'dt__criterion': ['gini', 'entropy']             # Function to measure the quality of a split\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=skf, scoring=scoring,\n",
    "        refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE: {best_params}\")\n",
    "    print(f\"Best F1 Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Calculate preparation time per document\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combinations\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'max_depth': results['params'][idx].get('dt__max_depth'),\n",
    "            'min_samples_split': results['params'][idx].get('dt__min_samples_split'),\n",
    "            'min_samples_leaf': results['params'][idx].get('dt__min_samples_leaf'),\n",
    "            'criterion': results['params'][idx].get('dt__criterion'),\n",
    "            'accuracy': results['mean_test_accuracy'][idx],\n",
    "            'precision': results['mean_test_precision'][idx],\n",
    "            'recall': results['mean_test_recall'][idx],\n",
    "            'f1': results['mean_test_f1'][idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile = os.path.join(outDir, f\"dt-smote-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = grid_search.best_score_\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    outFile = os.path.join(outDir, f\"dt-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {n_splits}-folds with SMOTE. Results saved to: {outFile}\")\n",
    "\n",
    "    return best_params, final_f1\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for Both 3-Fold and 5-Fold\n",
    "\n",
    "# Assuming 'Z', 'dataLabelsList', and 'outDir' are already defined\n",
    "\n",
    "# Run Decision Tree with SMOTE using 3-fold cross-validation\n",
    "print(\"Starting Decision Tree analysis with SMOTE for 3-fold cross-validation...\")\n",
    "best_params_3folds, best_f1_3folds = runDTWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=3)\n",
    "\n",
    "# Run Decision Tree with SMOTE using 5-fold cross-validation\n",
    "print(\"\\nStarting Decision Tree analysis with SMOTE for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds = runDTWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Decision Tree with SMOTE 3-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_3folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_3folds}\")\n",
    "\n",
    "print(\"\\nBest results for Decision Tree with SMOTE 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f4a6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55b949ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results saved to: best_results_smote.csv\n",
      "\n",
      "Best Results from All SMOTE Models\n",
      "        Model        Fold  Best Accuracy  Best Precision  Best Recall  Best F1 Score                                                                                                                                                                                                                        Best Parameters\n",
      "          KNN 5-fold-fold       0.849661        0.508939     0.644444       0.560588                                                 {'n_neighbors': 3, 'weights': 'distance', 'metric': 'cosine', 'accuracy': 0.8496610169491525, 'precision': 0.5089393939393939, 'recall': 0.6444444444444444, 'f1': 0.5605882352941176}\n",
      "          KNN 3-fold-fold       0.822963        0.450617     0.644444       0.526455                                                  {'n_neighbors': 3, 'weights': 'distance', 'metric': 'cosine', 'accuracy': 0.822962962962963, 'precision': 0.4506172839506173, 'recall': 0.6444444444444444, 'f1': 0.5264550264550265}\n",
      "          SVM 5-fold-fold       0.902938        0.724747     0.577778       0.623419                                                                                {'C': 0.1, 'kernel': 'linear', 'accuracy': 0.9029378531073448, 'precision': 0.7247474747474747, 'recall': 0.5777777777777777, 'f1': 0.6234188034188035}\n",
      "          SVM 3-fold-fold       0.902938        0.724747     0.577778       0.623419                                                                                {'C': 0.1, 'kernel': 'linear', 'accuracy': 0.9029378531073448, 'precision': 0.7247474747474747, 'recall': 0.5777777777777777, 'f1': 0.6234188034188035}\n",
      "  Naive Bayes 5-fold-fold       0.916384        0.795000     0.577778       0.658904                                                                                                           {'alpha': 0.001, 'accuracy': 0.9163841807909604, 'precision': 0.795, 'recall': 0.5777777777777777, 'f1': 0.6589043309631546}\n",
      "  Naive Bayes 3-fold-fold       0.909731        0.778535     0.577778       0.652471                                                                                                {'alpha': 1.0, 'accuracy': 0.9097306397306396, 'precision': 0.7785353535353535, 'recall': 0.5777777777777778, 'f1': 0.6524712002972873}\n",
      "      XGBoost 5-fold-fold       0.966497        1.000000     0.777778       0.866092                                                                {'n_estimators': 300.0, 'max_depth': 7.0, 'learning_rate': 0.1, 'accuracy': 0.9664971751412428, 'precision': 1.0, 'recall': 0.7777777777777778, 'f1': 0.86609243697479}\n",
      "      XGBoost 3-fold-fold       0.969899        1.000000     0.800000       0.884802                                                                 {'n_estimators': 300.0, 'max_depth': 3.0, 'learning_rate': 0.1, 'accuracy': 0.96989898989899, 'precision': 1.0, 'recall': 0.8000000000000002, 'f1': 0.884802043422733}\n",
      "Random Forest 5-fold-fold       0.949774        0.857540     0.800000       0.825817 {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'accuracy': 0.9497740112994352, 'precision': 0.8575396825396824, 'recall': 0.7999999999999999, 'f1': 0.8258169934640522}\n",
      "Random Forest 3-fold-fold       0.943064        0.820635     0.800000       0.809962  {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy', 'accuracy': 0.943063973063973, 'precision': 0.8206349206349207, 'recall': 0.7999999999999999, 'f1': 0.8099616858237547}\n",
      "Decision Tree 5-fold-fold       0.953107        0.877222     0.800000       0.831304                                        {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'accuracy': 0.9531073446327684, 'precision': 0.8772222222222222, 'recall': 0.8, 'f1': 0.8313037495700035}\n",
      "Decision Tree 3-fold-fold       0.959865        0.941026     0.777778       0.847553                      {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy', 'accuracy': 0.9598653198653198, 'precision': 0.9410256410256408, 'recall': 0.7777777777777777, 'f1': 0.8475533661740559}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract the best results from the CSV files of each model\n",
    "def extract_best_results(model_name, fold, csv_file):\n",
    "    \"\"\"\n",
    "    Extracts the best result from the CSV file for a model.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name: The name of the model (e.g., \"XGBoost\", \"Random Forest\", \"Decision Tree\")\n",
    "    - fold: Number of folds (e.g., 5 or 3)\n",
    "    - csv_file: The path to the CSV file containing the model's results\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing the best results for the model and fold.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_file):\n",
    "        print(f\"CSV file for {model_name} ({fold}-fold) does not exist: {csv_file}\")\n",
    "        return None\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Get the row with the best F1 score\n",
    "    best_row = df.loc[df['f1'].idxmax()]\n",
    "\n",
    "    # Collect the best results into a dictionary\n",
    "    best_results = {\n",
    "        'Model': model_name,\n",
    "        'Fold': f\"{fold}-fold\",\n",
    "        'Best Accuracy': best_row['accuracy'],\n",
    "        'Best Precision': best_row['precision'],\n",
    "        'Best Recall': best_row['recall'],\n",
    "        'Best F1 Score': best_row['f1'],\n",
    "        'Best Parameters': best_row.to_dict()  # Including all parameters\n",
    "    }\n",
    "\n",
    "    return best_results\n",
    "\n",
    "# Function to gather and print/save the best results from all SMOTE models\n",
    "def gather_best_results(models_results_dir, output_file):\n",
    "    \"\"\"\n",
    "    Gathers the best results from all SMOTE models and writes them to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - models_results_dir: Directory where the model result CSV files are stored for the SMOTE models.\n",
    "    - output_file: Path to the output CSV file to store the best results.\n",
    "    \"\"\"\n",
    "    # List of models and their corresponding result files for both 5-fold and 3-fold\n",
    "    models = {\n",
    "        'KNN': {'5-fold': 'knn-smote-fold-results-5-folds.csv', '3-fold': 'knn-smote-fold-results-3-folds.csv'},\n",
    "        'SVM': {'5-fold': 'svm-smote-fold-results-5-folds.csv', '3-fold': 'svm-smote-fold-results-5-folds.csv'},\n",
    "        'Naive Bayes': {'5-fold': 'nb-smote-fold-results-5-folds.csv', '3-fold': 'nb-smote-fold-results-3-folds.csv'},\n",
    "        'XGBoost': {'5-fold': 'xgb-smote-fold-results-5-folds.csv', '3-fold': 'xgb-smote-fold-results-3-folds.csv'},\n",
    "        'Random Forest': {'5-fold': 'rf-smote-fold-results-5-folds.csv', '3-fold': 'rf-smote-fold-results-3-folds.csv'},\n",
    "        'Decision Tree': {'5-fold': 'dt-smote-fold-results-5-folds.csv', '3-fold': 'dt-smote-fold-results-3-folds.csv'}\n",
    "    }\n",
    "\n",
    "    # Initialize an empty list to store the best results from each model and fold\n",
    "    best_results = []\n",
    "\n",
    "    # Iterate over each model and its result files for both 5-fold and 3-fold\n",
    "    for model_name, folds in models.items():\n",
    "        for fold, csv_file in folds.items():\n",
    "            full_csv_path = os.path.join(models_results_dir, csv_file)\n",
    "            best_result = extract_best_results(model_name, fold, full_csv_path)\n",
    "            if best_result:\n",
    "                best_results.append(best_result)\n",
    "\n",
    "    # Convert the list of best results into a DataFrame\n",
    "    best_results_df = pd.DataFrame(best_results)\n",
    "\n",
    "    # Save the best results to the output CSV file\n",
    "    best_results_df.to_csv(output_file, index=False)\n",
    "    print(f\"Best results saved to: {output_file}\")\n",
    "\n",
    "    # Print the best results as a table\n",
    "    print(f\"\\nBest Results from All SMOTE Models\")\n",
    "    print(best_results_df.to_string(index=False))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Directories where the model result CSV files are stored\n",
    "    results_dir = 'smote-results'\n",
    "\n",
    "    # Path to the output CSV file where best results will be stored\n",
    "    output_file = \"best_results_smote.csv\"\n",
    "\n",
    "    # Gather and save the best results\n",
    "    gather_best_results(results_dir, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf999d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
