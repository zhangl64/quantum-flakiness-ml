{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e03351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: equal-params-dt-5-folds-Threshold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: equal-params-dt-3-folds-Threshold.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.6540756302521008, 'accuracy': 0.6596491228070175, 'precision': 0.6605844155844156, 'recall': 0.6555555555555556, 'mcc': 0.3219734115997638}, 0.2: {'f1': 0.6540756302521008, 'accuracy': 0.6596491228070175, 'precision': 0.6605844155844156, 'recall': 0.6555555555555556, 'mcc': 0.3219734115997638}, 0.30000000000000004: {'f1': 0.6540756302521008, 'accuracy': 0.6596491228070175, 'precision': 0.6605844155844156, 'recall': 0.6555555555555556, 'mcc': 0.3219734115997638}, 0.4: {'f1': 0.6540756302521008, 'accuracy': 0.6596491228070175, 'precision': 0.6605844155844156, 'recall': 0.6555555555555556, 'mcc': 0.3219734115997638}, 0.5: {'f1': 0.6540756302521008, 'accuracy': 0.6596491228070175, 'precision': 0.6605844155844156, 'recall': 0.6555555555555556, 'mcc': 0.3219734115997638}, 0.6: {'f1': 0.5543977591036414, 'accuracy': 0.6058479532163743, 'precision': 0.6117748917748917, 'recall': 0.5288888888888889, 'mcc': 0.2182164952665861}, 0.7000000000000001: {'f1': 0.5724428718855963, 'accuracy': 0.6269005847953215, 'precision': 0.6481385281385281, 'recall': 0.5288888888888889, 'mcc': 0.2611291898990602}, 0.8: {'f1': 0.5724428718855963, 'accuracy': 0.6269005847953215, 'precision': 0.6481385281385281, 'recall': 0.5288888888888889, 'mcc': 0.2611291898990602}, 0.9: {'f1': 0.5724428718855963, 'accuracy': 0.6269005847953215, 'precision': 0.6481385281385281, 'recall': 0.5288888888888889, 'mcc': 0.2611291898990602}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.5512188960464822, 'accuracy': 0.5745967741935484, 'precision': 0.5974358974358974, 'recall': 0.5347222222222222, 'mcc': 0.15932048308127475}, 0.2: {'f1': 0.5512188960464822, 'accuracy': 0.5745967741935484, 'precision': 0.5974358974358974, 'recall': 0.5347222222222222, 'mcc': 0.15932048308127475}, 0.30000000000000004: {'f1': 0.510989010989011, 'accuracy': 0.5638440860215054, 'precision': 0.6166666666666667, 'recall': 0.47222222222222215, 'mcc': 0.15145405649877242}, 0.4: {'f1': 0.510989010989011, 'accuracy': 0.5638440860215054, 'precision': 0.6166666666666667, 'recall': 0.47222222222222215, 'mcc': 0.15145405649877242}, 0.5: {'f1': 0.510989010989011, 'accuracy': 0.5638440860215054, 'precision': 0.6166666666666667, 'recall': 0.47222222222222215, 'mcc': 0.15145405649877242}, 0.6: {'f1': 0.4925558312655087, 'accuracy': 0.5638440860215054, 'precision': 0.6166666666666667, 'recall': 0.42777777777777776, 'mcc': 0.14805869628024204}, 0.7000000000000001: {'f1': 0.4925558312655087, 'accuracy': 0.5638440860215054, 'precision': 0.6166666666666667, 'recall': 0.42777777777777776, 'mcc': 0.14805869628024204}, 0.8: {'f1': 0.4925558312655087, 'accuracy': 0.5638440860215054, 'precision': 0.6166666666666667, 'recall': 0.42777777777777776, 'mcc': 0.14805869628024204}, 0.9: {'f1': 0.4925558312655087, 'accuracy': 0.5638440860215054, 'precision': 0.6166666666666667, 'recall': 0.42777777777777776, 'mcc': 0.14805869628024204}}\n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: larger-params-dt-5-folds-Threshold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: larger-params-dt-3-folds-Threshold.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.41692810457516344, 'accuracy': 0.823879781420765, 'precision': 0.44642857142857145, 'recall': 0.4022222222222222, 'mcc': 0.3185982402980728}, 0.2: {'f1': 0.41692810457516344, 'accuracy': 0.823879781420765, 'precision': 0.44642857142857145, 'recall': 0.4022222222222222, 'mcc': 0.3185982402980728}, 0.30000000000000004: {'f1': 0.40632204396910276, 'accuracy': 0.823879781420765, 'precision': 0.4416666666666666, 'recall': 0.3822222222222222, 'mcc': 0.3069270097000493}, 0.4: {'f1': 0.40632204396910276, 'accuracy': 0.823879781420765, 'precision': 0.4416666666666666, 'recall': 0.3822222222222222, 'mcc': 0.3069270097000493}, 0.5: {'f1': 0.40632204396910276, 'accuracy': 0.823879781420765, 'precision': 0.4416666666666666, 'recall': 0.3822222222222222, 'mcc': 0.3069270097000493}, 0.6: {'f1': 0.41743315508021395, 'accuracy': 0.8304918032786885, 'precision': 0.47023809523809523, 'recall': 0.3822222222222222, 'mcc': 0.3245425812522293}, 0.7000000000000001: {'f1': 0.4298141074611663, 'accuracy': 0.8371584699453554, 'precision': 0.5092857142857142, 'recall': 0.3822222222222222, 'mcc': 0.3458712508087344}, 0.8: {'f1': 0.4056382832853421, 'accuracy': 0.8338251366120218, 'precision': 0.4892857142857142, 'recall': 0.36, 'mcc': 0.322268874442558}, 0.9: {'f1': 0.4056382832853421, 'accuracy': 0.8338251366120218, 'precision': 0.4892857142857142, 'recall': 0.36, 'mcc': 0.322268874442558}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.3717303510406959, 'accuracy': 0.8007920792079207, 'precision': 0.3650793650793651, 'recall': 0.38472222222222224, 'mcc': 0.2558674996260069}, 0.2: {'f1': 0.3717303510406959, 'accuracy': 0.8007920792079207, 'precision': 0.3650793650793651, 'recall': 0.38472222222222224, 'mcc': 0.2558674996260069}, 0.30000000000000004: {'f1': 0.3609195402298851, 'accuracy': 0.8007920792079207, 'precision': 0.3609022556390977, 'recall': 0.36388888888888893, 'mcc': 0.24406944388069549}, 0.4: {'f1': 0.3609195402298851, 'accuracy': 0.8007920792079207, 'precision': 0.3609022556390977, 'recall': 0.36388888888888893, 'mcc': 0.24406944388069549}, 0.5: {'f1': 0.3609195402298851, 'accuracy': 0.8007920792079207, 'precision': 0.3609022556390977, 'recall': 0.36388888888888893, 'mcc': 0.24406944388069549}, 0.6: {'f1': 0.32756132756132755, 'accuracy': 0.8205610561056105, 'precision': 0.40482654600301665, 'recall': 0.3, 'mcc': 0.24214780449336662}, 0.7000000000000001: {'f1': 0.32756132756132755, 'accuracy': 0.8205610561056105, 'precision': 0.40482654600301665, 'recall': 0.3, 'mcc': 0.24214780449336662}, 0.8: {'f1': 0.31290931290931295, 'accuracy': 0.8205610561056105, 'precision': 0.4024955436720143, 'recall': 0.27777777777777773, 'mcc': 0.2296755145022055}, 0.9: {'f1': 0.31290931290931295, 'accuracy': 0.8205610561056105, 'precision': 0.4024955436720143, 'recall': 0.27777777777777773, 'mcc': 0.2296755145022055}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define Decision Tree model with given parameters\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=params.get('criterion', 'entropy'),\n",
    "        max_depth=params.get('max_depth', None),\n",
    "        min_samples_split=params.get('min_samples_split', 2),\n",
    "        min_samples_leaf=params.get('min_samples_leaf', 1),\n",
    "        max_features=params.get('max_features', None),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize metrics storage for each threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_threshold = {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                             for threshold in thresholds}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, average='binary', zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='binary', zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, average='binary', zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Accumulate metrics for the current threshold\n",
    "            metrics_per_threshold[threshold]['f1'] += f1\n",
    "            metrics_per_threshold[threshold]['accuracy'] += accuracy\n",
    "            metrics_per_threshold[threshold]['precision'] += precision\n",
    "            metrics_per_threshold[threshold]['recall'] += recall\n",
    "            metrics_per_threshold[threshold]['mcc'] += mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Average metrics over all folds\n",
    "    for threshold in thresholds:\n",
    "        metrics_per_threshold[threshold]['f1'] /= successFold\n",
    "        metrics_per_threshold[threshold]['accuracy'] /= successFold\n",
    "        metrics_per_threshold[threshold]['precision'] /= successFold\n",
    "        metrics_per_threshold[threshold]['recall'] /= successFold\n",
    "        metrics_per_threshold[threshold]['mcc'] /= successFold\n",
    "\n",
    "    # Save the results for each threshold\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each threshold\n",
    "        for threshold in thresholds:\n",
    "            fo.write(f\"{threshold},{metrics_per_threshold[threshold]['accuracy']},{metrics_per_threshold[threshold]['precision']},\"\n",
    "                     f\"{metrics_per_threshold[threshold]['recall']},{metrics_per_threshold[threshold]['f1']},{metrics_per_threshold[threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_threshold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    params = {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"max_depth\": 300,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\": 'log2'\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6a1c0",
   "metadata": {},
   "source": [
    "Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c255f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1414966639.py, line 131)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 131\u001b[1;36m\u001b[0m\n\u001b[1;33m    precision = precision_score(y_test, y_pred, , zero_division=1)\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define Decision Tree model with given parameters\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=params.get('criterion', 'entropy'),\n",
    "        max_depth=params.get('max_depth', None),\n",
    "        min_samples_split=params.get('min_samples_split', 2),\n",
    "        min_samples_leaf=params.get('min_samples_leaf', 1),\n",
    "        max_features=params.get('max_features', None),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "       # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_fold = {fold+1: {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                                 for threshold in thresholds}\n",
    "                        for fold in range(n_splits)}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold for this fold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, , zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Store metrics for the current threshold for this fold\n",
    "            metrics_per_fold[fold+1][threshold]['f1'] = f1\n",
    "            metrics_per_fold[fold+1][threshold]['accuracy'] = accuracy\n",
    "            metrics_per_fold[fold+1][threshold]['precision'] = precision\n",
    "            metrics_per_fold[fold+1][threshold]['recall'] = recall\n",
    "            metrics_per_fold[fold+1][threshold]['mcc'] = mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Save the results for each threshold and fold\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold-allKfold.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"fold,threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each fold and each threshold\n",
    "        for fold in range(1, successFold + 1):\n",
    "            for threshold in thresholds:\n",
    "                fo.write(f\"{fold},{threshold},{metrics_per_fold[fold][threshold]['accuracy']},{metrics_per_fold[fold][threshold]['precision']},\"\n",
    "                         f\"{metrics_per_fold[fold][threshold]['recall']},{metrics_per_fold[fold][threshold]['f1']},{metrics_per_fold[fold][threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_fold\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    params = {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"max_depth\": 300,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\" : 'log2'\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157d704",
   "metadata": {},
   "source": [
    "Decition Tree - all Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6318a53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Decision Tree analysis completed. Results saved to: equal-params-dt-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "      criterion  max_depth  min_samples_split  min_samples_leaf max_features  \\\n",
      "0          gini        NaN                  2                 1         None   \n",
      "1          gini        NaN                  2                 1         None   \n",
      "2          gini        NaN                  2                 1         None   \n",
      "3          gini        NaN                  2                 1         None   \n",
      "4          gini        NaN                  2                 1         None   \n",
      "...         ...        ...                ...               ...          ...   \n",
      "22675   entropy      500.0                 10                10         log2   \n",
      "22676   entropy      500.0                 10                10         log2   \n",
      "22677   entropy      500.0                 10                10         log2   \n",
      "22678   entropy      500.0                 10                10         log2   \n",
      "22679   entropy      500.0                 10                10         log2   \n",
      "\n",
      "       fold  threshold  accuracy  precision    recall        f1       mcc  \n",
      "0         1        0.1  0.684211       0.75  0.600000  0.666667  0.382047  \n",
      "1         1        0.2  0.684211       0.75  0.600000  0.666667  0.382047  \n",
      "2         1        0.3  0.684211       0.75  0.600000  0.666667  0.382047  \n",
      "3         1        0.4  0.684211       0.75  0.600000  0.666667  0.382047  \n",
      "4         1        0.5  0.684211       0.75  0.600000  0.666667  0.382047  \n",
      "...     ...        ...       ...        ...       ...       ...       ...  \n",
      "22675     5        0.5  0.500000       0.50  0.444444  0.470588  0.000000  \n",
      "22676     5        0.6  0.611111       0.75  0.333333  0.461538  0.267261  \n",
      "22677     5        0.7  0.611111       0.75  0.333333  0.461538  0.267261  \n",
      "22678     5        0.8  0.500000       0.50  0.111111  0.181818  0.000000  \n",
      "22679     5        0.9  0.500000       0.50  0.111111  0.181818  0.000000  \n",
      "\n",
      "[22680 rows x 12 columns]\n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree analysis completed. Results saved to: larger-params-dt-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "      criterion  max_depth  min_samples_split  min_samples_leaf max_features  \\\n",
      "0          gini        NaN                  2                 1         None   \n",
      "1          gini        NaN                  2                 1         None   \n",
      "2          gini        NaN                  2                 1         None   \n",
      "3          gini        NaN                  2                 1         None   \n",
      "4          gini        NaN                  2                 1         None   \n",
      "...         ...        ...                ...               ...          ...   \n",
      "22675   entropy      500.0                 10                10         log2   \n",
      "22676   entropy      500.0                 10                10         log2   \n",
      "22677   entropy      500.0                 10                10         log2   \n",
      "22678   entropy      500.0                 10                10         log2   \n",
      "22679   entropy      500.0                 10                10         log2   \n",
      "\n",
      "       fold  threshold  accuracy  precision    recall        f1       mcc  \n",
      "0         1        0.1  0.836066       0.50  0.400000  0.444444  0.352676  \n",
      "1         1        0.2  0.836066       0.50  0.400000  0.444444  0.352676  \n",
      "2         1        0.3  0.836066       0.50  0.400000  0.444444  0.352676  \n",
      "3         1        0.4  0.836066       0.50  0.400000  0.444444  0.352676  \n",
      "4         1        0.5  0.836066       0.50  0.400000  0.444444  0.352676  \n",
      "...     ...        ...       ...        ...       ...       ...       ...  \n",
      "22675     5        0.5  0.816667       0.25  0.111111  0.153846  0.074848  \n",
      "22676     5        0.6  0.816667       0.25  0.111111  0.153846  0.074848  \n",
      "22677     5        0.7  0.850000       1.00  0.000000  0.000000  0.000000  \n",
      "22678     5        0.8  0.850000       1.00  0.000000  0.000000  0.000000  \n",
      "22679     5        0.9  0.850000       1.00  0.000000  0.000000  0.000000  \n",
      "\n",
      "[22680 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search Decision Tree with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize DecisionTreeClassifier with current hyperparameter combination\n",
    "        dt_model = DecisionTreeClassifier(\n",
    "            criterion=param_dict['criterion'],\n",
    "            max_depth=param_dict['max_depth'],\n",
    "            min_samples_split=param_dict['min_samples_split'],\n",
    "            min_samples_leaf=param_dict['min_samples_leaf'],\n",
    "            max_features=param_dict['max_features'],\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            dt_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred,  zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred,  zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'criterion': param_dict['criterion'],\n",
    "                    'max_depth': param_dict['max_depth'],\n",
    "                    'min_samples_split': param_dict['min_samples_split'],\n",
    "                    'min_samples_leaf': param_dict['min_samples_leaf'],\n",
    "                    'max_features': param_dict['max_features'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"Decision Tree analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "        'max_depth': [None, 10, 30, 50, 100, 300, 500],  # Maximum depth of each tree\n",
    "        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 5, 10],  # Minimum number of samples required to be at a leaf node\n",
    "        'max_features': [None, 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00921a6d",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e124ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Random Forest analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Random Forest analysis completed. Results saved to: equal-params-rf-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "       n_estimators criterion  max_depth  min_samples_split  min_samples_leaf  \\\n",
      "0                10      gini         10                  2                 1   \n",
      "1                10      gini         10                  2                 1   \n",
      "2                10      gini         10                  2                 1   \n",
      "3                10      gini         10                  2                 1   \n",
      "4                10      gini         10                  2                 1   \n",
      "...             ...       ...        ...                ...               ...   \n",
      "10795           500   entropy        500                  5                 2   \n",
      "10796           500   entropy        500                  5                 2   \n",
      "10797           500   entropy        500                  5                 2   \n",
      "10798           500   entropy        500                  5                 2   \n",
      "10799           500   entropy        500                  5                 2   \n",
      "\n",
      "       fold  threshold  accuracy  precision    recall        f1       mcc  \n",
      "0         1        0.1  0.526316   0.526316  1.000000  0.689655  0.000000  \n",
      "1         1        0.2  0.526316   0.529412  0.900000  0.666667  0.018078  \n",
      "2         1        0.3  0.473684   0.500000  0.500000  0.500000 -0.055556  \n",
      "3         1        0.4  0.473684   0.500000  0.500000  0.500000 -0.055556  \n",
      "4         1        0.5  0.578947   0.750000  0.300000  0.428571  0.231341  \n",
      "...     ...        ...       ...        ...       ...       ...       ...  \n",
      "10795     5        0.5  0.833333   1.000000  0.666667  0.800000  0.707107  \n",
      "10796     5        0.6  0.555556   1.000000  0.111111  0.200000  0.242536  \n",
      "10797     5        0.7  0.555556   1.000000  0.111111  0.200000  0.242536  \n",
      "10798     5        0.8  0.555556   1.000000  0.111111  0.200000  0.242536  \n",
      "10799     5        0.9  0.500000   1.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[10800 rows x 12 columns]\n",
      "Starting Random Forest analysis for flaky vs larger non-flaky files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Random Forest analysis completed. Results saved to: larger-params-rf-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "       n_estimators criterion  max_depth  min_samples_split  min_samples_leaf  \\\n",
      "0                10      gini         10                  2                 1   \n",
      "1                10      gini         10                  2                 1   \n",
      "2                10      gini         10                  2                 1   \n",
      "3                10      gini         10                  2                 1   \n",
      "4                10      gini         10                  2                 1   \n",
      "...             ...       ...        ...                ...               ...   \n",
      "10795           500   entropy        500                  5                 2   \n",
      "10796           500   entropy        500                  5                 2   \n",
      "10797           500   entropy        500                  5                 2   \n",
      "10798           500   entropy        500                  5                 2   \n",
      "10799           500   entropy        500                  5                 2   \n",
      "\n",
      "       fold  threshold  accuracy  precision    recall        f1       mcc  \n",
      "0         1        0.1  0.360656   0.162791  0.700000  0.264151 -0.004775  \n",
      "1         1        0.2  0.672131   0.291667  0.700000  0.411765  0.277875  \n",
      "2         1        0.3  0.803279   0.400000  0.400000  0.400000  0.282353  \n",
      "3         1        0.4  0.819672   0.444444  0.400000  0.421053  0.315219  \n",
      "4         1        0.5  0.852459   0.666667  0.200000  0.307692  0.308836  \n",
      "...     ...        ...       ...        ...       ...       ...       ...  \n",
      "10795     5        0.5  0.866667   1.000000  0.111111  0.200000  0.309912  \n",
      "10796     5        0.6  0.866667   1.000000  0.111111  0.200000  0.309912  \n",
      "10797     5        0.7  0.850000   1.000000  0.000000  0.000000  0.000000  \n",
      "10798     5        0.8  0.850000   1.000000  0.000000  0.000000  0.000000  \n",
      "10799     5        0.9  0.850000   1.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[10800 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search Random Forest with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize RandomForestClassifier with current hyperparameter combination\n",
    "        rf_model = RandomForestClassifier(\n",
    "            n_estimators=param_dict['n_estimators'],\n",
    "            criterion=param_dict['criterion'],\n",
    "            max_depth=param_dict['max_depth'],\n",
    "            min_samples_split=param_dict['min_samples_split'],\n",
    "            min_samples_leaf=param_dict['min_samples_leaf'],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            rf_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            y_pred_proba = rf_model.predict_proba(X_test)\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred,  zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred,  zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'n_estimators': param_dict['n_estimators'],\n",
    "                    'criterion': param_dict['criterion'],\n",
    "                    'max_depth': param_dict['max_depth'],\n",
    "                    'min_samples_split': param_dict['min_samples_split'],\n",
    "                    'min_samples_leaf': param_dict['min_samples_leaf'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-rf-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"Random Forest analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 300, 500],  # Number of trees\n",
    "        'max_depth': [10, 30, 50, 100, 300, 500],  # Maximum depth of each tree\n",
    "        'min_samples_split': [2, 5],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2],  # Minimum number of samples required to be at a leaf node\n",
    "        'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Random Forest analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Random Forest analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform Random Forest analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Random Forest analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69d231",
   "metadata": {},
   "source": [
    "XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63dba2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting XGBoost analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 50}\n",
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost analysis completed. Results saved to: equal-params-xgb-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "       eta  max_depth  n_estimators  fold  threshold  accuracy  precision  \\\n",
      "0     0.01          3            50     1        0.1  0.526316   0.526316   \n",
      "1     0.01          3            50     1        0.2  0.526316   0.526316   \n",
      "2     0.01          3            50     1        0.3  0.526316   0.526316   \n",
      "3     0.01          3            50     1        0.4  0.631579   0.600000   \n",
      "4     0.01          3            50     1        0.5  0.736842   0.692308   \n",
      "...    ...        ...           ...   ...        ...       ...        ...   \n",
      "2875  0.50         10           300     5        0.5  0.611111   0.625000   \n",
      "2876  0.50         10           300     5        0.6  0.611111   0.666667   \n",
      "2877  0.50         10           300     5        0.7  0.555556   0.600000   \n",
      "2878  0.50         10           300     5        0.8  0.555556   0.666667   \n",
      "2879  0.50         10           300     5        0.9  0.555556   0.666667   \n",
      "\n",
      "        recall        f1       mcc  \n",
      "0     1.000000  0.689655  0.000000  \n",
      "1     1.000000  0.689655  0.000000  \n",
      "2     1.000000  0.689655  0.000000  \n",
      "3     0.900000  0.720000  0.285774  \n",
      "4     0.900000  0.782609  0.489345  \n",
      "...        ...       ...       ...  \n",
      "2875  0.555556  0.588235  0.223607  \n",
      "2876  0.444444  0.533333  0.235702  \n",
      "2877  0.333333  0.428571  0.124035  \n",
      "2878  0.222222  0.333333  0.149071  \n",
      "2879  0.222222  0.333333  0.149071  \n",
      "\n",
      "[2880 rows x 10 columns]\n",
      "Starting XGBoost analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost analysis completed. Results saved to: larger-params-xgb-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "       eta  max_depth  n_estimators  fold  threshold  accuracy  precision  \\\n",
      "0     0.01          3            50     1        0.1  0.163934   0.163934   \n",
      "1     0.01          3            50     1        0.2  0.770492   0.333333   \n",
      "2     0.01          3            50     1        0.3  0.852459   1.000000   \n",
      "3     0.01          3            50     1        0.4  0.836066   1.000000   \n",
      "4     0.01          3            50     1        0.5  0.836066   1.000000   \n",
      "...    ...        ...           ...   ...        ...       ...        ...   \n",
      "2875  0.50         10           300     5        0.5  0.883333   1.000000   \n",
      "2876  0.50         10           300     5        0.6  0.883333   1.000000   \n",
      "2877  0.50         10           300     5        0.7  0.883333   1.000000   \n",
      "2878  0.50         10           300     5        0.8  0.866667   1.000000   \n",
      "2879  0.50         10           300     5        0.9  0.866667   1.000000   \n",
      "\n",
      "        recall        f1       mcc  \n",
      "0     1.000000  0.281690  0.000000  \n",
      "1     0.400000  0.363636  0.226437  \n",
      "2     0.100000  0.181818  0.291548  \n",
      "3     0.000000  0.000000  0.000000  \n",
      "4     0.000000  0.000000  0.000000  \n",
      "...        ...       ...       ...  \n",
      "2875  0.222222  0.363636  0.442043  \n",
      "2876  0.222222  0.363636  0.442043  \n",
      "2877  0.222222  0.363636  0.442043  \n",
      "2878  0.111111  0.200000  0.309912  \n",
      "2879  0.111111  0.200000  0.309912  \n",
      "\n",
      "[2880 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:42:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search XGBoost with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize XGBClassifier with current hyperparameter combination\n",
    "        xgb_model = XGBClassifier(\n",
    "            eta=param_dict['eta'],\n",
    "            max_depth=param_dict['max_depth'],\n",
    "            n_estimators=param_dict['n_estimators'],\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            xgb_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            y_pred_proba = xgb_model.predict_proba(X_test)\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred,  zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred,  zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred,  zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'eta': param_dict['eta'],\n",
    "                    'max_depth': param_dict['max_depth'],\n",
    "                    'n_estimators': param_dict['n_estimators'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-xgb-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"XGBoost analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'eta': [0.01, 0.1, 0.3, 0.5],  # Learning rate\n",
    "        'max_depth': [3, 5, 7, 10],    # Tree depth\n",
    "        'n_estimators': [50, 100, 200, 300],  # Number of boosting rounds\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform XGBoost analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting XGBoost analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform XGBoost analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting XGBoost analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd4d47",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6041d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KNN analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "KNN analysis completed. Results saved to: equal-params-knn-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "       n_neighbors   weights algorithm  leaf_size  p  fold  threshold  \\\n",
      "0                3   uniform      auto         30  1     1        0.1   \n",
      "1                3   uniform      auto         30  1     1        0.2   \n",
      "2                3   uniform      auto         30  1     1        0.3   \n",
      "3                3   uniform      auto         30  1     1        0.4   \n",
      "4                3   uniform      auto         30  1     1        0.5   \n",
      "...            ...       ...       ...        ... ..   ...        ...   \n",
      "10075           20  distance     brute         50  2     5        0.5   \n",
      "10076           20  distance     brute         50  2     5        0.6   \n",
      "10077           20  distance     brute         50  2     5        0.7   \n",
      "10078           20  distance     brute         50  2     5        0.8   \n",
      "10079           20  distance     brute         50  2     5        0.9   \n",
      "\n",
      "       accuracy  precision    recall        f1       mcc  \n",
      "0      0.631579   1.000000  0.300000  0.461538  0.410792  \n",
      "1      0.631579   1.000000  0.300000  0.461538  0.410792  \n",
      "2      0.631579   1.000000  0.300000  0.461538  0.410792  \n",
      "3      0.473684   1.000000  0.000000  0.000000  0.000000  \n",
      "4      0.473684   1.000000  0.000000  0.000000  0.000000  \n",
      "...         ...        ...       ...       ...       ...  \n",
      "10075  0.722222   0.833333  0.555556  0.666667  0.471405  \n",
      "10076  0.611111   0.750000  0.333333  0.461538  0.267261  \n",
      "10077  0.555556   1.000000  0.111111  0.200000  0.242536  \n",
      "10078  0.555556   1.000000  0.111111  0.200000  0.242536  \n",
      "10079  0.555556   1.000000  0.111111  0.200000  0.242536  \n",
      "\n",
      "[10080 rows x 12 columns]\n",
      "Starting KNN analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 50, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:583: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 30, 'p': 2}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 1}\n",
      "Training with parameters: {'n_neighbors': 20, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 50, 'p': 2}\n",
      "KNN analysis completed. Results saved to: larger-params-knn-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "       n_neighbors   weights algorithm  leaf_size  p  fold  threshold  \\\n",
      "0                3   uniform      auto         30  1     1        0.1   \n",
      "1                3   uniform      auto         30  1     1        0.2   \n",
      "2                3   uniform      auto         30  1     1        0.3   \n",
      "3                3   uniform      auto         30  1     1        0.4   \n",
      "4                3   uniform      auto         30  1     1        0.5   \n",
      "...            ...       ...       ...        ... ..   ...        ...   \n",
      "10075           20  distance     brute         50  2     5        0.5   \n",
      "10076           20  distance     brute         50  2     5        0.6   \n",
      "10077           20  distance     brute         50  2     5        0.7   \n",
      "10078           20  distance     brute         50  2     5        0.8   \n",
      "10079           20  distance     brute         50  2     5        0.9   \n",
      "\n",
      "       accuracy  precision    recall        f1       mcc  \n",
      "0      0.852459        1.0  0.100000  0.181818  0.291548  \n",
      "1      0.852459        1.0  0.100000  0.181818  0.291548  \n",
      "2      0.852459        1.0  0.100000  0.181818  0.291548  \n",
      "3      0.836066        1.0  0.000000  0.000000  0.000000  \n",
      "4      0.836066        1.0  0.000000  0.000000  0.000000  \n",
      "...         ...        ...       ...       ...       ...  \n",
      "10075  0.866667        1.0  0.111111  0.200000  0.309912  \n",
      "10076  0.866667        1.0  0.111111  0.200000  0.309912  \n",
      "10077  0.866667        1.0  0.111111  0.200000  0.309912  \n",
      "10078  0.866667        1.0  0.111111  0.200000  0.309912  \n",
      "10079  0.850000        1.0  0.000000  0.000000  0.000000  \n",
      "\n",
      "[10080 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search KNN with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize KNeighborsClassifier with current hyperparameter combination\n",
    "        knn_model = KNeighborsClassifier(\n",
    "            n_neighbors=param_dict['n_neighbors'],\n",
    "            weights=param_dict['weights'],\n",
    "            algorithm=param_dict['algorithm'],\n",
    "            leaf_size=param_dict['leaf_size'],\n",
    "            p=param_dict['p'],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            knn_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            if hasattr(knn_model, \"predict_proba\"):\n",
    "                y_pred_proba = knn_model.predict_proba(X_test)\n",
    "            else:\n",
    "                # If predict_proba is not available, use distance-based probabilities\n",
    "                distances, indices = knn_model.kneighbors(X_test)\n",
    "                weights = knn_model._get_weights(distances)\n",
    "                y_pred_proba = np.zeros((X_test.shape[0], 2))\n",
    "                for i, neighbors in enumerate(indices):\n",
    "                    neighbor_labels = y_train[neighbors]\n",
    "                    if weights is None:\n",
    "                        proba = np.bincount(neighbor_labels, minlength=2) / knn_model.n_neighbors\n",
    "                    else:\n",
    "                        proba = np.bincount(neighbor_labels, weights=weights[i], minlength=2) / weights[i].sum()\n",
    "                    y_pred_proba[i] = proba\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred,  zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred,  zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'n_neighbors': param_dict['n_neighbors'],\n",
    "                    'weights': param_dict['weights'],\n",
    "                    'algorithm': param_dict['algorithm'],\n",
    "                    'leaf_size': param_dict['leaf_size'],\n",
    "                    'p': param_dict['p'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-knn-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"KNN analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9,11,15,20],           # Number of neighbors to use\n",
    "        'weights': ['uniform', 'distance'],    # Weight function used in prediction\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute the nearest neighbors\n",
    "        'leaf_size': [30, 50],                 # Leaf size passed to BallTree or KDTree\n",
    "        'p': [1, 2],                           # Power parameter for the Minkowski metric\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform KNN analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting KNN analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform KNN analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting KNN analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc8ceb",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed90c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SVM analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'sigmoid'}\n",
      "SVM analysis completed. Results saved to: equal-params-svm-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "          C   kernel  fold  threshold  accuracy  precision    recall  \\\n",
      "0      0.01   linear     1        0.1  0.526316   0.526316  1.000000   \n",
      "1      0.01   linear     1        0.2  0.526316   0.526316  1.000000   \n",
      "2      0.01   linear     1        0.3  0.526316   0.526316  1.000000   \n",
      "3      0.01   linear     1        0.4  0.421053   0.466667  0.700000   \n",
      "4      0.01   linear     1        0.5  0.684211   0.833333  0.500000   \n",
      "..      ...      ...   ...        ...       ...        ...       ...   \n",
      "895  100.00  sigmoid     5        0.5  0.833333   1.000000  0.666667   \n",
      "896  100.00  sigmoid     5        0.6  0.500000   1.000000  0.000000   \n",
      "897  100.00  sigmoid     5        0.7  0.500000   1.000000  0.000000   \n",
      "898  100.00  sigmoid     5        0.8  0.500000   1.000000  0.000000   \n",
      "899  100.00  sigmoid     5        0.9  0.500000   1.000000  0.000000   \n",
      "\n",
      "           f1       mcc  \n",
      "0    0.689655  0.000000  \n",
      "1    0.689655  0.000000  \n",
      "2    0.689655  0.000000  \n",
      "3    0.560000 -0.231341  \n",
      "4    0.625000  0.417734  \n",
      "..        ...       ...  \n",
      "895  0.800000  0.707107  \n",
      "896  0.000000  0.000000  \n",
      "897  0.000000  0.000000  \n",
      "898  0.000000  0.000000  \n",
      "899  0.000000  0.000000  \n",
      "\n",
      "[900 rows x 9 columns]\n",
      "Starting SVM analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'sigmoid'}\n",
      "SVM analysis completed. Results saved to: larger-params-svm-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "          C   kernel  fold  threshold  accuracy  precision  recall       f1  \\\n",
      "0      0.01   linear     1        0.1  0.163934   0.163934     1.0  0.28169   \n",
      "1      0.01   linear     1        0.2  0.836066   1.000000     0.0  0.00000   \n",
      "2      0.01   linear     1        0.3  0.836066   1.000000     0.0  0.00000   \n",
      "3      0.01   linear     1        0.4  0.836066   1.000000     0.0  0.00000   \n",
      "4      0.01   linear     1        0.5  0.836066   1.000000     0.0  0.00000   \n",
      "..      ...      ...   ...        ...       ...        ...     ...      ...   \n",
      "895  100.00  sigmoid     5        0.5  0.850000   1.000000     0.0  0.00000   \n",
      "896  100.00  sigmoid     5        0.6  0.850000   1.000000     0.0  0.00000   \n",
      "897  100.00  sigmoid     5        0.7  0.850000   1.000000     0.0  0.00000   \n",
      "898  100.00  sigmoid     5        0.8  0.850000   1.000000     0.0  0.00000   \n",
      "899  100.00  sigmoid     5        0.9  0.850000   1.000000     0.0  0.00000   \n",
      "\n",
      "     mcc  \n",
      "0    0.0  \n",
      "1    0.0  \n",
      "2    0.0  \n",
      "3    0.0  \n",
      "4    0.0  \n",
      "..   ...  \n",
      "895  0.0  \n",
      "896  0.0  \n",
      "897  0.0  \n",
      "898  0.0  \n",
      "899  0.0  \n",
      "\n",
      "[900 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search SVM with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize SVM with current hyperparameter combination\n",
    "        svm_model = SVC(\n",
    "            C=param_dict['C'],\n",
    "            kernel=param_dict['kernel'],\n",
    "            probability=True,  # Enable probability estimates\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            try:\n",
    "                svm_model.fit(X_train, y_train)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to train SVM with parameters {param_dict} on fold {fold+1}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            try:\n",
    "                y_pred_proba = svm_model.predict_proba(X_test)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to predict probabilities with SVM on fold {fold+1}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred,  zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred,  zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred,  zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'C': param_dict['C'],\n",
    "                    'kernel': param_dict['kernel'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-svm-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"SVM analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization parameter\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # Kernel types\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform SVM analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting SVM analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform SVM analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting SVM analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74136b4",
   "metadata": {},
   "source": [
    "NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0281b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unlance without adjustment\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e823f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Naive Bayes analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'alpha': 0.001}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rp/h_pmxr992m143v567my_k4lm0000gn/T/ipykernel_8854/1748734143.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Perform Naive Bayes analysis for the first combination (flaky vs smaller non-flaky)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting Naive Bayes analysis for flaky vs smaller non-flaky files (47 each)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n\u001b[0m\u001b[1;32m    187\u001b[0m         outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/rp/h_pmxr992m143v567my_k4lm0000gn/T/ipykernel_8854/1748734143.py\u001b[0m in \u001b[0;36mflastThreshold\u001b[0;34m(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mnb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# Predict probabilities on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search Naive Bayes with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization without dimensionality reduction\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize MultinomialNB with current hyperparameter combination\n",
    "        nb_model = MultinomialNB(\n",
    "            alpha=param_dict['alpha']\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            nb_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            y_pred_proba = nb_model.predict_proba(X_test)\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'alpha': param_dict['alpha'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-nb-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"Naive Bayes analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0],  # Additive smoothing parameter\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Naive Bayes analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Naive Bayes analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform Naive Bayes analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Naive Bayes analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n",
    "    \n",
    "    \n",
    "    ### missing small but important?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e85bb0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file for KNN (equal, 3-fold) does not exist: results/equal_flaky_nonflaky/equal-params-knn-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for SVM (equal, 3-fold) does not exist: results/equal_flaky_nonflaky/equal-params-svm-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for Naive Bayes (equal, 5-fold) does not exist: results/equal_flaky_nonflaky/equal-params-nb-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "CSV file for Naive Bayes (equal, 3-fold) does not exist: results/equal_flaky_nonflaky/equal-params-nb-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for Naive Bayes (equal, 3-fold) does not exist: results/equal_flaky_nonflaky/equal-params-nb-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "CSV file for XGBoost (equal, 3-fold) does not exist: results/equal_flaky_nonflaky/equal-params-xgb-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for Random Forest (equal, 3-fold) does not exist: results/equal_flaky_nonflaky/equal-params-rf-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for Decision Tree (equal, 3-fold) does not exist: results/equal_flaky_nonflaky/equal-params-dt-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for equal combination (wogridsearch) saved to: best_results_equal_combination_wogridsearch.csv\n",
      "Best results for equal combination (one_hyperparameter) saved to: best_results_equal_combination_one_hyperparameter.csv\n",
      "\n",
      "Best Results from All Models for equal Combination (wogridsearch):\n",
      "              Model   Fold  Accuracy  Precision   Recall       F1      MCC                                                                                                                                      Parameters\n",
      "          equal KNN 5-fold  0.947368      0.900 1.000000 0.947368 0.900000                            {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2, 'threshold': 0.3, 'fold': 3}\n",
      "          equal SVM 5-fold  0.842105      0.800 0.888889 0.842105 0.688889                                                                                      {'C': 100.0, 'kernel': 'rbf', 'threshold': 0.4, 'fold': 3}\n",
      "  equal Naive Bayes 5-fold  0.842105      0.875 0.777778 0.823529 0.685437                                                                                                   {'alpha': 0.001, 'threshold': 0.1, 'fold': 3}\n",
      "      equal XGBoost 5-fold  1.000000      1.000 1.000000 1.000000 1.000000                                                              {'eta': 0.3, 'max_depth': 5.0, 'n_estimators': 100.0, 'threshold': 0.3, 'fold': 3}\n",
      "equal Random Forest 5-fold  1.000000      1.000 1.000000 1.000000 1.000000          {'n_estimators': 50, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'threshold': 0.5, 'fold': 4}\n",
      "equal Decision Tree 5-fold  0.842105      0.750 1.000000 0.857143 0.724569 {'criterion': 'entropy', 'max_depth': 10.0, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'threshold': 0.4, 'fold': 4}\n",
      "\n",
      "Best Results from All Models for equal Combination (one_hyperparameter):\n",
      "              Model   Fold  Accuracy  Precision   Recall       F1      MCC                                   Parameters\n",
      "          equal KNN 5-fold  0.842105   0.888889 0.800000 0.842105 0.688889                {'threshold': 0.5, 'fold': 2}\n",
      "          equal KNN 3-fold  0.806452   0.909091 0.666667 0.769231 0.631032                {'threshold': 0.5, 'fold': 3}\n",
      "          equal SVM 5-fold  0.789474   0.777778 0.777778 0.777778 0.577778                {'threshold': 0.5, 'fold': 3}\n",
      "          equal SVM 3-fold  0.709677   0.652174 0.937500 0.769231 0.461591                {'threshold': 0.3, 'fold': 2}\n",
      "      equal XGBoost 5-fold  0.894737   0.900000 0.900000 0.900000 0.788889                {'threshold': 0.5, 'fold': 2}\n",
      "      equal XGBoost 3-fold  0.875000   0.928571 0.812500 0.866667 0.755929 {'threshold': 0.7000000000000001, 'fold': 1}\n",
      "equal Random Forest 5-fold  0.944444   1.000000 0.888889 0.941176 0.894427                {'threshold': 0.5, 'fold': 5}\n",
      "equal Random Forest 3-fold  0.806452   0.800000 0.800000 0.800000 0.612500                {'threshold': 0.5, 'fold': 3}\n",
      "equal Decision Tree 5-fold  0.631579   0.652256 0.631579 0.625387 0.287527                {'threshold': 0.3, 'fold': 4}\n",
      "equal Decision Tree 3-fold  0.677419   0.712442 0.677419 0.667080 0.391983                {'threshold': 0.6, 'fold': 2}\n",
      "CSV file for KNN (larger, 3-fold) does not exist: results/larger_nonflaky/larger-params-knn-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for SVM (larger, 3-fold) does not exist: results/larger_nonflaky/larger-params-svm-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for Naive Bayes (larger, 5-fold) does not exist: results/larger_nonflaky/larger-params-nb-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "CSV file for Naive Bayes (larger, 3-fold) does not exist: results/larger_nonflaky/larger-params-nb-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for Naive Bayes (larger, 3-fold) does not exist: results/larger_nonflaky/larger-params-nb-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "CSV file for XGBoost (larger, 3-fold) does not exist: results/larger_nonflaky/larger-params-xgb-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for Random Forest (larger, 3-fold) does not exist: results/larger_nonflaky/larger-params-rf-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "CSV file for Decision Tree (larger, 3-fold) does not exist: results/larger_nonflaky/larger-params-dt-3-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for larger combination (wogridsearch) saved to: best_results_larger_combination_wogridsearch.csv\n",
      "Best results for larger combination (one_hyperparameter) saved to: best_results_larger_combination_one_hyperparameter.csv\n",
      "\n",
      "Best Results from All Models for larger Combination (wogridsearch):\n",
      "               Model   Fold  Accuracy  Precision   Recall       F1      MCC                                                                                                                                   Parameters\n",
      "          larger KNN 5-fold  0.950000   0.875000 0.777778 0.823529 0.796391                         {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2, 'threshold': 0.3, 'fold': 4}\n",
      "          larger SVM 5-fold  0.916667   0.750000 0.666667 0.705882 0.659082                                                                                   {'C': 100.0, 'kernel': 'rbf', 'threshold': 0.2, 'fold': 4}\n",
      "  larger Naive Bayes 5-fold  0.983333   0.900000 1.000000 0.947368 0.939336                                                                                                {'alpha': 0.001, 'threshold': 0.1, 'fold': 4}\n",
      "      larger XGBoost 5-fold  0.966667   1.000000 0.800000 0.888889 0.877058                                                          {'eta': 0.01, 'max_depth': 7.0, 'n_estimators': 100.0, 'threshold': 0.3, 'fold': 2}\n",
      "larger Random Forest 5-fold  0.966667   0.888889 0.888889 0.888889 0.869281   {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'threshold': 0.3, 'fold': 4}\n",
      "larger Decision Tree 5-fold  0.933333   1.000000 0.555556 0.714286 0.717741 {'criterion': 'gini', 'max_depth': 10.0, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'threshold': 0.1, 'fold': 3}\n",
      "\n",
      "Best Results from All Models for larger Combination (one_hyperparameter):\n",
      "               Model   Fold  Accuracy  Precision   Recall       F1      MCC                                   Parameters\n",
      "          larger KNN 5-fold  0.933333   0.777778 0.777778 0.777778 0.738562                {'threshold': 0.2, 'fold': 4}\n",
      "          larger KNN 3-fold  0.920000   1.000000 0.466667 0.636364 0.653088                {'threshold': 0.5, 'fold': 3}\n",
      "          larger SVM 5-fold  0.950000   0.750000 1.000000 0.857143 0.840168                {'threshold': 0.2, 'fold': 4}\n",
      "          larger SVM 3-fold  0.840000   0.500000 0.500000 0.500000 0.404762                {'threshold': 0.2, 'fold': 2}\n",
      "      larger XGBoost 5-fold  0.933333   0.727273 0.888889 0.800000 0.765992                {'threshold': 0.1, 'fold': 4}\n",
      "      larger XGBoost 3-fold  0.930693   0.846154 0.687500 0.758621 0.723945                {'threshold': 0.2, 'fold': 1}\n",
      "larger Random Forest 5-fold  0.883333   0.583333 0.777778 0.666667 0.606788                {'threshold': 0.3, 'fold': 4}\n",
      "larger Random Forest 3-fold  0.830000   0.480000 0.750000 0.585366 0.503953                {'threshold': 0.2, 'fold': 2}\n",
      "larger Decision Tree 5-fold  0.916667   0.913462 0.916667 0.914620 0.659082 {'threshold': 0.7000000000000001, 'fold': 4}\n",
      "larger Decision Tree 3-fold  0.871287   0.862563 0.871287 0.865746 0.481026                {'threshold': 0.6, 'fold': 1}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract the best results from the CSV files of each model\n",
    "def extract_best_results(model_name, combination, fold_label, csv_file):\n",
    "    \"\"\"\n",
    "    Extracts the best result from the CSV file for a model.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name: The name of the model (e.g., \"KNN\", \"SVM\")\n",
    "    - combination: The combination of flaky and non-flaky files (e.g., \"equal\", \"larger\")\n",
    "    - fold_label: Number of folds (e.g., \"5-fold\" or \"3-fold\")\n",
    "    - csv_file: The path to the CSV file containing the model's results\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing the best results for the model, combination, and fold.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_file):\n",
    "        print(f\"CSV file for {model_name} ({combination}, {fold_label}) does not exist: {csv_file}\")\n",
    "        return None\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"CSV file for {model_name} ({combination}, {fold_label}) is empty: {csv_file}\")\n",
    "        return None\n",
    "    \n",
    "    # Identify the metric columns\n",
    "    metric_columns = ['accuracy', 'precision', 'recall', 'f1', 'mcc']\n",
    "    # Identify parameter columns (exclude known metric columns and 'fold' and 'threshold')\n",
    "    parameter_columns = [col for col in df.columns if col not in metric_columns + ['fold', 'threshold']]\n",
    "    \n",
    "    # Group by hyperparameters, fold, and threshold, then find the row with the highest F1 score\n",
    "    idx = df.groupby(parameter_columns + ['fold', 'threshold'])['f1'].idxmax()\n",
    "    df_best = df.loc[idx]\n",
    "    \n",
    "    # Now, find the overall best result (highest F1 score)\n",
    "    best_row = df_best.loc[df_best['f1'].idxmax()]\n",
    "    \n",
    "    # Extract metrics\n",
    "    accuracy = best_row['accuracy']\n",
    "    precision = best_row['precision']\n",
    "    recall = best_row['recall']\n",
    "    f1 = best_row['f1']\n",
    "    mcc = best_row.get('mcc', None)  # Get MCC if available\n",
    "    \n",
    "    # Extract parameters\n",
    "    parameters = {col: best_row[col] for col in parameter_columns}\n",
    "    parameters['threshold'] = best_row['threshold']\n",
    "    parameters['fold'] = int(best_row['fold'])\n",
    "    \n",
    "    # Create a combined model name\n",
    "    combined_model_name = f\"{combination} {model_name}\"\n",
    "    \n",
    "    # Collect the best results into a dictionary\n",
    "    best_results = {\n",
    "        'Model': combined_model_name,\n",
    "        'Fold': fold_label,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'MCC': mcc,\n",
    "        'Parameters': parameters\n",
    "    }\n",
    "    \n",
    "    return best_results\n",
    "\n",
    "# Function to gather and print/save the best results from a single combination\n",
    "def gather_best_results_for_combination(models_results_dir, output_file_prefix, combination):\n",
    "    \"\"\"\n",
    "    Gathers the best results from all models for a specific combination (e.g., \"equal\", \"larger\") and writes them to separate CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    - models_results_dir: Directory where the model result CSV files are stored for the combination.\n",
    "    - output_file_prefix: Prefix for the output CSV files to store the best results for both 'wogridsearch' and 'one_hyperparameter'.\n",
    "    - combination: The combination name (e.g., \"equal\", \"larger\").\n",
    "    \"\"\"\n",
    "    # List of models and their corresponding result file patterns\n",
    "    models = {\n",
    "        'KNN': 'params-knn',\n",
    "        'SVM': 'params-svm',\n",
    "        'Naive Bayes': 'params-nb',\n",
    "        'XGBoost': 'params-xgb',\n",
    "        'Random Forest': 'params-rf',\n",
    "        'Decision Tree': 'params-dt'\n",
    "    }\n",
    "\n",
    "    # Initialize an empty list to store the best results from each model and fold for both file types\n",
    "    best_results_wogridsearch = []\n",
    "    best_results_one_hyperparameter = []\n",
    "\n",
    "    # Iterate over each model and its result files for both 5-fold and 3-fold\n",
    "    for model_name, base_filename in models.items():\n",
    "        for n_splits in [5, 3]:\n",
    "            fold_label = f\"{n_splits}-fold\"\n",
    "            \n",
    "            # Construct the CSV filenames for both \"wogridsearch\" and \"one_hyperparameter\"\n",
    "            csv_file_wogridsearch = f\"{combination}-{base_filename}-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "            csv_file_one_hyperparameter = f\"{combination}-{base_filename}-{n_splits}-folds-Threshold-allKfold_one_hyperparameter.csv\"\n",
    "            \n",
    "            # Get full paths\n",
    "            full_csv_path_wogridsearch = os.path.join(models_results_dir, csv_file_wogridsearch)\n",
    "            full_csv_path_one_hyperparameter = os.path.join(models_results_dir, csv_file_one_hyperparameter)\n",
    "\n",
    "            # Extract the best results from both files\n",
    "            best_result_wogridsearch = extract_best_results(model_name, combination, fold_label, full_csv_path_wogridsearch)\n",
    "            best_result_one_hyperparameter = extract_best_results(model_name, combination, fold_label, full_csv_path_one_hyperparameter)\n",
    "\n",
    "            # Append results to respective lists\n",
    "            if best_result_wogridsearch:\n",
    "                best_results_wogridsearch.append(best_result_wogridsearch)\n",
    "            if best_result_one_hyperparameter:\n",
    "                best_results_one_hyperparameter.append(best_result_one_hyperparameter)\n",
    "\n",
    "    # Save the best results to CSV files\n",
    "    if best_results_wogridsearch:\n",
    "        best_results_df_wogridsearch = pd.DataFrame(best_results_wogridsearch)\n",
    "        output_file_wogridsearch = f\"{output_file_prefix}_wogridsearch.csv\"\n",
    "        best_results_df_wogridsearch.to_csv(output_file_wogridsearch, index=False)\n",
    "        print(f\"Best results for {combination} combination (wogridsearch) saved to: {output_file_wogridsearch}\")\n",
    "\n",
    "    if best_results_one_hyperparameter:\n",
    "        best_results_df_one_hyperparameter = pd.DataFrame(best_results_one_hyperparameter)\n",
    "        output_file_one_hyperparameter = f\"{output_file_prefix}_one_hyperparameter.csv\"\n",
    "        best_results_df_one_hyperparameter.to_csv(output_file_one_hyperparameter, index=False)\n",
    "        print(f\"Best results for {combination} combination (one_hyperparameter) saved to: {output_file_one_hyperparameter}\")\n",
    "    \n",
    "    # Print the best results as a table for both cases\n",
    "    if best_results_wogridsearch:\n",
    "        print(f\"\\nBest Results from All Models for {combination} Combination (wogridsearch):\")\n",
    "        print(best_results_df_wogridsearch.to_string(index=False))\n",
    "\n",
    "    if best_results_one_hyperparameter:\n",
    "        print(f\"\\nBest Results from All Models for {combination} Combination (one_hyperparameter):\")\n",
    "        print(best_results_df_one_hyperparameter.to_string(index=False))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Directories where the model result CSV files are stored for each combination\n",
    "    equal_results_dir = 'results/equal_flaky_nonflaky/'\n",
    "    larger_results_dir = 'results/larger_nonflaky/'\n",
    "\n",
    "    # Prefixes for the output CSV files\n",
    "    equal_output_prefix = \"best_results_equal_combination\"\n",
    "    larger_output_prefix = \"best_results_larger_combination\"\n",
    "\n",
    "    # Gather and save the best results for the equal combination\n",
    "    gather_best_results_for_combination(equal_results_dir, equal_output_prefix, \"equal\")\n",
    "\n",
    "    # Gather and save the best results for the larger combination\n",
    "    gather_best_results_for_combination(larger_results_dir, larger_output_prefix, \"larger\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb730b8",
   "metadata": {},
   "source": [
    "Compare with threhold imbalance\n",
    "Compare with threshold balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe051a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6163e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
