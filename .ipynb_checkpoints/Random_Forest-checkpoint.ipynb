{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eab9b6e-a03b-4173-855a-c334a520dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0, Recall: 0.8888888888888888, Accuracy: 0.9473684210526315, F1 Score: 0.9411764705882353\n",
      "1.0 0.8888888888888888 0.9473684210526315 0.9411764705882353\n",
      "Precision: 0.8, Recall: 0.8888888888888888, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8 0.8888888888888888 0.8421052631578947 0.8421052631578947\n",
      "Precision: 1.0, Recall: 0.9, Accuracy: 0.9473684210526315, F1 Score: 0.9473684210526315\n",
      "1.0 0.9 0.9473684210526315 0.9473684210526315\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "0.8888888888888888 0.8888888888888888 0.8947368421052632 0.8888888888888888\n",
      "Precision: 1.0, Recall: 0.8, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "1.0 0.8 0.8947368421052632 0.8888888888888888\n",
      "Precision: 0.8571428571428571, Recall: 0.6666666666666666, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "0.8571428571428571 0.6666666666666666 0.7894736842105263 0.75\n",
      "Precision: 0.7, Recall: 0.7, Accuracy: 0.6842105263157895, F1 Score: 0.7\n",
      "0.7 0.7 0.6842105263157895 0.7\n",
      "Precision: 0.875, Recall: 0.7, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.875 0.7 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "0.8888888888888888 0.8888888888888888 0.8947368421052632 0.8888888888888888\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8888888888888888 0.8 0.8421052631578947 0.8421052631578947\n",
      "Precision: 0.75, Recall: 1.0, Accuracy: 0.8421052631578947, F1 Score: 0.8571428571428571\n",
      "0.75 1.0 0.8421052631578947 0.8571428571428571\n",
      "Precision: 1.0, Recall: 0.7, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "1.0 0.7 0.8421052631578947 0.8235294117647058\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.9 0.9 0.8947368421052632 0.9\n",
      "Precision: 0.7272727272727273, Recall: 0.8888888888888888, Accuracy: 0.7894736842105263, F1 Score: 0.8\n",
      "0.7272727272727273 0.8888888888888888 0.7894736842105263 0.8\n",
      "Precision: 1.0, Recall: 0.6666666666666666, Accuracy: 0.8421052631578947, F1 Score: 0.8\n",
      "1.0 0.6666666666666666 0.8421052631578947 0.8\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.7777777777777778 0.7777777777777778 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.7142857142857143, Recall: 0.5555555555555556, Accuracy: 0.6842105263157895, F1 Score: 0.625\n",
      "0.7142857142857143 0.5555555555555556 0.6842105263157895 0.625\n",
      "Precision: 0.6666666666666666, Recall: 0.6666666666666666, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666666\n",
      "0.6666666666666666 0.6666666666666666 0.6842105263157895 0.6666666666666666\n",
      "Precision: 0.6666666666666666, Recall: 0.6666666666666666, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666666\n",
      "0.6666666666666666 0.6666666666666666 0.6842105263157895 0.6666666666666666\n",
      "Precision: 0.8, Recall: 0.8888888888888888, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8 0.8888888888888888 0.8421052631578947 0.8421052631578947\n",
      "Precision: 0.8333333333333334, Recall: 1.0, Accuracy: 0.8947368421052632, F1 Score: 0.9090909090909091\n",
      "0.8333333333333334 1.0 0.8947368421052632 0.9090909090909091\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.7777777777777778 0.7777777777777778 0.7894736842105263 0.7777777777777778\n",
      "Precision: 1.0, Recall: 0.6, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "1.0 0.6 0.7894736842105263 0.75\n",
      "Precision: 1.0, Recall: 0.8888888888888888, Accuracy: 0.9473684210526315, F1 Score: 0.9411764705882353\n",
      "1.0 0.8888888888888888 0.9473684210526315 0.9411764705882353\n",
      "Precision: 0.8571428571428571, Recall: 0.6666666666666666, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "0.8571428571428571 0.6666666666666666 0.7894736842105263 0.75\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "0.875 0.7777777777777778 0.8421052631578947 0.8235294117647058\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "0.875 0.7777777777777778 0.8421052631578947 0.8235294117647058\n",
      "Precision: 0.75, Recall: 0.6666666666666666, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.75 0.6666666666666666 0.7368421052631579 0.7058823529411765\n",
      "Precision: 1.0, Recall: 0.6666666666666666, Accuracy: 0.8421052631578947, F1 Score: 0.8\n",
      "1.0 0.6666666666666666 0.8421052631578947 0.8\n",
      "Precision: 0.625, Recall: 0.5555555555555556, Accuracy: 0.631578947368421, F1 Score: 0.5882352941176471\n",
      "0.625 0.5555555555555556 0.631578947368421 0.5882352941176471\n",
      "Results to be written: 100,gini,None,2,1,37.7,37.3,9.3,9.7,0.8498244348244348,0.7737037037037041,0.8175438596491227,0.8031770044540946,379617,0.16506482170278838,0.0017690951735816014\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8888888888888888 0.8 0.8421052631578947 0.8421052631578947\n",
      "Precision: 1.0, Recall: 0.7777777777777778, Accuracy: 0.8947368421052632, F1 Score: 0.875\n",
      "1.0 0.7777777777777778 0.8947368421052632 0.875\n",
      "Precision: 0.8571428571428571, Recall: 0.6, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.8571428571428571 0.6 0.7368421052631579 0.7058823529411765\n",
      "Precision: 0.75, Recall: 0.6666666666666666, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.75 0.6666666666666666 0.7368421052631579 0.7058823529411765\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.9 0.9 0.8947368421052632 0.9\n",
      "Precision: 0.8333333333333334, Recall: 0.5, Accuracy: 0.6842105263157895, F1 Score: 0.625\n",
      "0.8333333333333334 0.5 0.6842105263157895 0.625\n",
      "Precision: 0.7, Recall: 0.7777777777777778, Accuracy: 0.7368421052631579, F1 Score: 0.7368421052631579\n",
      "0.7 0.7777777777777778 0.7368421052631579 0.7368421052631579\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "0.8888888888888888 0.8888888888888888 0.8947368421052632 0.8888888888888888\n",
      "Precision: 0.6, Recall: 0.6, Accuracy: 0.5789473684210527, F1 Score: 0.6\n",
      "0.6 0.6 0.5789473684210527 0.6\n",
      "Precision: 0.7272727272727273, Recall: 0.8888888888888888, Accuracy: 0.7894736842105263, F1 Score: 0.8\n",
      "0.7272727272727273 0.8888888888888888 0.7894736842105263 0.8\n",
      "Precision: 1.0, Recall: 0.8, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "1.0 0.8 0.8947368421052632 0.8888888888888888\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8888888888888888 0.8 0.8421052631578947 0.8421052631578947\n",
      "Precision: 1.0, Recall: 0.5555555555555556, Accuracy: 0.7894736842105263, F1 Score: 0.7142857142857143\n",
      "1.0 0.5555555555555556 0.7894736842105263 0.7142857142857143\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.7777777777777778 0.7777777777777778 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.9, Recall: 1.0, Accuracy: 0.9473684210526315, F1 Score: 0.9473684210526315\n",
      "0.9 1.0 0.9473684210526315 0.9473684210526315\n",
      "Precision: 0.8, Recall: 0.8, Accuracy: 0.7894736842105263, F1 Score: 0.8\n",
      "0.8 0.8 0.7894736842105263 0.8\n",
      "Precision: 1.0, Recall: 0.4444444444444444, Accuracy: 0.7368421052631579, F1 Score: 0.6153846153846154\n",
      "1.0 0.4444444444444444 0.7368421052631579 0.6153846153846154\n",
      "Precision: 0.8, Recall: 0.8888888888888888, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8 0.8888888888888888 0.8421052631578947 0.8421052631578947\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.7777777777777778 0.7777777777777778 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.9 0.9 0.8947368421052632 0.9\n",
      "Precision: 0.6666666666666666, Recall: 0.6666666666666666, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666666\n",
      "0.6666666666666666 0.6666666666666666 0.6842105263157895 0.6666666666666666\n",
      "Precision: 0.75, Recall: 1.0, Accuracy: 0.8421052631578947, F1 Score: 0.8571428571428571\n",
      "0.75 1.0 0.8421052631578947 0.8571428571428571\n",
      "Precision: 0.8, Recall: 0.8888888888888888, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8 0.8888888888888888 0.8421052631578947 0.8421052631578947\n",
      "Precision: 1.0, Recall: 0.6, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "1.0 0.6 0.7894736842105263 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8571428571428571, Recall: 0.6, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.8571428571428571 0.6 0.7368421052631579 0.7058823529411765\n",
      "Precision: 0.6666666666666666, Recall: 0.6666666666666666, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666666\n",
      "0.6666666666666666 0.6666666666666666 0.6842105263157895 0.6666666666666666\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "0.875 0.7777777777777778 0.8421052631578947 0.8235294117647058\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "0.875 0.7777777777777778 0.8421052631578947 0.8235294117647058\n",
      "Precision: 0.9, Recall: 1.0, Accuracy: 0.9473684210526315, F1 Score: 0.9473684210526315\n",
      "0.9 1.0 0.9473684210526315 0.9473684210526315\n",
      "Precision: 0.8333333333333334, Recall: 0.5555555555555556, Accuracy: 0.7368421052631579, F1 Score: 0.6666666666666666\n",
      "0.8333333333333334 0.5555555555555556 0.7368421052631579 0.6666666666666666\n",
      "Results to be written: 100,gini,None,2,2,37.63333333333333,37.36666666666667,9.366666666666667,9.633333333333333,0.8404593554593555,0.7559259259259263,0.8017543859649121,0.7844950800833155,379617,0.1645769180850974,0.0017617050130609466\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.9 0.9 0.8947368421052632 0.9\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8888888888888888 0.8 0.8421052631578947 0.8421052631578947\n",
      "Precision: 0.7272727272727273, Recall: 0.8888888888888888, Accuracy: 0.7894736842105263, F1 Score: 0.8\n",
      "0.7272727272727273 0.8888888888888888 0.7894736842105263 0.8\n",
      "Precision: 0.8333333333333334, Recall: 1.0, Accuracy: 0.8947368421052632, F1 Score: 0.9090909090909091\n",
      "0.8333333333333334 1.0 0.8947368421052632 0.9090909090909091\n",
      "Precision: 1.0, Recall: 1.0, Accuracy: 1.0, F1 Score: 1.0\n",
      "1.0 1.0 1.0 1.0\n",
      "Precision: 1.0, Recall: 0.8, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "1.0 0.8 0.8947368421052632 0.8888888888888888\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "0.8888888888888888 0.8888888888888888 0.8947368421052632 0.8888888888888888\n",
      "Precision: 1.0, Recall: 0.7777777777777778, Accuracy: 0.8947368421052632, F1 Score: 0.875\n",
      "1.0 0.7777777777777778 0.8947368421052632 0.875\n",
      "Precision: 0.6666666666666666, Recall: 0.6666666666666666, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666666\n",
      "0.6666666666666666 0.6666666666666666 0.6842105263157895 0.6666666666666666\n",
      "Precision: 1.0, Recall: 0.6, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "1.0 0.6 0.7894736842105263 0.75\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.9 0.9 0.8947368421052632 0.9\n",
      "Precision: 0.8181818181818182, Recall: 1.0, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.8181818181818182 1.0 0.8947368421052632 0.9\n",
      "Precision: 0.75, Recall: 0.6666666666666666, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.75 0.6666666666666666 0.7368421052631579 0.7058823529411765\n",
      "Precision: 0.75, Recall: 0.6666666666666666, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.75 0.6666666666666666 0.7368421052631579 0.7058823529411765\n",
      "Precision: 0.8333333333333334, Recall: 1.0, Accuracy: 0.8947368421052632, F1 Score: 0.9090909090909091\n",
      "0.8333333333333334 1.0 0.8947368421052632 0.9090909090909091\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.9 0.9 0.8947368421052632 0.9\n",
      "Precision: 1.0, Recall: 0.6, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "1.0 0.6 0.7894736842105263 0.75\n",
      "Precision: 0.75, Recall: 1.0, Accuracy: 0.8421052631578947, F1 Score: 0.8571428571428571\n",
      "0.75 1.0 0.8421052631578947 0.8571428571428571\n",
      "Precision: 0.875, Recall: 0.7, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.875 0.7 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8888888888888888 0.8 0.8421052631578947 0.8421052631578947\n",
      "Precision: 0.8, Recall: 0.8, Accuracy: 0.7894736842105263, F1 Score: 0.8\n",
      "0.8 0.8 0.7894736842105263 0.8\n",
      "Precision: 0.7, Recall: 0.7777777777777778, Accuracy: 0.7368421052631579, F1 Score: 0.7368421052631579\n",
      "0.7 0.7777777777777778 0.7368421052631579 0.7368421052631579\n",
      "Precision: 0.7777777777777778, Recall: 0.7, Accuracy: 0.7368421052631579, F1 Score: 0.7368421052631579\n",
      "0.7777777777777778 0.7 0.7368421052631579 0.7368421052631579\n",
      "Precision: 0.8181818181818182, Recall: 1.0, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.8181818181818182 1.0 0.8947368421052632 0.9\n",
      "Precision: 1.0, Recall: 0.7, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "1.0 0.7 0.8421052631578947 0.8235294117647058\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.9 0.9 0.8947368421052632 0.9\n",
      "Precision: 1.0, Recall: 0.8, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "1.0 0.8 0.8947368421052632 0.8888888888888888\n",
      "Precision: 1.0, Recall: 0.7, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "1.0 0.7 0.8421052631578947 0.8235294117647058\n",
      "Precision: 1.0, Recall: 0.8888888888888888, Accuracy: 0.9473684210526315, F1 Score: 0.9411764705882353\n",
      "1.0 0.8888888888888888 0.9473684210526315 0.9411764705882353\n",
      "Precision: 0.8571428571428571, Recall: 0.6666666666666666, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "0.8571428571428571 0.6666666666666666 0.7894736842105263 0.75\n",
      "Results to be written: 100,gini,None,5,1,37.4,37.6,9.6,9.4,0.8741185666185667,0.8162962962962962,0.8421052631578948,0.8356443507759297,379617,0.16659172758829816,0.001863328898846741\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "0.8888888888888888 0.8888888888888888 0.8947368421052632 0.8888888888888888\n",
      "Precision: 1.0, Recall: 0.7777777777777778, Accuracy: 0.8947368421052632, F1 Score: 0.875\n",
      "1.0 0.7777777777777778 0.8947368421052632 0.875\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "0.875 0.7777777777777778 0.8421052631578947 0.8235294117647058\n",
      "Precision: 0.8, Recall: 0.8, Accuracy: 0.7894736842105263, F1 Score: 0.8\n",
      "0.8 0.8 0.7894736842105263 0.8\n",
      "Precision: 0.6, Recall: 0.6666666666666666, Accuracy: 0.631578947368421, F1 Score: 0.631578947368421\n",
      "0.6 0.6666666666666666 0.631578947368421 0.631578947368421\n",
      "Precision: 0.9090909090909091, Recall: 1.0, Accuracy: 0.9473684210526315, F1 Score: 0.9523809523809523\n",
      "0.9090909090909091 1.0 0.9473684210526315 0.9523809523809523\n",
      "Precision: 0.8181818181818182, Recall: 0.9, Accuracy: 0.8421052631578947, F1 Score: 0.8571428571428571\n",
      "0.8181818181818182 0.9 0.8421052631578947 0.8571428571428571\n",
      "Precision: 0.6, Recall: 0.6, Accuracy: 0.5789473684210527, F1 Score: 0.6\n",
      "0.6 0.6 0.5789473684210527 0.6\n",
      "Precision: 1.0, Recall: 0.5, Accuracy: 0.7368421052631579, F1 Score: 0.6666666666666666\n",
      "1.0 0.5 0.7368421052631579 0.6666666666666666\n",
      "Precision: 0.8181818181818182, Recall: 0.9, Accuracy: 0.8421052631578947, F1 Score: 0.8571428571428571\n",
      "0.8181818181818182 0.9 0.8421052631578947 0.8571428571428571\n",
      "Precision: 0.7692307692307693, Recall: 1.0, Accuracy: 0.8421052631578947, F1 Score: 0.8695652173913043\n",
      "0.7692307692307693 1.0 0.8421052631578947 0.8695652173913043\n",
      "Precision: 0.6363636363636364, Recall: 0.7, Accuracy: 0.631578947368421, F1 Score: 0.6666666666666666\n",
      "0.6363636363636364 0.7 0.631578947368421 0.6666666666666666\n",
      "Precision: 0.875, Recall: 0.7, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.875 0.7 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.7, Recall: 0.7777777777777778, Accuracy: 0.7368421052631579, F1 Score: 0.7368421052631579\n",
      "0.7 0.7777777777777778 0.7368421052631579 0.7368421052631579\n",
      "Precision: 0.75, Recall: 0.6666666666666666, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.75 0.6666666666666666 0.7368421052631579 0.7058823529411765\n",
      "Precision: 1.0, Recall: 0.6666666666666666, Accuracy: 0.8421052631578947, F1 Score: 0.8\n",
      "1.0 0.6666666666666666 0.8421052631578947 0.8\n",
      "Precision: 0.7692307692307693, Recall: 1.0, Accuracy: 0.8421052631578947, F1 Score: 0.8695652173913043\n",
      "0.7692307692307693 1.0 0.8421052631578947 0.8695652173913043\n",
      "Precision: 0.75, Recall: 0.6666666666666666, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.75 0.6666666666666666 0.7368421052631579 0.7058823529411765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.7777777777777778 0.7777777777777778 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.7777777777777778, Recall: 0.7, Accuracy: 0.7368421052631579, F1 Score: 0.7368421052631579\n",
      "0.7777777777777778 0.7 0.7368421052631579 0.7368421052631579\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "0.8888888888888888 0.8888888888888888 0.8947368421052632 0.8888888888888888\n",
      "Precision: 1.0, Recall: 0.6666666666666666, Accuracy: 0.8421052631578947, F1 Score: 0.8\n",
      "1.0 0.6666666666666666 0.8421052631578947 0.8\n",
      "Precision: 1.0, Recall: 1.0, Accuracy: 1.0, F1 Score: 1.0\n",
      "1.0 1.0 1.0 1.0\n",
      "Precision: 1.0, Recall: 0.7777777777777778, Accuracy: 0.8947368421052632, F1 Score: 0.875\n",
      "1.0 0.7777777777777778 0.8947368421052632 0.875\n",
      "Precision: 0.75, Recall: 0.6666666666666666, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.75 0.6666666666666666 0.7368421052631579 0.7058823529411765\n",
      "Precision: 0.6153846153846154, Recall: 0.8888888888888888, Accuracy: 0.6842105263157895, F1 Score: 0.7272727272727273\n",
      "0.6153846153846154 0.8888888888888888 0.6842105263157895 0.7272727272727273\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8888888888888888 0.8 0.8421052631578947 0.8421052631578947\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.9 0.9 0.8947368421052632 0.9\n",
      "Precision: 0.875, Recall: 0.7, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.875 0.7 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.7142857142857143, Recall: 0.5, Accuracy: 0.631578947368421, F1 Score: 0.5882352941176471\n",
      "0.7142857142857143 0.5 0.631578947368421 0.5882352941176471\n",
      "Results to be written: 100,gini,None,5,2,37.5,37.5,9.5,9.5,0.8249057424057425,0.7751851851851852,0.7964912280701754,0.790143148630832,379617,0.17639212709255583,0.001914644188135206\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "0.8888888888888888 0.8888888888888888 0.8947368421052632 0.8888888888888888\n",
      "Precision: 1.0, Recall: 0.7, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "1.0 0.7 0.8421052631578947 0.8235294117647058\n",
      "Precision: 0.7777777777777778, Recall: 0.7, Accuracy: 0.7368421052631579, F1 Score: 0.7368421052631579\n",
      "0.7777777777777778 0.7 0.7368421052631579 0.7368421052631579\n",
      "Precision: 1.0, Recall: 0.5555555555555556, Accuracy: 0.7894736842105263, F1 Score: 0.7142857142857143\n",
      "1.0 0.5555555555555556 0.7894736842105263 0.7142857142857143\n",
      "Precision: 0.8, Recall: 0.8, Accuracy: 0.7894736842105263, F1 Score: 0.8\n",
      "0.8 0.8 0.7894736842105263 0.8\n",
      "Precision: 1.0, Recall: 0.6, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "1.0 0.6 0.7894736842105263 0.75\n",
      "Precision: 0.8333333333333334, Recall: 0.5555555555555556, Accuracy: 0.7368421052631579, F1 Score: 0.6666666666666666\n",
      "0.8333333333333334 0.5555555555555556 0.7368421052631579 0.6666666666666666\n",
      "Precision: 0.75, Recall: 0.6666666666666666, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.75 0.6666666666666666 0.7368421052631579 0.7058823529411765\n",
      "Precision: 0.75, Recall: 0.6, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666666\n",
      "0.75 0.6 0.6842105263157895 0.6666666666666666\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.9 0.9 0.8947368421052632 0.9\n",
      "Precision: 0.7272727272727273, Recall: 0.8, Accuracy: 0.7368421052631579, F1 Score: 0.7619047619047619\n",
      "0.7272727272727273 0.8 0.7368421052631579 0.7619047619047619\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.7777777777777778 0.7777777777777778 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.7777777777777778 0.7777777777777778 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.8181818181818182, Recall: 1.0, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "0.8181818181818182 1.0 0.8947368421052632 0.9\n",
      "Precision: 0.5833333333333334, Recall: 0.7777777777777778, Accuracy: 0.631578947368421, F1 Score: 0.6666666666666666\n",
      "0.5833333333333334 0.7777777777777778 0.631578947368421 0.6666666666666666\n",
      "Precision: 0.75, Recall: 0.6, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666666\n",
      "0.75 0.6 0.6842105263157895 0.6666666666666666\n",
      "Precision: 0.8333333333333334, Recall: 1.0, Accuracy: 0.8947368421052632, F1 Score: 0.9090909090909091\n",
      "0.8333333333333334 1.0 0.8947368421052632 0.9090909090909091\n",
      "Precision: 0.7, Recall: 0.7777777777777778, Accuracy: 0.7368421052631579, F1 Score: 0.7368421052631579\n",
      "0.7 0.7777777777777778 0.7368421052631579 0.7368421052631579\n",
      "Precision: 0.875, Recall: 0.7, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.875 0.7 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.8571428571428571, Recall: 0.6666666666666666, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "0.8571428571428571 0.6666666666666666 0.7894736842105263 0.75\n",
      "Precision: 1.0, Recall: 0.7777777777777778, Accuracy: 0.8947368421052632, F1 Score: 0.875\n",
      "1.0 0.7777777777777778 0.8947368421052632 0.875\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "0.7777777777777778 0.7777777777777778 0.7894736842105263 0.7777777777777778\n",
      "Precision: 0.8181818181818182, Recall: 0.9, Accuracy: 0.8421052631578947, F1 Score: 0.8571428571428571\n",
      "0.8181818181818182 0.9 0.8421052631578947 0.8571428571428571\n",
      "Precision: 0.75, Recall: 0.6666666666666666, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411765\n",
      "0.75 0.6666666666666666 0.7368421052631579 0.7058823529411765\n",
      "Precision: 0.6363636363636364, Recall: 0.7777777777777778, Accuracy: 0.6842105263157895, F1 Score: 0.7\n",
      "0.6363636363636364 0.7777777777777778 0.6842105263157895 0.7\n",
      "Precision: 0.75, Recall: 1.0, Accuracy: 0.8421052631578947, F1 Score: 0.8571428571428571\n",
      "0.75 1.0 0.8421052631578947 0.8571428571428571\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578947\n",
      "0.8888888888888888 0.8 0.8421052631578947 0.8421052631578947\n",
      "Precision: 0.6, Recall: 0.6666666666666666, Accuracy: 0.631578947368421, F1 Score: 0.631578947368421\n",
      "0.6 0.6666666666666666 0.631578947368421 0.631578947368421\n",
      "Precision: 0.7272727272727273, Recall: 0.8, Accuracy: 0.7368421052631579, F1 Score: 0.7619047619047619\n",
      "0.7272727272727273 0.8 0.7368421052631579 0.7619047619047619\n",
      "Precision: 1.0, Recall: 0.5555555555555556, Accuracy: 0.7894736842105263, F1 Score: 0.7142857142857143\n",
      "1.0 0.5555555555555556 0.7894736842105263 0.7142857142857143\n",
      "Results to be written: 100,gini,10,2,1,37.56666666666667,37.43333333333333,9.433333333333334,9.566666666666666,0.8116101491101492,0.7522222222222225,0.7807017543859648,0.7700028927041312,379617,0.16507112361708334,0.0017745087569988425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5780 (_handle_results):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 595, in _handle_results\n",
      "    cache[job]._set(i, obj)\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 779, in _set\n",
      "    self._callback(self._value)\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 385, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 834, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 252, in apply_async\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 458, in apply_async\n",
      "    self._check_running()\n",
      "  File \"C:\\Users\\haha9\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 353, in _check_running\n",
      "    raise ValueError(\"Pool not running\")\n",
      "ValueError: Pool not running\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0, Recall: 0.8, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "1.0 0.8 0.8947368421052632 0.8888888888888888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 212\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m combinations:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 212\u001b[0m         results \u001b[38;5;241m=\u001b[39m randomForest(outDir, extractDir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojectName\u001b[39m\u001b[38;5;124m\"\u001b[39m, kf, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;66;03m# Flatten the results tuple and write to CSV\u001b[39;00m\n\u001b[0;32m    215\u001b[0m         results_flat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, results))\n",
      "Cell \u001b[1;32mIn[2], line 144\u001b[0m, in \u001b[0;36mrandomForest\u001b[1;34m(outDir, projectBasePath, projectName, kf, dim, eps, params)\u001b[0m\n\u001b[0;32m    141\u001b[0m nSamplesTestData, nxTest, nyTest \u001b[38;5;241m=\u001b[39m testData\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    142\u001b[0m testData \u001b[38;5;241m=\u001b[39m testData\u001b[38;5;241m.\u001b[39mreshape((nSamplesTestData, nxTest \u001b[38;5;241m*\u001b[39m nyTest))\n\u001b[1;32m--> 144\u001b[0m trainTime, testTime, predictLabels \u001b[38;5;241m=\u001b[39m classificationRandomForest(trainData, trainLabels, testData, params)\n\u001b[0;32m    145\u001b[0m preparationTime \u001b[38;5;241m=\u001b[39m (vecTime \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(trainData) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataPoints)) \u001b[38;5;241m+\u001b[39m trainTime\n\u001b[0;32m    146\u001b[0m predictionTime \u001b[38;5;241m=\u001b[39m (vecTime \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataPoints)) \u001b[38;5;241m+\u001b[39m (testTime \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(testData))\n",
      "Cell \u001b[1;32mIn[2], line 92\u001b[0m, in \u001b[0;36mclassificationRandomForest\u001b[1;34m(trainData, trainLabels, testData, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m trainTime \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[0;32m     91\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m---> 92\u001b[0m predictLabels \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(testData)\n\u001b[0;32m     93\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     94\u001b[0m testTime \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:905\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    885\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 905\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:958\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    953\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    954\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[0;32m    956\u001b[0m ]\n\u001b[0;32m    957\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m--> 958\u001b[0m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, require\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msharedmem\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[0;32m    959\u001b[0m     delayed(_accumulate_prediction)(e\u001b[38;5;241m.\u001b[39mpredict_proba, X, all_proba, lock)\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\n\u001b[0;32m    961\u001b[0m )\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[0;32m    964\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:971\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by default hence\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# the use of the lock\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 971\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from itertools import product\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "###############################################################################\n",
    "# read data from file\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "\n",
    "def computeResults(testLabels, predictLabels):\n",
    "    try:\n",
    "        precision = precision_score(testLabels, predictLabels)\n",
    "        recall = recall_score(testLabels, predictLabels)\n",
    "        accuracy = accuracy_score(testLabels, predictLabels)\n",
    "        f1 = f1_score(testLabels, predictLabels)\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, Accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing metrics: {e}\")\n",
    "        precision = recall = accuracy = f1 = \"-\"\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "###############################################################################\n",
    "# FLAST\n",
    "\n",
    "def vectorization(dataPoints, dim=0, eps=0.3):\n",
    "    countVec = CountVectorizer()\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "def classificationRandomForest(trainData, trainLabels, testData, params):\n",
    "    # training\n",
    "    t0 = time.perf_counter()\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=params.get(\"n_estimators\", 100),\n",
    "        criterion=params.get(\"criterion\", \"gini\"),\n",
    "        max_depth=params.get(\"max_depth\"),\n",
    "        min_samples_split=params.get(\"min_samples_split\", 2),\n",
    "        min_samples_leaf=params.get(\"min_samples_leaf\", 1),\n",
    "        n_jobs=params.get(\"n_jobs\", -1),\n",
    "        random_state=params.get(\"random_state\", 42)\n",
    "    )\n",
    "    clf.fit(trainData, trainLabels)\n",
    "    t1 = time.perf_counter()\n",
    "    trainTime = t1 - t0\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    predictLabels = clf.predict(testData)\n",
    "    t1 = time.perf_counter()\n",
    "    testTime = t1 - t0\n",
    "\n",
    "    return trainTime, testTime, predictLabels\n",
    "\n",
    "def randomForest(outDir, projectBasePath, projectName, kf, dim, eps, params):\n",
    "    v0 = time.perf_counter()\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "    print(\"Data points before vectorization:\",len(dataPoints))\n",
    "    Z = vectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataPointsList = np.array([Z[i].toarray() for i in range(Z.shape[0])])\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    v1 = time.perf_counter()\n",
    "    vecTime = v1 - v0\n",
    "\n",
    "    # storage\n",
    "    randomForest = (dataPointsList, dataLabelsList)\n",
    "    pickleDumpRandomForest = os.path.join(outDir, \"random-forest.pickle\")\n",
    "    with open(pickleDumpRandomForest, \"wb\") as pickleFile:\n",
    "        pickle.dump(randomForest, pickleFile)\n",
    "    storage = os.path.getsize(pickleDumpRandomForest)\n",
    "    os.remove(pickleDumpRandomForest)\n",
    "\n",
    "    avgP, avgR, avgAccuracy, avgF1 = 0, 0, 0, 0  # Add avgF1\n",
    "    avgTPrep, avgTPred = 0, 0\n",
    "    avgFlakyTrain, avgNonFlakyTrain, avgFlakyTest, avgNonFlakyTest = 0, 0, 0, 0\n",
    "    successFold, precisionFold = 0, 0\n",
    "    for (trnIdx, tstIdx) in kf.split(dataPointsList, dataLabelsList):\n",
    "        trainData, testData = dataPointsList[trnIdx], dataPointsList[tstIdx]\n",
    "        trainLabels, testLabels = dataLabelsList[trnIdx], dataLabelsList[tstIdx]\n",
    "        if sum(trainLabels) == 0 or sum(testLabels) == 0:\n",
    "            print(\"Skipping fold...\")\n",
    "            print(\" Flaky Train Tests\", sum(trainLabels))\n",
    "            print(\" Flaky Test Tests\", sum(testLabels))\n",
    "            continue\n",
    "\n",
    "        successFold += 1\n",
    "        avgFlakyTrain += sum(trainLabels)\n",
    "        avgNonFlakyTrain += len(trainLabels) - sum(trainLabels)\n",
    "        avgFlakyTest += sum(testLabels)\n",
    "        avgNonFlakyTest += len(testLabels) - sum(testLabels)\n",
    "\n",
    "        # prepare the data in the right format for Random Forest\n",
    "        nSamplesTrainData, nxTrain, nyTrain = trainData.shape\n",
    "        trainData = trainData.reshape((nSamplesTrainData, nxTrain * nyTrain))\n",
    "        nSamplesTestData, nxTest, nyTest = testData.shape\n",
    "        testData = testData.reshape((nSamplesTestData, nxTest * nyTest))\n",
    "\n",
    "        trainTime, testTime, predictLabels = classificationRandomForest(trainData, trainLabels, testData, params)\n",
    "        preparationTime = (vecTime * len(trainData) / len(dataPoints)) + trainTime\n",
    "        predictionTime = (vecTime / len(dataPoints)) + (testTime / len(testData))\n",
    "        precision, recall, accuracy, f1 = computeResults(testLabels, predictLabels)\n",
    "\n",
    "        print(precision, recall, accuracy, f1)  # Add F1 score to print statement\n",
    "        if precision != \"-\":\n",
    "            precisionFold += 1\n",
    "            avgP += precision\n",
    "            avgF1 += f1  # Aggregate F1 score\n",
    "        avgR += recall\n",
    "        avgAccuracy += accuracy\n",
    "        avgTPrep += preparationTime\n",
    "        avgTPred += predictionTime\n",
    "\n",
    "    if precisionFold == 0:\n",
    "        avgP = avgF1 = \"-\"  # Adjust for F1\n",
    "    else:\n",
    "        avgP /= precisionFold\n",
    "        avgF1 /= precisionFold  # Average F1 score\n",
    "    avgR /= successFold\n",
    "    avgAccuracy /= successFold\n",
    "    avgTPrep /= successFold\n",
    "    avgTPred /= successFold\n",
    "    avgFlakyTrain /= successFold\n",
    "    avgNonFlakyTrain /= successFold\n",
    "    avgFlakyTest /= successFold\n",
    "    avgNonFlakyTest /= successFold\n",
    "\n",
    "    return (avgFlakyTrain, avgNonFlakyTrain, avgFlakyTest, avgNonFlakyTest, avgP, avgR, avgAccuracy, avgF1, storage, avgTPrep, avgTPred)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters setup\n",
    "    flakyZip = \"cleaned_flaky_files.zip\"\n",
    "    nonFlakyZip = \"reduced_nonflaky_files.zip\"\n",
    "    extractDir = \"extracted\"\n",
    "    outDir = \"results_Random_Forest\"\n",
    "    os.makedirs(outDir, exist_ok=True)\n",
    "    os.makedirs(extractDir, exist_ok=True)\n",
    "\n",
    "    numSplit = 30\n",
    "    testSetSize = 0.2\n",
    "    kf = StratifiedShuffleSplit(n_splits=numSplit, test_size=testSetSize)\n",
    "\n",
    "    outFile = \"params-random-forest.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Updated the header to match the number of columns\n",
    "        fo.write(\"n_estimators,criterion,max_depth,min_samples_split,min_samples_leaf,avgFlakyTrain,avgNonFlakyTrain,avgFlakyTest,avgNonFlakyTest,precision,recall,accuracy,f1,storage,preparationTime,predictionTime\\n\")\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5],\n",
    "        \"min_samples_leaf\": [1, 2]\n",
    "    }\n",
    "\n",
    "    # Flatten the parameter grid into all possible combinations\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for params in combinations:\n",
    "        try:\n",
    "            results = randomForest(outDir, extractDir, \"projectName\", kf, dim=0, eps=0.3, params=params)\n",
    "            \n",
    "            # Flatten the results tuple and write to CSV\n",
    "            results_flat = ','.join(map(str, results))\n",
    "            print(f\"Results to be written: {params['n_estimators']},{params['criterion']},{params['max_depth']},{params['min_samples_split']},{params['min_samples_leaf']},{results_flat}\")\n",
    "            \n",
    "            with open(os.path.join(outDir, outFile), \"a\") as fo:\n",
    "                fo.write(f\"{params['n_estimators']},{params['criterion']},{params['max_depth']},{params['min_samples_split']},{params['min_samples_leaf']},{results_flat}\\n\")\n",
    "            \n",
    "            # Update the best parameters based on accuracy\n",
    "            avg_accuracy = results[6]  # Index of accuracy in the results tuple\n",
    "            if avg_accuracy > best_accuracy:\n",
    "                best_accuracy = avg_accuracy\n",
    "                best_params = params\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for params {params}: {e}\")\n",
    "\n",
    "    print(f\"Best hyperparameters found: {best_params} with accuracy: {best_accuracy}\")\n",
    "    print(\"Random Forest analysis completed. Results saved to:\", outFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3020bc-234a-4ef0-82be-224b4036852c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
