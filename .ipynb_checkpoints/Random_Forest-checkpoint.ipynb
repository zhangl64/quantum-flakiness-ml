{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eab9b6e-a03b-4173-855a-c334a520dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR3307_0a45dea238c813ade4e9421a553f86f1bbe5d068_qiskit_pulse_reschedule.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR3307_0a45dea238c813ade4e9421a553f86f1bbe5d068_test_python_pulse_test_reschedule.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR3348_d3bf2374bbe5f2abdf19d97a078bb3bdcfe7a07a_qiskit_quantum_info_synthesis_one_qubit_decompose.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR3348_d3bf2374bbe5f2abdf19d97a078bb3bdcfe7a07a_qiskit_transpiler_passes_ms_basis_decomposer.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_dagcircuit__dagcircuit.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_barrier.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_ccx.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_ch.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_crz.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_cswap.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_cu1.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_cu3.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_cx.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_cxbase.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_cy.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_cz.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_h.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_iden.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_rx.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_ry.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_rz.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_s.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_swap.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_t.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit_extensions_standard_u0.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit__classicalregister.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit__instruction.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit__measure.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit__quantumcircuit.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit__quantumprogram.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit__quantumregister.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit__register.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit__reset.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR338_9364c2b98cfdda74993df973b030db9bb006477d_qiskit__result.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR3393_1996bc25401d5060e23dbc23f851fd980c8cdaaf_qiskit_converters_ast_to_dag.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR3393_1996bc25401d5060e23dbc23f851fd980c8cdaaf_test_python_circuit_test_circuit_load_from_qasm.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR3418_b9f2de9700a1f4cde0af2a78fc9949ca03de5825_qiskit_visualization_pulse_matplotlib.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR3450_3bbdf32289db063577825f28b4a82d4861272a1f_qiskit_pulse_timeslots.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR3495_12bbc237b64ce395dec92a6032e95d77334cc344_qiskit_visualization_counts_visualization.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR366_01e92859d53933b5125687a4d7dfc0434f8af956_qiskit_extensions_qiskit_simulator_noise.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_doc_conf.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_examples_python_ghz.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_examples_python_qft.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_examples_python_rippleadd-async.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_examples_python_rippleadd.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_examples_python_sympy_backends.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_examples_python_teleport.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit_backends_basebackend.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit_backends_baseprovider.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit_backends_ibmq_ibmqbackend.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit_backends_ibmq_ibmqprovider.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit_backends_local_localprovider.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit_backends_local_qasm_simulator_cpp.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit_backends_local___init__.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit__compiler.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit__jobprocessor.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit__quantumjob.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit__quantumprogram.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR435_298d42d1cc7ac0ebe7f0d8105d1271e61f95e7ca_qiskit__result.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR466_f0e3e406205e4792aaa4109023aa1b7fe9838caa_qiskit__result.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR466_f0e3e406205e4792aaa4109023aa1b7fe9838caa_test_python_test_unitary_simulator_py.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR603_1d76d534ccd92ca6be10f68c443fd0dd8ab0e195_test_python_common.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR781_09af5d7566345355d52454e7f3c5e1cc7da3cb16_qiskit_backends_ibmq_ibmqbackend.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR781_09af5d7566345355d52454e7f3c5e1cc7da3cb16_qiskit_backends_ibmq_ibmqjob.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR781_09af5d7566345355d52454e7f3c5e1cc7da3cb16_test_python_test_ibmqjob_states.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR781_09af5d7566345355d52454e7f3c5e1cc7da3cb16_test_python_test_quantumprogram.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR929_ce2fcfd32f8c3b6ee663c8a357df712d95ebea52_qiskit_transpiler__parallel.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR929_ce2fcfd32f8c3b6ee663c8a357df712d95ebea52_qiskit_transpiler___init__.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR929_ce2fcfd32f8c3b6ee663c8a357df712d95ebea52_test_python_test_parallel.txt\n",
      "Attempting to open file: dataset\\project\\nonflakyMethods\\Qiskit_qiskit_PR944_739e94c352bd8b47d9b1ab0b839e1e8da54147cf_test_python_test_qasm_simulator_cpp.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.6111111111111112\n",
      "1.0 0.4444444444444444\n",
      "1.0 0.5555555555555556\n",
      "0.9 0.5\n",
      "0.875 0.3888888888888889\n",
      "1.0 0.5\n",
      "1.0 0.4444444444444444\n",
      "1.0 0.6111111111111112\n",
      "1.0 0.5\n",
      "1.0 0.4444444444444444\n",
      "1.0 0.5555555555555556\n",
      "1.0 0.5555555555555556\n",
      "0.9 0.5\n",
      "1.0 0.3888888888888889\n",
      "1.0 0.7222222222222222\n",
      "1.0 0.5555555555555556\n",
      "1.0 0.5\n",
      "1.0 0.4444444444444444\n",
      "1.0 0.3888888888888889\n",
      "1.0 0.5555555555555556\n",
      "1.0 0.5\n",
      "0.8888888888888888 0.4444444444444444\n",
      "1.0 0.3888888888888889\n",
      "0.9 0.5\n",
      "0.8888888888888888 0.4444444444444444\n",
      "1.0 0.6666666666666666\n",
      "1.0 0.3333333333333333\n",
      "1.0 0.1111111111111111\n",
      "0.9 0.5\n",
      "1.0 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score, \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "###############################################################################\n",
    "# read data from file\n",
    "\n",
    "def getDataPoints(path):\n",
    "    dataPointsList = []\n",
    "    for dataPointName in os.listdir(path):\n",
    "        if dataPointName[0] == \".\":\n",
    "            continue\n",
    "        filePath = os.path.join(path, dataPointName)\n",
    "        print(f\"Attempting to open file: {filePath}\")\n",
    "        if not os.path.exists(filePath):\n",
    "            print(f\"File does not exist: {filePath}\")\n",
    "            continue\n",
    "        with open(filePath, encoding=\"utf-8\") as fileIn:\n",
    "            dp = fileIn.read()\n",
    "        dataPointsList.append(dp)\n",
    "    return dataPointsList\n",
    "\n",
    "def getDataPointsInfo(projectBasePath, projectName):\n",
    "    # get list of tokenized test methods\n",
    "    projectPath = os.path.join(projectBasePath, projectName)\n",
    "    flakyPath = os.path.join(projectPath, \"flakyMethods\")\n",
    "    nonFlakyPath = os.path.join(projectPath, \"nonflakyMethods\")  # Updated path\n",
    "    return getDataPoints(flakyPath), getDataPoints(nonFlakyPath)\n",
    "\n",
    "# Example usage\n",
    "projectBasePath = r\"dataset\"\n",
    "projectName = \"project\"  # Replace with the actual project name\n",
    "\n",
    "flakyMethods, nonFlakyMethods = getDataPointsInfo(projectBasePath, projectName)\n",
    "\n",
    "print(\"Flaky Methods:\")\n",
    "for method in flakyMethods:\n",
    "    print(method)\n",
    "\n",
    "print(\"\\nNon-Flaky Methods:\")\n",
    "for method in nonFlakyMethods:\n",
    "    print(method)\n",
    "\n",
    "###############################################################################\n",
    "# compute effectiveness metrics\n",
    "\n",
    "def computeResults(testLabels, predictLabels):\n",
    "    warnings.filterwarnings(\"error\")  # to catch warnings, e.g., \"prec set to 0.0\"\n",
    "    try:\n",
    "        precision = precision_score(testLabels, predictLabels)\n",
    "    except:\n",
    "        precision = \"-\"\n",
    "    try:\n",
    "        recall = recall_score(testLabels, predictLabels)\n",
    "    except:\n",
    "        recall = \"-\"\n",
    "    warnings.resetwarnings()  # warnings are no more errors\n",
    "    return precision, recall\n",
    "\n",
    "###############################################################################\n",
    "# FLAST\n",
    "\n",
    "def vectorization(dataPoints, dim=0, eps=0.3):\n",
    "    countVec = CountVectorizer()\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "def classificationRandomForest(trainData, trainLabels, testData, params):\n",
    "    # training\n",
    "    t0 = time.perf_counter()\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=params.get(\"n_estimators\", 100),\n",
    "        criterion=params.get(\"criterion\", \"gini\"),\n",
    "        max_depth=params.get(\"max_depth\"),\n",
    "        min_samples_split=params.get(\"min_samples_split\", 2),\n",
    "        min_samples_leaf=params.get(\"min_samples_leaf\", 1),\n",
    "        n_jobs=params.get(\"n_jobs\", -1),\n",
    "        random_state=params.get(\"random_state\", 42)\n",
    "    )\n",
    "    clf.fit(trainData, trainLabels)\n",
    "    t1 = time.perf_counter()\n",
    "    trainTime = t1 - t0\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    predictLabels = clf.predict(testData)\n",
    "    t1 = time.perf_counter()\n",
    "    testTime = t1 - t0\n",
    "\n",
    "    return trainTime, testTime, predictLabels\n",
    "\n",
    "def randomForest(outDir, projectBasePath, projectName, kf, dim, eps, params):\n",
    "    v0 = time.perf_counter()\n",
    "    dataPointsFlaky, dataPointsNonFlaky = getDataPointsInfo(projectBasePath, projectName)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "    Z = vectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataPointsList = np.array([Z[i].toarray() for i in range(Z.shape[0])])\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    v1 = time.perf_counter()\n",
    "    vecTime = v1 - v0\n",
    "\n",
    "    # storage\n",
    "    randomForest = (dataPointsList, dataLabelsList)\n",
    "    pickleDumpRandomForest = os.path.join(outDir, \"random-forest.pickle\")\n",
    "    with open(pickleDumpRandomForest, \"wb\") as pickleFile:\n",
    "        pickle.dump(randomForest, pickleFile)\n",
    "    storage = os.path.getsize(pickleDumpRandomForest)\n",
    "    os.remove(pickleDumpRandomForest)\n",
    "\n",
    "    avgP, avgR = 0, 0\n",
    "    avgTPrep, avgTPred = 0, 0\n",
    "    avgFlakyTrain, avgNonFlakyTrain, avgFlakyTest, avgNonFlakyTest = 0, 0, 0, 0\n",
    "    successFold, precisionFold = 0, 0\n",
    "    for (trnIdx, tstIdx) in kf.split(dataPointsList, dataLabelsList):\n",
    "        trainData, testData = dataPointsList[trnIdx], dataPointsList[tstIdx]\n",
    "        trainLabels, testLabels = dataLabelsList[trnIdx], dataLabelsList[tstIdx]\n",
    "        if sum(trainLabels) == 0 or sum(testLabels) == 0:\n",
    "            print(\"Skipping fold...\")\n",
    "            print(\" Flaky Train Tests\", sum(trainLabels))\n",
    "            print(\" Flaky Test Tests\", sum(testLabels))\n",
    "            continue\n",
    "\n",
    "        successFold += 1\n",
    "        avgFlakyTrain += sum(trainLabels)\n",
    "        avgNonFlakyTrain += len(trainLabels) - sum(trainLabels)\n",
    "        avgFlakyTest += sum(testLabels)\n",
    "        avgNonFlakyTest += len(testLabels) - sum(testLabels)\n",
    "\n",
    "        # prepare the data in the right format for Random Forest\n",
    "        nSamplesTrainData, nxTrain, nyTrain = trainData.shape\n",
    "        trainData = trainData.reshape((nSamplesTrainData, nxTrain * nyTrain))\n",
    "        nSamplesTestData, nxTest, nyTest = testData.shape\n",
    "        testData = testData.reshape((nSamplesTestData, nxTest * nyTest))\n",
    "\n",
    "        trainTime, testTime, predictLabels = classificationRandomForest(trainData, trainLabels, testData, params)\n",
    "        preparationTime = (vecTime * len(trainData) / len(dataPoints)) + trainTime\n",
    "        predictionTime = (vecTime / len(dataPoints)) + (testTime / len(testData))\n",
    "        (precision, recall) = computeResults(testLabels, predictLabels)\n",
    "\n",
    "        print(precision, recall)\n",
    "        if precision != \"-\":\n",
    "            precisionFold += 1\n",
    "            avgP += precision\n",
    "        avgR += recall\n",
    "        avgTPrep += preparationTime\n",
    "        avgTPred += predictionTime\n",
    "\n",
    "    if precisionFold == 0:\n",
    "        avgP = \"-\"\n",
    "    else:\n",
    "        avgP /= precisionFold\n",
    "    avgR /= successFold\n",
    "    avgTPrep /= successFold\n",
    "    avgTPred /= successFold\n",
    "    avgFlakyTrain /= successFold\n",
    "    avgNonFlakyTrain /= successFold\n",
    "    avgFlakyTest /= successFold\n",
    "    avgNonFlakyTest /= successFold\n",
    "\n",
    "    return (avgFlakyTrain, avgNonFlakyTrain, avgFlakyTest, avgNonFlakyTest, avgP, avgR, storage, avgTPrep, avgTPred)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    projectBasePath = \"dataset\"\n",
    "    projectList = [\n",
    "        \"project\"  # Replace with the actual project name\n",
    "    ]\n",
    "    outDir = \"results-RandomForest\"\n",
    "    outFile = \"result_Random_Forest.csv\"\n",
    "    os.makedirs(outDir, exist_ok=True)\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"dataset,flakyTrain,nonFlakyTrain,flakyTest,nonFlakyTest,precision,recall,storage,preparationTime,predictionTime\\n\")\n",
    "\n",
    "    numSplit = 30\n",
    "    testSetSize = 0.2\n",
    "    kf = StratifiedShuffleSplit(n_splits=numSplit, test_size=testSetSize)\n",
    "\n",
    "    # FLAST\n",
    "    dim = 0  # number of dimensions (0: JL with error eps)\n",
    "    eps = 0.3  # JL eps\n",
    "    params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"criterion\": \"gini\",\n",
    "        \"max_depth\": None,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    for projectName in projectList:\n",
    "        print(projectName.upper(), \"FLAST\")\n",
    "        (flakyTrain, nonFlakyTrain, flakyTest, nonFlakyTest, avgP, avgR, storage, avgTPrep, avgTPred) = randomForest(outDir, projectBasePath, projectName, kf, dim, eps, params)\n",
    "        with open(os.path.join(outDir, outFile), \"a\") as fo:\n",
    "            fo.write(\"{},{},{},{},{},{},{},{},{},{}\\n\".format(projectName, flakyTrain, nonFlakyTrain, flakyTest, nonFlakyTest, avgP, avgR, storage, avgTPrep, avgTPred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3020bc-234a-4ef0-82be-224b4036852c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
