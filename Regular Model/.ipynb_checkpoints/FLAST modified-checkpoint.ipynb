{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a42537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents (equal combination): 45\n",
      "Number of non-flaky documents (equal combination): 47\n",
      "Total number of documents (equal combination): 92\n",
      "Number of flaky documents (larger combination): 45\n",
      "Number of non-flaky documents (larger combination): 254\n",
      "Total number of documents (larger combination): 299\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints):\n",
    "    \"\"\"Performs vectorization using CountVectorizer.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z = countVec.fit_transform(dataPoints)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Data Extraction and Vectorization\n",
    "\n",
    "# Parameters setup\n",
    "flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "# Create directories\n",
    "outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "outDirLarger = \"results/larger_nonflaky/\"\n",
    "os.makedirs(outDirEqual, exist_ok=True)\n",
    "os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "os.makedirs(extractDirEqual, exist_ok=True)\n",
    "os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "# Extract and read data once for equal combination\n",
    "flakyDirEqual = os.path.join(extractDirEqual, 'flaky')\n",
    "nonFlakyDirEqual = os.path.join(extractDirEqual, 'nonFlaky')\n",
    "os.makedirs(flakyDirEqual, exist_ok=True)\n",
    "os.makedirs(nonFlakyDirEqual, exist_ok=True)\n",
    "\n",
    "extract_zip(flakyZip, flakyDirEqual)\n",
    "extract_zip(nonFlakyZip, nonFlakyDirEqual)\n",
    "\n",
    "dataPointsFlakyEqual = getDataPoints(flakyDirEqual)\n",
    "dataPointsNonFlakyEqual = getDataPoints(nonFlakyDirEqual)\n",
    "dataPointsEqual = dataPointsFlakyEqual + dataPointsNonFlakyEqual\n",
    "\n",
    "# Print the number of datasets for equal combination\n",
    "print(f\"Number of flaky documents (equal combination): {len(dataPointsFlakyEqual)}\")\n",
    "print(f\"Number of non-flaky documents (equal combination): {len(dataPointsNonFlakyEqual)}\")\n",
    "print(f\"Total number of documents (equal combination): {len(dataPointsEqual)}\")\n",
    "\n",
    "dataLabelsListEqual = np.array([1]*len(dataPointsFlakyEqual) + [0]*len(dataPointsNonFlakyEqual))\n",
    "\n",
    "# Vectorize data once\n",
    "Z_equal = flastVectorization(dataPointsEqual)\n",
    "\n",
    "# Extract and read data once for larger non-flaky combination\n",
    "flakyDirLarger = os.path.join(extractDirLarger, 'flaky')\n",
    "nonFlakyDirLarger = os.path.join(extractDirLarger, 'nonFlaky')\n",
    "os.makedirs(flakyDirLarger, exist_ok=True)\n",
    "os.makedirs(nonFlakyDirLarger, exist_ok=True)\n",
    "\n",
    "extract_zip(flakyZip, flakyDirLarger)\n",
    "extract_zip(largerNonFlakyZip, nonFlakyDirLarger)\n",
    "\n",
    "dataPointsFlakyLarger = getDataPoints(flakyDirLarger)\n",
    "dataPointsNonFlakyLarger = getDataPoints(nonFlakyDirLarger)\n",
    "dataPointsLarger = dataPointsFlakyLarger + dataPointsNonFlakyLarger\n",
    "\n",
    "# Print the number of datasets for larger combination\n",
    "print(f\"Number of flaky documents (larger combination): {len(dataPointsFlakyLarger)}\")\n",
    "print(f\"Number of non-flaky documents (larger combination): {len(dataPointsNonFlakyLarger)}\")\n",
    "print(f\"Total number of documents (larger combination): {len(dataPointsLarger)}\")\n",
    "\n",
    "dataLabelsListLarger = np.array([1]*len(dataPointsFlakyLarger) + [0]*len(dataPointsNonFlakyLarger))\n",
    "\n",
    "Z_larger = flastVectorization(dataPointsLarger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304d035",
   "metadata": {},
   "source": [
    "## KNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "540d06d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting KNN analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.7811111111111111\n",
      "KNN analysis completed for 5-folds. Results saved to: equal-params-knn-5-folds.csv\n",
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Best F1 Score: 0.7119673436877738\n",
      "KNN analysis completed for 3-folds. Results saved to: equal-params-knn-3-folds.csv\n",
      "\n",
      "Best results for KNN 5-fold on equal combination:\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.7811111111111111\n",
      "\n",
      "Best results for KNN 3-fold on equal combination:\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Best F1 Score: 0.7119673436877738\n",
      "\n",
      "Starting KNN analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.5696886446886447\n",
      "KNN analysis completed for 5-folds. Results saved to: larger-params-knn-5-folds.csv\n",
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.5818070818070818\n",
      "KNN analysis completed for 3-folds. Results saved to: larger-params-knn-3-folds.csv\n",
      "\n",
      "Best results for KNN 5-fold on larger combination:\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.5696886446886447\n",
      "\n",
      "Best results for KNN 3-fold on larger combination:\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.5818070818070818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def runKNN(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "    \n",
    "    # Define the KNN model\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11, 15, 20],\n",
    "        'metric': ['cosine', 'euclidean'],  # Distance metrics\n",
    "        'weights': ['uniform', 'distance'],  # Neighbor weighting schemes\n",
    "    }\n",
    "\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),  \n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-knn-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"n_neighbors,metric,weights,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['n_neighbors']},{param['metric']},{param['weights']},{accuracy},{precision},{recall},{f1},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"KNN analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run KNN on equal combination\n",
    "print(\"\\nStarting KNN analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_knn_equal, best_score_5folds_knn_equal = runKNN(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_knn_equal, best_score_3folds_knn_equal = runKNN(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for KNN 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_knn_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_knn_equal}\")\n",
    "\n",
    "print(\"\\nBest results for KNN 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_knn_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_knn_equal}\")\n",
    "\n",
    "# Run KNN on larger non-flaky combination\n",
    "print(\"\\nStarting KNN analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_knn_larger, best_score_5folds_knn_larger = runKNN(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_knn_larger, best_score_3folds_knn_larger = runKNN(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for KNN 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_knn_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_knn_larger}\")\n",
    "\n",
    "print(\"\\nBest results for KNN 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_knn_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_knn_larger}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1a814",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# SVM with GridSearchCV\n",
    "\n",
    "def runSVM(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define the SVM model\n",
    "    svm = SVC()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization parameter\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # Kernel types\n",
    "    }\n",
    "\n",
    "    # Custom scoring functions (without MCC)\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-svm-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"C,kernel,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['C']},{param['kernel']},{accuracy},{precision},{recall},{f1},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"SVM analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4436c1",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba4000e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting SVM analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7786800334168754\n",
      "SVM analysis completed for 5-folds. Results saved to: equal-params-svm-5-folds.csv\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7776541836608577\n",
      "SVM analysis completed for 3-folds. Results saved to: equal-params-svm-3-folds.csv\n",
      "\n",
      "Best results for SVM 5-fold on equal combination:\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7786800334168754\n",
      "\n",
      "Best results for SVM 3-fold on equal combination:\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7776541836608577\n",
      "\n",
      "Starting SVM analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.6994444444444444\n",
      "SVM analysis completed for 5-folds. Results saved to: larger-params-svm-5-folds.csv\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.6067620650953984\n",
      "SVM analysis completed for 3-folds. Results saved to: larger-params-svm-3-folds.csv\n",
      "\n",
      "Best results for SVM 5-fold on larger combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.6994444444444444\n",
      "\n",
      "Best results for SVM 3-fold on larger combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.6067620650953984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def runSVM(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define the SVM model\n",
    "    svm = SVC()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization parameter\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # Kernel types\n",
    "    }\n",
    "\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-svm-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"C,kernel,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['C']},{param['kernel']},{accuracy},{precision},{recall},{f1},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"SVM analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run SVM on equal combination\n",
    "print(\"\\nStarting SVM analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_svm_equal, best_score_5folds_svm_equal = runSVM(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_svm_equal, best_score_3folds_svm_equal = runSVM(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_svm_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_svm_equal}\")\n",
    "\n",
    "print(\"\\nBest results for SVM 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_svm_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_svm_equal}\")\n",
    "\n",
    "# Run SVM on larger non-flaky combination\n",
    "print(\"\\nStarting SVM analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_svm_larger, best_score_5folds_svm_larger = runSVM(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_svm_larger, best_score_3folds_svm_larger = runSVM(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_svm_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_svm_larger}\")\n",
    "\n",
    "print(\"\\nBest results for SVM 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_svm_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_svm_larger}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2dd8f",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "554dd8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting NB analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7786800334168754\n",
      "SVM analysis completed for 5-folds. Results saved to: equal-params-svm-5-folds.csv\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7776541836608577\n",
      "SVM analysis completed for 3-folds. Results saved to: equal-params-svm-3-folds.csv\n",
      "\n",
      "Best results for SVM 5-fold on equal combination:\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7786800334168754\n",
      "\n",
      "Best results for SVM 3-fold on equal combination:\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7776541836608577\n",
      "\n",
      "Starting nb analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rp/h_pmxr992m143v567my_k4lm0000gn/T/ipykernel_26116/3536238448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Run SVM on larger non-flaky combination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting nb analysis for flaky vs larger non-flaky files (larger combination)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mbest_params_5folds_nb_larger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score_5folds_svm_larger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_larger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLabelsListLarger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutDirLarger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"larger\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mbest_params_3folds_nb_larger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score_3folds_svm_larger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_larger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLabelsListLarger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutDirLarger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"larger\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/rp/h_pmxr992m143v567my_k4lm0000gn/T/ipykernel_26116/2666059032.py\u001b[0m in \u001b[0;36mrunSVM\u001b[0;34m(Z, dataLabelsList, outDir, n_splits, combination_label)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Fit the GridSearchCV on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLabelsList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Get the best parameters and the best score for f1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    963\u001b[0m                     )\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibsvm_sparse_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row- and column-oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "def runNB(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define the NB model\n",
    "    nb = MultinomialNB()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0], \n",
    "    }\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(nb, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-nb-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"C,kernel,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['C']},{param['kernel']},{accuracy},{precision},{recall},{f1},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"Naive Bayes analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run NB on equal combination\n",
    "print(\"\\nStarting NB analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_nb_equal, best_score_5folds_nb_equal = runNB(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_nb_equal, best_score_3folds_nb_equal = runNB(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_nb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_nb_equal}\")\n",
    "\n",
    "print(\"\\nBest results for SVM 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_nb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_nb_equal}\")\n",
    "\n",
    "# Run SVM on larger non-flaky combination\n",
    "print(\"\\nStarting nb analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_nb_larger, best_score_5folds_svm_larger = runNB(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_nb_larger, best_score_3folds_svm_larger = runNB(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_nb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_nb_larger}\")\n",
    "\n",
    "print(\"\\nBest results for SVM 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_nb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_nb_larger}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665bed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
