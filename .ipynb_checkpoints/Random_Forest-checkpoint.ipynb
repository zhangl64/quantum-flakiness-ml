{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eab9b6e-a03b-4173-855a-c334a520dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points before vectorization: 94\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.6666666666666666, Recall: 0.6, Accuracy: 0.631578947368421, F1 Score: 0.631578947368421\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.75, Recall: 0.6, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666665\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.7142857142857143, Recall: 0.5555555555555556, Accuracy: 0.6842105263157895, F1 Score: 0.6250000000000001\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 1.0, Recall: 0.7, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 1.0, Recall: 0.7, Accuracy: 0.8421052631578947, F1 Score: 0.8235294117647058\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.75, Recall: 0.9, Accuracy: 0.7894736842105263, F1 Score: 0.8181818181818182\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.75, Recall: 0.9, Accuracy: 0.7894736842105263, F1 Score: 0.8181818181818182\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.7142857142857143, Recall: 0.5555555555555556, Accuracy: 0.6842105263157895, F1 Score: 0.6250000000000001\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.5714285714285714, Recall: 0.4444444444444444, Accuracy: 0.5789473684210527, F1 Score: 0.5\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.5714285714285714, Recall: 0.4444444444444444, Accuracy: 0.5789473684210527, F1 Score: 0.5\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.823529411764706\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.8571428571428571, Recall: 0.6666666666666666, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.823529411764706\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.823529411764706\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.8571428571428571, Recall: 0.6, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411764\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.875, Recall: 0.7, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777777\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Precision: 0.7272727272727273, Recall: 0.8, Accuracy: 0.7368421052631579, F1 Score: 0.761904761904762\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.7272727272727273, Recall: 0.8, Accuracy: 0.7368421052631579, F1 Score: 0.761904761904762\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.823529411764706\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Precision: 0.8571428571428571, Recall: 0.6666666666666666, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.9, Recall: 1.0, Accuracy: 0.9473684210526315, F1 Score: 0.9473684210526316\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.8, Recall: 0.8888888888888888, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578948\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578948\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.75, Recall: 0.6, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666665\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.8571428571428571, Recall: 0.6, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411764\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Precision: 0.7272727272727273, Recall: 0.8888888888888888, Accuracy: 0.7894736842105263, F1 Score: 0.7999999999999999\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.7272727272727273, Recall: 0.8888888888888888, Accuracy: 0.7894736842105263, F1 Score: 0.7999999999999999\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.7272727272727273, Recall: 0.8888888888888888, Accuracy: 0.7894736842105263, F1 Score: 0.7999999999999999\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.7, Recall: 0.7777777777777778, Accuracy: 0.7368421052631579, F1 Score: 0.7368421052631577\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.75, Recall: 0.9, Accuracy: 0.7894736842105263, F1 Score: 0.8181818181818182\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.7272727272727273, Recall: 0.8, Accuracy: 0.7368421052631579, F1 Score: 0.761904761904762\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.9, Recall: 0.9, Accuracy: 0.8947368421052632, F1 Score: 0.9\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578948\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.8, Recall: 0.8, Accuracy: 0.7894736842105263, F1 Score: 0.8000000000000002\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.75, Recall: 0.6, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666665\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.823529411764706\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.8571428571428571, Recall: 0.6666666666666666, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Precision: 0.6666666666666666, Recall: 0.8888888888888888, Accuracy: 0.7368421052631579, F1 Score: 0.761904761904762\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.75, Recall: 1.0, Accuracy: 0.8421052631578947, F1 Score: 0.8571428571428571\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.8571428571428571, Recall: 0.6666666666666666, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.8888888888888888, Recall: 0.8888888888888888, Accuracy: 0.8947368421052632, F1 Score: 0.8888888888888888\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Precision: 0.8571428571428571, Recall: 0.6, Accuracy: 0.7368421052631579, F1 Score: 0.7058823529411764\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 1.0, Recall: 0.6, Accuracy: 0.7894736842105263, F1 Score: 0.7499999999999999\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.8888888888888888, Recall: 0.8, Accuracy: 0.8421052631578947, F1 Score: 0.8421052631578948\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 1.0, Recall: 0.6, Accuracy: 0.7894736842105263, F1 Score: 0.7499999999999999\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.8, Recall: 0.4444444444444444, Accuracy: 0.6842105263157895, F1 Score: 0.5714285714285714\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, Accuracy: 0.7894736842105263, F1 Score: 0.7777777777777778\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Precision: 0.6666666666666666, Recall: 0.6666666666666666, Accuracy: 0.6842105263157895, F1 Score: 0.6666666666666666\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.7, Recall: 0.7777777777777778, Accuracy: 0.7368421052631579, F1 Score: 0.7368421052631577\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.8333333333333334, Recall: 0.5555555555555556, Accuracy: 0.7368421052631579, F1 Score: 0.6666666666666667\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.8571428571428571, Recall: 0.6666666666666666, Accuracy: 0.7894736842105263, F1 Score: 0.75\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.823529411764706\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Precision: 0.875, Recall: 0.7777777777777778, Accuracy: 0.8421052631578947, F1 Score: 0.823529411764706\n",
      "Best hyperparameters found: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Random Forest analysis completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import zipfile\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "###############################################################################\n",
    "# read data from file\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "\n",
    "def computeResults(testLabels, predictLabels):\n",
    "    try:\n",
    "        precision = precision_score(testLabels, predictLabels)\n",
    "        recall = recall_score(testLabels, predictLabels)\n",
    "        accuracy = accuracy_score(testLabels, predictLabels)\n",
    "        f1 = f1_score(testLabels, predictLabels)\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, Accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing metrics: {e}\")\n",
    "        precision = recall = accuracy = f1 = \"-\"\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "###############################################################################\n",
    "# FLAST\n",
    "\n",
    "def vectorization(dataPoints, dim=0, eps=0.3):\n",
    "    countVec = CountVectorizer()\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "def classificationRandomForest(trainData, trainLabels, testData, params):\n",
    "    # training\n",
    "    t0 = time.perf_counter()\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=params.get(\"n_estimators\", 100),\n",
    "        criterion=params.get(\"criterion\", \"gini\"),\n",
    "        max_depth=params.get(\"max_depth\"),\n",
    "        min_samples_split=params.get(\"min_samples_split\", 2),\n",
    "        min_samples_leaf=params.get(\"min_samples_leaf\", 1),\n",
    "        n_jobs=params.get(\"n_jobs\", -1),\n",
    "        random_state=params.get(\"random_state\", 42)\n",
    "    )\n",
    "    clf.fit(trainData, trainLabels)\n",
    "    t1 = time.perf_counter()\n",
    "    trainTime = t1 - t0\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    predictLabels = clf.predict(testData)\n",
    "    t1 = time.perf_counter()\n",
    "    testTime = t1 - t0\n",
    "\n",
    "    return trainTime, testTime, predictLabels\n",
    "\n",
    "def randomForestWithGridSearch(outDir, projectBasePath, projectName, kf, dim, eps, csv_filename):\n",
    "    v0 = time.perf_counter()\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "    print(\"Data points before vectorization:\", len(dataPoints))\n",
    "    Z = vectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataPointsList = np.array([Z[i].toarray() for i in range(Z.shape[0])])\n",
    "    dataLabelsList = np.array([1] * len(dataPointsFlaky) + [0] * len(dataPointsNonFlaky))\n",
    "    v1 = time.perf_counter()\n",
    "    vecTime = v1 - v0\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5],\n",
    "        \"min_samples_leaf\": [1, 2]\n",
    "    }\n",
    "\n",
    "    # Open the CSV file for writing results\n",
    "    with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"precision\", \"recall\", \"accuracy\", \"f1\"])  # CSV header\n",
    "\n",
    "        # Split the data and perform GridSearchCV\n",
    "        for (train_index, test_index) in kf.split(dataPointsList, dataLabelsList):\n",
    "            trainData, testData = dataPointsList[train_index], dataPointsList[test_index]\n",
    "            trainLabels, testLabels = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            # Flatten the train and test data\n",
    "            nSamplesTrainData, nxTrain, nyTrain = trainData.shape\n",
    "            trainData = trainData.reshape((nSamplesTrainData, nxTrain * nyTrain))\n",
    "            nSamplesTestData, nxTest, nyTest = testData.shape\n",
    "            testData = testData.reshape((nSamplesTestData, nxTest * nyTest))\n",
    "\n",
    "            # Instantiate RandomForestClassifier\n",
    "            rf = RandomForestClassifier(random_state=42)\n",
    "            \n",
    "            for cvTest in [3,5]:\n",
    "                \n",
    "                # GridSearchCV: searching for the best hyperparameters\n",
    "                grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cvTest, n_jobs=-1, verbose=1)\n",
    "                grid_search.fit(trainData, trainLabels)\n",
    "\n",
    "                # Retrieve the best parameters from the grid search\n",
    "                best_params = grid_search.best_params_\n",
    "                print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "                # Train the RandomForest with the best parameters and measure times\n",
    "                trainTime, testTime, predictLabels = classificationRandomForest(trainData, trainLabels, testData, best_params)\n",
    "                precision, recall, accuracy, f1 = computeResults(testLabels, predictLabels)\n",
    "\n",
    "                # Write the results to the CSV file\n",
    "                writer.writerow([best_params['criterion'], cVTest, best_params['min_samples_split'], best_params['min_samples_leaf'], precision, recall, accuracy, f1])\n",
    "\n",
    "    return best_params\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters setup\n",
    "    flakyZip = \"cleaned_flaky_files.zip\"\n",
    "    nonFlakyZip = \"reduced_nonflaky_files.zip\"\n",
    "    extractDir = \"extracted\"\n",
    "    outDir = \"results_Random_Forest\"\n",
    "    os.makedirs(outDir, exist_ok=True)\n",
    "    os.makedirs(extractDir, exist_ok=True)\n",
    "\n",
    "    numSplit = 30\n",
    "    testSetSize = 0.2\n",
    "    kf = StratifiedShuffleSplit(n_splits=numSplit, test_size=testSetSize)\n",
    "\n",
    "    # Define the CSV file for results\n",
    "    csv_filename = os.path.join(outDir, \"params-random-forest.csv\")\n",
    "\n",
    "    # Run Random Forest with Grid Search and save results to CSV\n",
    "    best_params = randomForestWithGridSearch(outDir, extractDir, \"projectName\", kf, dim=0, eps=0.3, csv_filename=csv_filename)\n",
    "    print(f\"Best hyperparameters found: {best_params}\")\n",
    "    print(\"Random Forest analysis completed.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3020bc-234a-4ef0-82be-224b4036852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points before vectorization: 94\n",
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "Results for CV=3:\n",
      "Iteration 0: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0051s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 1: Mean score: 0.5749327956989246, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 2: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0057s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 3: Mean score: 0.5325940860215054, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0021s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 4: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0042s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 5: Mean score: 0.510752688172043, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0018s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 6: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0044s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 7: Mean score: 0.5218413978494624, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 8: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0050s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 9: Mean score: 0.5749327956989246, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0024s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 10: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0054s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 11: Mean score: 0.5325940860215054, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 12: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0055s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 13: Mean score: 0.510752688172043, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0018s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 14: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0043s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 15: Mean score: 0.5218413978494624, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0018s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 16: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0052s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 17: Mean score: 0.5749327956989246, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 18: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0050s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 19: Mean score: 0.5325940860215054, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 20: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0043s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 21: Mean score: 0.510752688172043, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0013s, Test time: 0.0012s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 22: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0045s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 23: Mean score: 0.5218413978494624, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 24: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0048s, Test time: 0.0009s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 25: Mean score: 0.5749327956989246, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 26: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0046s, Test time: 0.0009s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 27: Mean score: 0.5325940860215054, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 28: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0052s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 29: Mean score: 0.510752688172043, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0018s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 30: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0050s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 31: Mean score: 0.5218413978494624, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 32: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0047s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 33: Mean score: 0.5749327956989246, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0050s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 35: Mean score: 0.5325940860215054, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 36: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0049s, Test time: 0.0009s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 37: Mean score: 0.510752688172043, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 38: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0051s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 39: Mean score: 0.5218413978494624, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 40: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0054s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 41: Mean score: 0.5749327956989246, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0018s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 42: Mean score: 0.6391129032258065, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0054s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 43: Mean score: 0.5325940860215054, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0028s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 44: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0047s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 45: Mean score: 0.510752688172043, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 46: Mean score: 0.6606182795698925, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0052s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 47: Mean score: 0.5218413978494624, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0018s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 48: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0069s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 49: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0027s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 50: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0070s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 51: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 52: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0065s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 53: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 54: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0072s, Test time: 0.0013s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 55: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0028s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 56: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0067s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 57: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 58: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0070s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 59: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 60: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0064s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 61: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 62: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0069s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 63: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 64: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0074s, Test time: 0.0013s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 65: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 66: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0070s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 67: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 68: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0075s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 69: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 70: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0070s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 71: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 72: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0079s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 73: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0027s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 74: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0075s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 75: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0027s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 76: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0072s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 77: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 78: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0072s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 79: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 80: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0082s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 81: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0015s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 82: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0070s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 83: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0032s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 84: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0065s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 85: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 86: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0072s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 87: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0033s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 88: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0074s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 89: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0033s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 90: Mean score: 0.6384408602150536, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0071s, Test time: 0.0013s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 91: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 92: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0064s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 93: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 94: Mean score: 0.6599462365591398, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0064s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 95: Mean score: 0.575268817204301, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Results for CV=5:\n",
      "Iteration 0: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0058s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 1: Mean score: 0.647953216374269, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0021s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 2: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0057s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 3: Mean score: 0.6368421052631579, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 4: Mean score: 0.6912280701754386, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0054s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 5: Mean score: 0.6052631578947368, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0019s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 6: Mean score: 0.6801169590643276, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0055s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 7: Mean score: 0.5947368421052632, Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0018s, Test time: 0.0009s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 8: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0052s, Test time: 0.0014s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 9: Mean score: 0.647953216374269, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 10: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0061s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 11: Mean score: 0.6368421052631579, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 12: Mean score: 0.6912280701754386, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0059s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 13: Mean score: 0.6052631578947368, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0016s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 14: Mean score: 0.6801169590643276, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0056s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 15: Mean score: 0.5947368421052632, Params: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0016s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 16: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0057s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 17: Mean score: 0.647953216374269, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0021s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 18: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0055s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 19: Mean score: 0.6368421052631579, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 20: Mean score: 0.6912280701754386, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0058s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 21: Mean score: 0.6052631578947368, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0019s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 22: Mean score: 0.6801169590643276, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0053s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 23: Mean score: 0.5947368421052632, Params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0018s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 24: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0059s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 25: Mean score: 0.647953216374269, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 26: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0067s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 27: Mean score: 0.6368421052631579, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0019s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 28: Mean score: 0.6912280701754386, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0057s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 29: Mean score: 0.6052631578947368, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0021s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 30: Mean score: 0.6801169590643276, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0062s, Test time: 0.0000s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 31: Mean score: 0.5947368421052632, Params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0018s, Test time: 0.0003s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 32: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0060s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33: Mean score: 0.647953216374269, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 34: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0056s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 35: Mean score: 0.6368421052631579, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0021s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 36: Mean score: 0.6912280701754386, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0056s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 37: Mean score: 0.6052631578947368, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0016s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 38: Mean score: 0.6801169590643276, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0051s, Test time: 0.0009s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 39: Mean score: 0.5947368421052632, Params: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0021s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 40: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0053s, Test time: 0.0011s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 41: Mean score: 0.647953216374269, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0021s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 42: Mean score: 0.6485380116959065, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0055s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 43: Mean score: 0.6368421052631579, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 44: Mean score: 0.6912280701754386, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0054s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 45: Mean score: 0.6052631578947368, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0017s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 46: Mean score: 0.6801169590643276, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0056s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 47: Mean score: 0.5947368421052632, Params: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0019s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 48: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0078s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 49: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0027s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 50: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0082s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 51: Mean score: 0.5321637426900585, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0024s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 52: Mean score: 0.6590643274853801, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0084s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 53: Mean score: 0.5532163742690057, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 54: Mean score: 0.6368421052631579, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0074s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 55: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0026s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 56: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0080s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 57: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0027s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 58: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0079s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 59: Mean score: 0.5321637426900585, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0024s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 60: Mean score: 0.6590643274853801, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0077s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 61: Mean score: 0.5532163742690057, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0024s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 62: Mean score: 0.6368421052631579, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0081s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 63: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 64: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0080s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 65: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0031s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 66: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0083s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 67: Mean score: 0.5321637426900585, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0026s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 68: Mean score: 0.6590643274853801, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0079s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 69: Mean score: 0.5532163742690057, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0020s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 70: Mean score: 0.6368421052631579, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0080s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 71: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 72: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0079s, Test time: 0.0010s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 73: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0028s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 74: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0076s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 75: Mean score: 0.5321637426900585, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0027s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 76: Mean score: 0.6590643274853801, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0087s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 77: Mean score: 0.5532163742690057, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0002s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 78: Mean score: 0.6368421052631579, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0075s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 79: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0019s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 80: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0083s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 81: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 82: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0081s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 83: Mean score: 0.5321637426900585, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0024s, Test time: 0.0005s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 84: Mean score: 0.6590643274853801, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0075s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 85: Mean score: 0.5532163742690057, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 86: Mean score: 0.6368421052631579, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0072s, Test time: 0.0006s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 87: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 88: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0087s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 89: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0023s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 90: Mean score: 0.6269005847953215, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0082s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "Iteration 91: Mean score: 0.5321637426900585, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0025s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Iteration 92: Mean score: 0.6590643274853801, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}, Train time: 0.0074s, Test time: 0.0004s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Iteration 93: Mean score: 0.5532163742690057, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}, Train time: 0.0022s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Iteration 94: Mean score: 0.6368421052631579, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}, Train time: 0.0074s, Test time: 0.0008s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 95: Mean score: 0.5426900584795321, Params: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}, Train time: 0.0017s, Test time: 0.0007s\n",
      "Training Decision Tree with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Best hyperparameters found: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Decision Tree analysis completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim, SparseRandomProjection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "###############################################################################\n",
    "# Helper Functions\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def computeResults(testLabels, predictLabels):\n",
    "    precision = precision_score(testLabels, predictLabels)\n",
    "    recall = recall_score(testLabels, predictLabels)\n",
    "    accuracy = accuracy_score(testLabels, predictLabels)\n",
    "    f1 = f1_score(testLabels, predictLabels)\n",
    "    \n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "###############################################################################\n",
    "# FLAST\n",
    "\n",
    "def vectorization(dataPoints, dim=0, eps=0.3):\n",
    "    countVec = CountVectorizer(stop_words=None)  # Disable stop words filtering\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "def classificationDecisionTree(trainData, trainLabels, testData, params):\n",
    "    # Log the parameters being used for training\n",
    "    print(f\"Training Decision Tree with parameters: {params}\")\n",
    "    \n",
    "    # Create the DecisionTreeClassifier with the selected hyperparameters\n",
    "    clf = DecisionTreeClassifier(\n",
    "        criterion=params.get(\"criterion\", \"gini\"),\n",
    "        splitter=params.get(\"splitter\", \"best\"),\n",
    "        max_depth=params.get(\"max_depth\"),  # Ensure max_depth is correctly passed\n",
    "        min_samples_split=params.get(\"min_samples_split\", 2),\n",
    "        min_samples_leaf=params.get(\"min_samples_leaf\", 1),\n",
    "    )\n",
    "\n",
    "    # Fit the classifier\n",
    "    t0 = time.perf_counter()\n",
    "    clf.fit(trainData, trainLabels)\n",
    "    t1 = time.perf_counter()\n",
    "    trainTime = t1 - t0\n",
    "\n",
    "    # Make predictions\n",
    "    t0 = time.perf_counter()\n",
    "    predictLabels = clf.predict(testData)\n",
    "    t1 = time.perf_counter()\n",
    "    testTime = t1 - t0\n",
    "\n",
    "    return trainTime, testTime, predictLabels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def decisionTreeWithGridSearch(outDir, projectBasePath, projectName, dim, eps, csv_filename):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Load data from directories\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "    print(\"Data points before vectorization:\", len(dataPoints))\n",
    "\n",
    "    # Vectorize data\n",
    "    Z = vectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataPointsList = np.array([Z[i].toarray() for i in range(Z.shape[0])])\n",
    "    dataLabelsList = np.array([1] * len(dataPointsFlaky) + [0] * len(dataPointsNonFlaky))\n",
    "    v1 = time.perf_counter()\n",
    "    vecTime = v1 - v0\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataPointsList, dataLabelsList, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"splitter\": [\"best\", \"random\"],\n",
    "        \"max_depth\": [10, 30, 50, 100, 300, 500],\n",
    "        \"min_samples_split\": [2, 5],\n",
    "        \"min_samples_leaf\": [1, 2]\n",
    "    }\n",
    "\n",
    "    # Open CSV file to write results\n",
    "    with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"criterion\", \"cvTest\", \"splitter\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"precision\", \"recall\", \"accuracy\", \"f1\", \"train_time\", \"test_time\"])\n",
    "\n",
    "        # Instantiate DecisionTreeClassifier\n",
    "        dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        # Perform Grid Search with Cross-Validation\n",
    "        for cvTest in [3, 5]:\n",
    "            grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=cvTest, n_jobs=-1, verbose=2)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Log results\n",
    "            for i in range(len(grid_search.cv_results_['params'])):\n",
    "                params = grid_search.cv_results_['params'][i]\n",
    "                mean_score = grid_search.cv_results_['mean_test_score'][i]\n",
    "                mean_fit_time = grid_search.cv_results_['mean_fit_time'][i]\n",
    "                mean_score_time = grid_search.cv_results_['mean_score_time'][i]\n",
    "\n",
    "                # Train and test with current parameters\n",
    "                trainTime, testTime, predictLabels = classificationDecisionTree(X_train, y_train, X_test, params)\n",
    "                precision, recall, accuracy, f1 = computeResults(y_test, predictLabels)\n",
    "\n",
    "                # Write results to CSV\n",
    "                writer.writerow([params['criterion'], cvTest, params['splitter'], params['max_depth'], \n",
    "                                 params['min_samples_split'], params['min_samples_leaf'], \n",
    "                                 precision, recall, accuracy, f1, mean_fit_time, mean_score_time])\n",
    "\n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters setup\n",
    "    flakyZip = \"cleaned_flaky_files.zip\"\n",
    "    nonFlakyZip = \"reduced_nonflaky_files.zip\"\n",
    "    extractDir = \"extracted\"\n",
    "    outDir = \"results_DecisionTree\"\n",
    "    \n",
    "    # Ensure the directories for output exist\n",
    "    os.makedirs(outDir, exist_ok=True)\n",
    "    os.makedirs(extractDir, exist_ok=True)\n",
    "\n",
    "    # Define the CSV file for results\n",
    "    csv_filename = os.path.join(outDir, \"params-DecisionTree.csv\")\n",
    "\n",
    "    # Run Decision Tree with Grid Search and save results to CSV\n",
    "    best_params = decisionTreeWithGridSearch(outDir, extractDir, \"projectName\", dim=0, eps=0.3, csv_filename=csv_filename)\n",
    "    \n",
    "    print(f\"Best hyperparameters found: {best_params}\")\n",
    "    print(\"Decision Tree analysis completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e58d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
