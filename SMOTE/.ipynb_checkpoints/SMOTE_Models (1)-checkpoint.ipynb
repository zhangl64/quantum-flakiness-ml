{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84acd571",
   "metadata": {
    "id": "84acd571"
   },
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2d4796",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb2d4796",
    "outputId": "0fae8c6c-6f63-49a9-925d-fa604a27c5c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting KNN analysis with SMOTE and PCA for 5-fold cross-validation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'runKNNWithSMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rp/h_pmxr992m143v567my_k4lm0000gn/T/ipykernel_66200/3775088793.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Run KNN with SMOTE and PCA using 5-fold cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting KNN analysis with SMOTE and PCA for 5-fold cross-validation...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mbest_params_5folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_f1_5folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_mcc_5folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunKNNWithSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataPoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLabelsList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Display results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'runKNNWithSMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "# Set global random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set environment variables for deterministic behavior\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'  # For OpenMP\n",
    "os.environ['MKL_NUM_THREADS'] = '1'  # For MKL\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'  # For OpenBLAS\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'  # For NumExpr\n",
    "#os.environ['VECLIB_MAXIMUM_THREADS'] = '1'  # For macOS Accelerate\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        dirs.sort()  # Sort directories to ensure consistent traversal\n",
    "        files.sort()  # Sort files to ensure consistent order\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "\n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "\n",
    "    return dataPointsList\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for 5-Fold Cross-Validation\n",
    "\n",
    "outDir = \"smote-results\"\n",
    "os.makedirs(outDir, exist_ok=True)\n",
    "\n",
    "# Run KNN with SMOTE and PCA using 5-fold cross-validation\n",
    "print(\"\\nStarting KNN analysis with SMOTE and PCA for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds, final_mcc_5folds = runKNNWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for KNN with SMOTE and PCA 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n",
    "print(f\"Final MCC: {final_mcc_5folds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf94de6",
   "metadata": {
    "id": "aaf94de6"
   },
   "source": [
    "## KNN with SMOTE|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f791afe1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f791afe1",
    "outputId": "dc45e99f-d4f2-4b73-f524-931d4ff2ed74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting KNN analysis with SMOTE and PCA for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Best Parameters with SMOTE and PCA: {'knn__metric': 'cosine', 'knn__n_neighbors': 11, 'knn__weights': 'distance', 'pca__n_components': 150}\n",
      "Best MCC Score from cross-validation: 0.5832507361919127\n",
      "Per-fold metrics saved to: smote-results\\knn-smote-pca-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.611111111111111\n",
      "Final Recall: 0.6\n",
      "Final Accuracy: 0.8750151240169389\n",
      "Final F1 Score: 0.5832507361919127\n",
      "Final MCC: 0.5250008288463672\n",
      "KNN analysis completed for 5-folds with SMOTE and PCA. Results saved to: smote-results\\knn-results-5-folds.csv\n",
      "\n",
      "Best results for KNN with SMOTE and PCA 5-fold cross-validation:\n",
      "Best Parameters: {'knn__metric': 'cosine', 'knn__n_neighbors': 11, 'knn__weights': 'distance', 'pca__n_components': 150}\n",
      "Best F1 Score: 0.5832507361919127\n",
      "Final MCC: 0.5250008288463672\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef, make_scorer)\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "###############################################################################\n",
    "# Custom MCC scorer function\n",
    "def mcc_scorer(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "###############################################################################\n",
    "# KNN with SMOTE and PCA\n",
    "\n",
    "def runKNNWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': mcc_scorer\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with PCA, SMOTE, and KNN\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Vectorizer\n",
    "        ('pca', PCA(random_state=42)),                     # PCA for dimensionality reduction\n",
    "        ('smote', SMOTE(random_state=42)),                 # SMOTE for oversampling\n",
    "        ('knn', KNeighborsClassifier()),                   # KNN classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'pca__n_components': [150, 180, 200, 220],             # PCA components\n",
    "        'knn__n_neighbors': [3, 5, 7, 9, 11],     # Number of neighbors for KNN\n",
    "        'knn__weights': ['uniform', 'distance'],          # Weighting options\n",
    "        'knn__metric': ['euclidean', 'cosine']            # Distance metrics\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=skf, scoring=scoring,\n",
    "        refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.perf_counter()\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE and PCA: {best_params}\")\n",
    "    print(f\"Best MCC Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combinations\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'n_components': results['params'][idx].get('pca__n_components'),\n",
    "            'n_neighbors': results['params'][idx].get('knn__n_neighbors'),\n",
    "            'weights': results['params'][idx].get('knn__weights'),\n",
    "            'metric': results['params'][idx].get('knn__metric'),\n",
    "            'accuracy': results.get('mean_test_accuracy', [None])[idx],\n",
    "            'precision': results.get('mean_test_precision', [None])[idx],\n",
    "            'recall': results.get('mean_test_recall', [None])[idx],\n",
    "            'f1': results.get('mean_test_f1', [None])[idx],\n",
    "            'mcc': results.get('mean_test_mcc', [None])[idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile_folds = os.path.join(outDir, f\"knn-smote-pca-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile_folds, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile_folds}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "    final_mcc = results['mean_test_mcc'][grid_search.best_index_]  # Extract final MCC\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "    print(f\"Final MCC: {final_mcc}\")\n",
    "\n",
    "    # Save the final results to a CSV file\n",
    "    outFile_final = os.path.join(outDir, f\"knn-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile_final, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1,MCC\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1},{final_mcc}\\n\")\n",
    "\n",
    "    print(f\"KNN analysis completed for {n_splits}-folds with SMOTE and PCA. Results saved to: {outFile_final}\")\n",
    "\n",
    "    return best_params, final_f1, final_mcc\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for 5-Fold Cross-Validation\n",
    "\n",
    "outDir = \"smote-results\"\n",
    "os.makedirs(outDir, exist_ok=True)\n",
    "\n",
    "# Run KNN with SMOTE and PCA using 5-fold cross-validation\n",
    "print(\"\\nStarting KNN analysis with SMOTE and PCA for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds, final_mcc_5folds = runKNNWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for KNN with SMOTE and PCA 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n",
    "print(f\"Final MCC: {final_mcc_5folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c826fa",
   "metadata": {
    "id": "f8c826fa"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c857480",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c857480",
    "outputId": "c9d2c502-82d5-4a13-d2be-e8ddde0af57d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting SVM analysis with SMOTE and PCA for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Best Parameters with SMOTE and PCA: {'pca__n_components': 220, 'svm__C': 0.01, 'svm__kernel': 'linear'}\n",
      "Best F1 Score from cross-validation: 0.6914602683178535\n",
      "Per-fold metrics saved to: smote-results\\svm-smote-pca-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.8445238095238097\n",
      "Final Recall: 0.6222222222222222\n",
      "Final Accuracy: 0.9201451905626135\n",
      "Final F1 Score: 0.6914602683178535\n",
      "Final MCC: 0.6720359085671346\n",
      "SVM analysis completed for 5-folds with SMOTE and PCA. Results saved to: smote-results\\svm-results-5-folds.csv\n",
      "\n",
      "Best results for SVM with SMOTE and PCA 5-fold cross-validation:\n",
      "Best Parameters: {'pca__n_components': 220, 'svm__C': 0.01, 'svm__kernel': 'linear'}\n",
      "Best F1 Score: 0.6914602683178535\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef, make_scorer)\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "###############################################################################\n",
    "# Custom MCC scorer function\n",
    "def mcc_scorer(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "###############################################################################\n",
    "# SVM with SMOTE and PCA\n",
    "\n",
    "def runSVMWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': mcc_scorer\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with CountVectorizer, PCA, SMOTE, and SVM\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Vectorizer\n",
    "        ('pca', PCA(random_state=42)),                     # Dimensionality reduction\n",
    "        ('smote', SMOTE(random_state=42)),                 # SMOTE for oversampling\n",
    "        ('svm', SVC(probability=True))                     # SVM classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'pca__n_components': [150, 180, 200, 220],          # PCA components\n",
    "        'svm__C': [0.01, 0.1, 1.0, 10.0, 100.0],            # Regularization parameter\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly', 'sigmoid'] # Kernel types\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE and PCA: {best_params}\")\n",
    "    print(f\"Best F1 Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combinations\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'n_components': results['params'][idx].get('pca__n_components'),\n",
    "            'C': results['params'][idx].get('svm__C'),\n",
    "            'kernel': results['params'][idx].get('svm__kernel'),\n",
    "            'accuracy': results.get(f'mean_test_accuracy', [None])[idx],\n",
    "            'precision': results.get(f'mean_test_precision', [None])[idx],\n",
    "            'recall': results.get(f'mean_test_recall', [None])[idx],\n",
    "            'f1': results.get(f'mean_test_f1', [None])[idx],\n",
    "            'mcc': results.get(f'mean_test_mcc', [None])[idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile_folds = os.path.join(outDir, f\"svm-smote-pca-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile_folds, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile_folds}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "    final_mcc = results['mean_test_mcc'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "    print(f\"Final MCC: {final_mcc}\")\n",
    "\n",
    "    # Save the final results to a CSV file\n",
    "    outFile_final = os.path.join(outDir, f\"svm-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile_final, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1,MCC\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1},{final_mcc}\\n\")\n",
    "\n",
    "    print(f\"SVM analysis completed for {n_splits}-folds with SMOTE and PCA. Results saved to: {outFile_final}\")\n",
    "\n",
    "    return best_params, final_f1, final_mcc\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution\n",
    "\n",
    "outDir = \"smote-results\"\n",
    "os.makedirs(outDir, exist_ok=True)\n",
    "\n",
    "# Run SVM with SMOTE and PCA using 5-fold cross-validation\n",
    "print(\"\\nStarting SVM analysis with SMOTE and PCA for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds, final_mcc_5folds = runSVMWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM with SMOTE and PCA 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6bbf78",
   "metadata": {
    "id": "ed6bbf78"
   },
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb569e16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb569e16",
    "outputId": "4fe6d6c4-8bec-4d47-ebb6-20130d13fd73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGBoost analysis with SMOTE, PCA, and CountVectorizer for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "Best Parameters with SMOTE, PCA, and CountVectorizer: {'pca__n_components': 150, 'xgb__learning_rate': 0.5, 'xgb__max_depth': 3, 'xgb__n_estimators': 100}\n",
      "Best F1 Score from cross-validation: 0.7552324438547349\n",
      "Per-fold metrics saved to: smote-results/xgb-smote-pca-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.8306349206349207\n",
      "Final Recall: 0.711111111111111\n",
      "Final Accuracy: 0.9304900181488203\n",
      "Final F1 Score: 0.7552324438547349\n",
      "Final MCC: 0.72509493338034\n",
      "XGBoost analysis completed for 5-folds with SMOTE, PCA, and CountVectorizer. Results saved to: smote-results/xgb-results-5-folds.csv\n",
      "\n",
      "Best results for XGBoost with SMOTE, PCA, and CountVectorizer 5-fold cross-validation:\n",
      "Best Parameters: {'pca__n_components': 150, 'xgb__learning_rate': 0.5, 'xgb__max_depth': 3, 'xgb__n_estimators': 100}\n",
      "Best F1 Score: 0.7552324438547349\n",
      "Final MCC: 0.72509493338034\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef, make_scorer)\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "###############################################################################\n",
    "# Custom MCC scorer function\n",
    "def mcc_scorer(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "###############################################################################\n",
    "# XGBoost with SMOTE, PCA, and CountVectorizer\n",
    "\n",
    "def runXGBWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': mcc_scorer\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with CountVectorizer, PCA, SMOTE, and XGBoost\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),               # Vectorizer\n",
    "        ('pca', PCA(random_state=42)),                                                 # PCA for dimensionality reduction\n",
    "        ('smote', SMOTE(random_state=42)),                              # SMOTE for oversampling\n",
    "        ('xgb', XGBClassifier(eval_metric='logloss', random_state=42))  # XGBoost classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'pca__n_components': [150, 180, 200, 220],        # PCA components\n",
    "        'xgb__n_estimators': [100, 150, 200],             # Number of boosting rounds\n",
    "        'xgb__max_depth': [3, 5, 7, 10],                  # Maximum depth of a tree\n",
    "        'xgb__learning_rate': [0.01, 0.1, 0.3, 0.5],      # Learning rate\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE, PCA, and CountVectorizer: {best_params}\")\n",
    "    print(f\"Best F1 Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combination\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'n_components': results['params'][idx].get('pca__n_components'),\n",
    "            'n_estimators': results['params'][idx].get('xgb__n_estimators'),\n",
    "            'max_depth': results['params'][idx].get('xgb__max_depth'),\n",
    "            'learning_rate': results['params'][idx].get('xgb__learning_rate'),\n",
    "            'accuracy': results.get('mean_test_accuracy', [None])[idx],\n",
    "            'precision': results.get('mean_test_precision', [None])[idx],\n",
    "            'recall': results.get('mean_test_recall', [None])[idx],\n",
    "            'f1': results.get('mean_test_f1', [None])[idx],\n",
    "            'mcc': results.get('mean_test_mcc', [None])[idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile_folds = os.path.join(outDir, f\"xgb-smote-pca-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile_folds, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile_folds}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "    final_mcc = results['mean_test_mcc'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "    print(f\"Final MCC: {final_mcc}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    outFile_final = os.path.join(outDir, f\"xgb-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile_final, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1,MCC\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1},{final_mcc}\\n\")\n",
    "\n",
    "    print(f\"XGBoost analysis completed for {n_splits}-folds with SMOTE, PCA, and CountVectorizer. Results saved to: {outFile_final}\")\n",
    "\n",
    "    return best_params, final_f1, final_mcc\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for 5-Fold Cross-Validation\n",
    "\n",
    "outDir = \"smote-results\"\n",
    "os.makedirs(outDir, exist_ok=True)\n",
    "\n",
    "# Run XGBoost with SMOTE, PCA, and CountVectorizer using 5-fold cross-validation\n",
    "print(\"\\nStarting XGBoost analysis with SMOTE, PCA, and CountVectorizer for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds, final_mcc_5folds = runXGBWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for XGBoost with SMOTE, PCA, and CountVectorizer 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n",
    "print(f\"Final MCC: {final_mcc_5folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fde55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cb851b8",
   "metadata": {
    "id": "7cb851b8"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd465761",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd465761",
    "outputId": "4dc04334-51e8-449e-f3e2-87ae7e7c2806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Random Forest analysis with SMOTE for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters with SMOTE and PCA: {'rf__criterion': 'entropy', 'rf__max_depth': 20, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}\n",
      "Best F1 Score from cross-validation: 0.822015823873409\n",
      "Per-fold metrics saved to: smote-results\\rf-smote-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.8238888888888889\n",
      "Final Recall: 0.8222222222222222\n",
      "Final Accuracy: 0.9444041137326075\n",
      "Final F1 Score: 0.822015823873409\n",
      "Final MCC: 0.7898138504372108\n",
      "Random Forest analysis completed for 5-folds with SMOTE. Results saved to: smote-results\\rf-results-5-folds.csv\n",
      "\n",
      "Best results for Random Forest with SMOTE 5-fold cross-validation:\n",
      "Best Parameters: {'rf__criterion': 'entropy', 'rf__max_depth': 20, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}\n",
      "Best F1 Score: 0.822015823873409\n",
      "Final MCC: 0.7898138504372108\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef, make_scorer)\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "###############################################################################\n",
    "# Custom MCC scorer function\n",
    "def mcc_scorer(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "###############################################################################\n",
    "# Random Forest with SMOTE\n",
    "\n",
    "def runRFWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': mcc_scorer\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with SMOTE, and Random Forest\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Vectorizer\n",
    "        ('smote', SMOTE(random_state=42)),                 # SMOTE for oversampling\n",
    "        ('rf', RandomForestClassifier(random_state=42))    # Random Forest classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'rf__n_estimators': [50, 100, 200],                 # Number of trees in the forest\n",
    "        'rf__max_depth': [10, 20, 30],                     # Maximum depth of the tree\n",
    "        'rf__min_samples_split': [5, 10],                   # Minimum number of samples required to split a node\n",
    "        'rf__min_samples_leaf': [2, 5],                    # Minimum number of samples required at a leaf node\n",
    "        'rf__criterion': ['gini', 'entropy']               # Function to measure the quality of a split\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE and PCA: {best_params}\")\n",
    "    print(f\"Best F1 Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combinations\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "\n",
    "            'n_estimators': results['params'][idx].get('rf__n_estimators'),\n",
    "            'max_depth': results['params'][idx].get('rf__max_depth'),\n",
    "            'min_samples_split': results['params'][idx].get('rf__min_samples_split'),\n",
    "            'min_samples_leaf': results['params'][idx].get('rf__min_samples_leaf'),\n",
    "            'criterion': results['params'][idx].get('rf__criterion'),\n",
    "            'accuracy': results.get('mean_test_accuracy', [None])[idx],\n",
    "            'precision': results.get('mean_test_precision', [None])[idx],\n",
    "            'recall': results.get('mean_test_recall', [None])[idx],\n",
    "            'f1': results.get('mean_test_f1', [None])[idx],\n",
    "            'mcc': results.get('mean_test_mcc', [None])[idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile_folds = os.path.join(outDir, f\"rf-smote-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile_folds, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile_folds}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "    final_mcc = results['mean_test_mcc'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "    print(f\"Final MCC: {final_mcc}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    outFile_final = os.path.join(outDir, f\"rf-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile_final, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1,MCC\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1},{final_mcc}\\n\")\n",
    "\n",
    "    print(f\"Random Forest analysis completed for {n_splits}-folds with SMOTE. Results saved to: {outFile_final}\")\n",
    "\n",
    "    return best_params, final_f1, final_mcc\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for 5-Fold Cross-Validation\n",
    "\n",
    "outDir = \"smote-results\"\n",
    "os.makedirs(outDir, exist_ok=True)\n",
    "\n",
    "# Run Random Forest with SMOTE and PCA using 5-fold cross-validation\n",
    "print(\"\\nStarting Random Forest analysis with SMOTE for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds, final_mcc_5folds = runRFWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Random Forest with SMOTE 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n",
    "print(f\"Final MCC: {final_mcc_5folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef3f6e",
   "metadata": {
    "id": "3aef3f6e"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6504957",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6504957",
    "outputId": "749e9f64-e89e-415f-e7d9-ecc6287f640c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Decision Tree analysis with SMOTE and PCA for 5-fold cross-validation...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters with SMOTE and PCA: {'dt__criterion': 'gini', 'dt__max_depth': 10, 'dt__max_features': None, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 5}\n",
      "Best Score from cross-validation: 0.8495475113122172\n",
      "Per-fold metrics saved to: smote-results\\dt-smote-pca-fold-results-5-folds.csv\n",
      "\n",
      "Final Cross-Validation Metrics:\n",
      "Final Precision: 0.9199999999999999\n",
      "Final Recall: 0.8444444444444443\n",
      "Final Accuracy: 0.955111917725348\n",
      "Final F1 Score: 0.8495475113122172\n",
      "Final MCC: 0.8454298941250029\n",
      "Decision Tree analysis completed for 5-folds with SMOTE and PCA. Results saved to: smote-results\\dt-results-5-folds.csv\n",
      "\n",
      "Best results for Decision Tree with SMOTE 5-fold cross-validation:\n",
      "Best Parameters: {'dt__criterion': 'gini', 'dt__max_depth': 10, 'dt__max_features': None, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 5}\n",
      "Best F1 Score: 0.8495475113122172\n",
      "Final MCC: 0.8454298941250029\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef, make_scorer)\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "###############################################################################\n",
    "# Custom MCC scorer function\n",
    "def mcc_scorer(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with SMOTE and PCA\n",
    "\n",
    "def runDTWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': mcc_scorer\n",
    "    }\n",
    "\n",
    "    # Define a pipeline with SMOTE, and Decision Tree\n",
    "    pipeline = ImbPipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=None)),  # Vectorizer\n",
    "        ('smote', SMOTE(random_state=42)),                 # SMOTE for oversampling\n",
    "        ('dt', DecisionTreeClassifier(random_state=42))    # Decision Tree classifier\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'dt__max_depth': [10, 20, 30],                     # Maximum depth of the tree\n",
    "        'dt__min_samples_split': [5, 10],                  # Minimum number of samples required to split a node\n",
    "        'dt__min_samples_leaf': [2, 5],                    # Minimum number of samples required at a leaf node\n",
    "        'dt__criterion': ['gini', 'entropy'],              # Function to measure the quality of a split\n",
    "        'dt__max_features': [None, 'sqrt', 'log2']         # Controls how many features to consider for splits\n",
    "    }\n",
    "\n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV with the pipeline and parameter grid\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=skf, scoring=scoring,\n",
    "        refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV to the data\n",
    "    grid_search.fit(dataPoints, dataLabelsList)\n",
    "\n",
    "    # Retrieve the best parameters and score from cross-validation\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1_cv = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters with SMOTE and PCA: {best_params}\")\n",
    "    print(f\"Best Score from cross-validation: {best_f1_cv}\")\n",
    "\n",
    "    # Extract the cross-validation results and print final metrics\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Prepare per-fold metrics for CSV along with the parameter combinations\n",
    "    fold_metrics = []\n",
    "    for idx in range(len(results['params'])):\n",
    "        fold_metrics.append({\n",
    "            'n_components': results['params'][idx].get('pca__n_components'),\n",
    "            'max_depth': results['params'][idx].get('dt__max_depth'),\n",
    "            'min_samples_split': results['params'][idx].get('dt__min_samples_split'),\n",
    "            'min_samples_leaf': results['params'][idx].get('dt__min_samples_leaf'),\n",
    "            'criterion': results['params'][idx].get('dt__criterion'),\n",
    "            'dt__max_features': results['params'][idx].get('dt__max_features'),\n",
    "            'accuracy': results.get('mean_test_accuracy', [None])[idx],\n",
    "            'precision': results.get('mean_test_precision', [None])[idx],\n",
    "            'recall': results.get('mean_test_recall', [None])[idx],\n",
    "            'f1': results.get('mean_test_f1', [None])[idx],\n",
    "            'mcc': results.get('mean_test_mcc', [None])[idx],\n",
    "        })\n",
    "\n",
    "    # Save fold-wise metrics to CSV\n",
    "    df_folds = pd.DataFrame(fold_metrics)\n",
    "    outFile_folds = os.path.join(outDir, f\"dt-smote-pca-fold-results-{n_splits}-folds.csv\")\n",
    "    df_folds.to_csv(outFile_folds, index=False)\n",
    "\n",
    "    print(f\"Per-fold metrics saved to: {outFile_folds}\")\n",
    "\n",
    "    # Extract final metrics based on the cross-validation results\n",
    "    final_f1 = results['mean_test_f1'][grid_search.best_index_]\n",
    "    final_precision = results['mean_test_precision'][grid_search.best_index_]\n",
    "    final_recall = results['mean_test_recall'][grid_search.best_index_]\n",
    "    final_accuracy = results['mean_test_accuracy'][grid_search.best_index_]\n",
    "    final_mcc = results['mean_test_mcc'][grid_search.best_index_]\n",
    "\n",
    "    # Print final metrics (cross-validation averages)\n",
    "    print(\"\\nFinal Cross-Validation Metrics:\")\n",
    "    print(f\"Final Precision: {final_precision}\")\n",
    "    print(f\"Final Recall: {final_recall}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy}\")\n",
    "    print(f\"Final F1 Score: {final_f1}\")\n",
    "    print(f\"Final MCC: {final_mcc}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    outFile_final = os.path.join(outDir, f\"dt-results-{n_splits}-folds.csv\")\n",
    "    with open(outFile_final, \"w\") as f:\n",
    "        f.write(\"Accuracy,Precision,Recall,F1,MCC\\n\")\n",
    "        f.write(f\"{final_accuracy},{final_precision},{final_recall},{final_f1},{final_mcc}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {n_splits}-folds with SMOTE and PCA. Results saved to: {outFile_final}\")\n",
    "\n",
    "    return best_params, final_f1, final_mcc\n",
    "\n",
    "###############################################################################\n",
    "# Main Execution for 5-Fold Cross-Validation\n",
    "\n",
    "outDir = \"smote-results\"\n",
    "os.makedirs(outDir, exist_ok=True)\n",
    "\n",
    "# Run Decision Tree with SMOTE using 5-fold cross-validation\n",
    "print(\"\\nStarting Decision Tree analysis with SMOTE for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_f1_5folds, final_mcc_5folds = runDTWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Decision Tree with SMOTE 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n",
    "print(f\"Final MCC: {final_mcc_5folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ff970",
   "metadata": {},
   "source": [
    "## Decision Tree with Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95dedc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Decision Tree analysis with SMOTE and Threshold adjustment for 5-fold cross-validation...\n",
      "Results saved to: smote-results-DT-new\\dt-smote-threshold-results-5-folds.csv\n",
      "\n",
      "Best Parameters, Threshold, and Metrics:\n",
      "Best Parameters: {'dt__max_depth': 10, 'dt__min_samples_split': 5, 'dt__min_samples_leaf': 2, 'dt__criterion': 'gini', 'dt__max_features': None}\n",
      "Best Threshold: 0.1\n",
      "Best F1 Score: 0.8760130718954249\n",
      "Final MCC: 0.8639675781078721\n",
      "\n",
      "Best results for Decision Tree with SMOTE and Threshold adjustment 5-fold cross-validation:\n",
      "Best Parameters: {'dt__max_depth': 10, 'dt__min_samples_split': 5, 'dt__min_samples_leaf': 2, 'dt__criterion': 'gini', 'dt__max_features': None}\n",
      "Best Threshold: 0.1\n",
      "Best F1 Score: 0.8760130718954249\n",
      "Final MCC: 0.8639675781078721\n"
     ]
    }
   ],
   "source": [
    "def runDTWithSMOTE(dataPoints, dataLabelsList, outDir, n_splits):\n",
    "    v0 = time.perf_counter()\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'dt__max_depth': [10],\n",
    "        'dt__min_samples_split': [5],\n",
    "        'dt__min_samples_leaf': [2],\n",
    "        'dt__criterion': ['gini'],\n",
    "        'dt__max_features': [None]\n",
    "    }\n",
    "    \n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    param_keys = list(param_grid.keys())\n",
    "    \n",
    "    # Prepare to store metrics\n",
    "    metrics_per_combination = []\n",
    "    \n",
    "    # Define thresholds to evaluate\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)  # Thresholds from 0.1 to 0.9\n",
    "    \n",
    "    # Setup cross-validation strategy\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Loop over each hyperparameter combination\n",
    "    for params in param_combinations:\n",
    "        param_dict = dict(zip(param_keys, params))\n",
    "        \n",
    "        # Initialize lists to store metrics per threshold\n",
    "        threshold_metrics_list = []\n",
    "        \n",
    "        # For each fold in cross-validation\n",
    "        for fold_idx, (train_index, test_index) in enumerate(skf.split(dataPoints, dataLabelsList)):\n",
    "            X_train = [dataPoints[i] for i in train_index]\n",
    "            X_test = [dataPoints[i] for i in test_index]\n",
    "            y_train = [dataLabelsList[i] for i in train_index]\n",
    "            y_test = [dataLabelsList[i] for i in test_index]\n",
    "            \n",
    "            # Define a pipeline with SMOTE and Decision Tree with current params\n",
    "            pipeline = ImbPipeline([\n",
    "                ('vectorizer', CountVectorizer(stop_words=None)),\n",
    "                ('smote', SMOTE(random_state=42)),\n",
    "                ('dt', DecisionTreeClassifier(\n",
    "                    max_depth=param_dict['dt__max_depth'],\n",
    "                    min_samples_split=param_dict['dt__min_samples_split'],\n",
    "                    min_samples_leaf=param_dict['dt__min_samples_leaf'],\n",
    "                    criterion=param_dict['dt__criterion'],\n",
    "                    max_features=param_dict['dt__max_features'],\n",
    "                    random_state=42))\n",
    "            ])\n",
    "            \n",
    "            # Train the pipeline\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict probabilities\n",
    "            y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Iterate over thresholds\n",
    "            for threshold in thresholds:\n",
    "                y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                accuracy = accuracy_score(y_test, y_pred_threshold)\n",
    "                precision = precision_score(y_test, y_pred_threshold, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred_threshold, zero_division=1)\n",
    "                f1 = f1_score(y_test, y_pred_threshold, zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred_threshold)\n",
    "                \n",
    "                # Store fold metrics\n",
    "                threshold_metrics_list.append({\n",
    "                    **param_dict,\n",
    "                    'threshold': threshold,\n",
    "                    'fold': fold_idx + 1,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "        \n",
    "        # Calculate average metrics over folds for each threshold\n",
    "        for threshold in thresholds:\n",
    "            # Filter metrics for the current threshold\n",
    "            threshold_metrics = [tm for tm in threshold_metrics_list if tm['threshold'] == threshold]\n",
    "            \n",
    "            avg_accuracy = np.mean([tm['accuracy'] for tm in threshold_metrics])\n",
    "            avg_precision = np.mean([tm['precision'] for tm in threshold_metrics])\n",
    "            avg_recall = np.mean([tm['recall'] for tm in threshold_metrics])\n",
    "            avg_f1 = np.mean([tm['f1'] for tm in threshold_metrics])\n",
    "            avg_mcc = np.mean([tm['mcc'] for tm in threshold_metrics])\n",
    "            \n",
    "            # Store the metrics along with parameters and threshold\n",
    "            metrics_per_combination.append({\n",
    "                **param_dict,\n",
    "                'threshold': threshold,\n",
    "                'accuracy': avg_accuracy,\n",
    "                'precision': avg_precision,\n",
    "                'recall': avg_recall,\n",
    "                'f1': avg_f1,\n",
    "                'mcc': avg_mcc\n",
    "            })\n",
    "    \n",
    "    # Now, find the parameter combination with the best F1 score\n",
    "    best_result = max(metrics_per_combination, key=lambda x: x['f1'])\n",
    "    \n",
    "    # Save the results to CSV\n",
    "    df_metrics = pd.DataFrame(metrics_per_combination)\n",
    "    outFile_metrics = os.path.join(outDir, f\"dt-smote-threshold-results-{n_splits}-folds.csv\")\n",
    "    df_metrics.to_csv(outFile_metrics, index=False)\n",
    "    \n",
    "    print(f\"Results saved to: {outFile_metrics}\")\n",
    "    \n",
    "    # Extract the best parameters, threshold, and metrics\n",
    "    best_params = {key: best_result[key] for key in param_keys}\n",
    "    best_threshold = best_result['threshold']\n",
    "    best_f1 = best_result['f1']\n",
    "    final_mcc = best_result['mcc']\n",
    "    \n",
    "    print(\"\\nBest Parameters, Threshold, and Metrics:\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best Threshold: {best_threshold}\")\n",
    "    print(f\"Best F1 Score: {best_f1}\")\n",
    "    print(f\"Final MCC: {final_mcc}\")\n",
    "    \n",
    "    return best_params, best_threshold, best_f1, final_mcc\n",
    "# Main Execution for 5-Fold Cross-Validation\n",
    "outDir = \"smote-results-DT-new\"\n",
    "os.makedirs(outDir, exist_ok=True)\n",
    "\n",
    "# Run Decision Tree with SMOTE and Threshold adjustment using 5-fold cross-validation\n",
    "print(\"\\nStarting Decision Tree analysis with SMOTE and Threshold adjustment for 5-fold cross-validation...\")\n",
    "best_params_5folds, best_threshold_5folds, best_f1_5folds, final_mcc_5folds = runDTWithSMOTE(\n",
    "    dataPoints, dataLabelsList, outDir, n_splits=5)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Decision Tree with SMOTE and Threshold adjustment 5-fold cross-validation:\")\n",
    "print(f\"Best Parameters: {best_params_5folds}\")\n",
    "print(f\"Best Threshold: {best_threshold_5folds}\")\n",
    "print(f\"Best F1 Score: {best_f1_5folds}\")\n",
    "print(f\"Final MCC: {final_mcc_5folds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a3554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
