{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a42537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents (equal combination): 45\n",
      "Number of non-flaky documents (equal combination): 45\n",
      "Total number of documents (equal combination): 90\n",
      "Number of flaky documents (larger combination): 45\n",
      "Number of non-flaky documents (larger combination): 254\n",
      "Total number of documents (larger combination): 299\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints):\n",
    "    \"\"\"Performs vectorization using CountVectorizer.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z = countVec.fit_transform(dataPoints)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Data Extraction and Vectorization\n",
    "\n",
    "# Parameters setup\n",
    "flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "# Create directories\n",
    "outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "outDirLarger = \"results/larger_nonflaky/\"\n",
    "os.makedirs(outDirEqual, exist_ok=True)\n",
    "os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "os.makedirs(extractDirEqual, exist_ok=True)\n",
    "os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "# Extract and read data once for equal combination\n",
    "flakyDirEqual = os.path.join(extractDirEqual, 'flaky')\n",
    "nonFlakyDirEqual = os.path.join(extractDirEqual, 'nonFlaky')\n",
    "os.makedirs(flakyDirEqual, exist_ok=True)\n",
    "os.makedirs(nonFlakyDirEqual, exist_ok=True)\n",
    "\n",
    "extract_zip(flakyZip, flakyDirEqual)\n",
    "extract_zip(nonFlakyZip, nonFlakyDirEqual)\n",
    "\n",
    "dataPointsFlakyEqual = getDataPoints(flakyDirEqual)\n",
    "dataPointsNonFlakyEqual = getDataPoints(nonFlakyDirEqual)\n",
    "dataPointsEqual = dataPointsFlakyEqual + dataPointsNonFlakyEqual\n",
    "\n",
    "# Print the number of datasets for equal combination\n",
    "print(f\"Number of flaky documents (equal combination): {len(dataPointsFlakyEqual)}\")\n",
    "print(f\"Number of non-flaky documents (equal combination): {len(dataPointsNonFlakyEqual)}\")\n",
    "print(f\"Total number of documents (equal combination): {len(dataPointsEqual)}\")\n",
    "\n",
    "dataLabelsListEqual = np.array([1]*len(dataPointsFlakyEqual) + [0]*len(dataPointsNonFlakyEqual))\n",
    "\n",
    "# Vectorize data once\n",
    "Z_equal = flastVectorization(dataPointsEqual)\n",
    "\n",
    "# Extract and read data once for larger non-flaky combination\n",
    "flakyDirLarger = os.path.join(extractDirLarger, 'flaky')\n",
    "nonFlakyDirLarger = os.path.join(extractDirLarger, 'nonFlaky')\n",
    "os.makedirs(flakyDirLarger, exist_ok=True)\n",
    "os.makedirs(nonFlakyDirLarger, exist_ok=True)\n",
    "\n",
    "extract_zip(flakyZip, flakyDirLarger)\n",
    "extract_zip(largerNonFlakyZip, nonFlakyDirLarger)\n",
    "\n",
    "dataPointsFlakyLarger = getDataPoints(flakyDirLarger)\n",
    "dataPointsNonFlakyLarger = getDataPoints(nonFlakyDirLarger)\n",
    "dataPointsLarger = dataPointsFlakyLarger + dataPointsNonFlakyLarger\n",
    "\n",
    "# Print the number of datasets for larger combination\n",
    "print(f\"Number of flaky documents (larger combination): {len(dataPointsFlakyLarger)}\")\n",
    "print(f\"Number of non-flaky documents (larger combination): {len(dataPointsNonFlakyLarger)}\")\n",
    "print(f\"Total number of documents (larger combination): {len(dataPointsLarger)}\")\n",
    "\n",
    "dataLabelsListLarger = np.array([1]*len(dataPointsFlakyLarger) + [0]*len(dataPointsNonFlakyLarger))\n",
    "\n",
    "Z_larger = flastVectorization(dataPointsLarger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304d035",
   "metadata": {},
   "source": [
    "## KNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "540d06d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting KNN analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "Best F1 Score: 0.7894117647058824\n",
      "KNN analysis completed for 5-folds. Results saved to: equal-params-knn-5-folds.csv\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Best F1 Score: 0.7699905033238367\n",
      "KNN analysis completed for 3-folds. Results saved to: equal-params-knn-3-folds.csv\n",
      "\n",
      "Best results for KNN 5-fold on equal combination:\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "Best F1 Score: 0.7894117647058824\n",
      "\n",
      "Best results for KNN 3-fold on equal combination:\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Best F1 Score: 0.7699905033238367\n",
      "\n",
      "Starting KNN analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "************SAHPE od DATA: (299, 11986)\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.4906410256410256\n",
      "KNN analysis completed for 5-folds. Results saved to: larger-params-knn-5-folds.csv\n",
      "************SAHPE od DATA: (299, 11986)\n",
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.49930986887508627\n",
      "KNN analysis completed for 3-folds. Results saved to: larger-params-knn-3-folds.csv\n",
      "\n",
      "Best results for KNN 5-fold on larger combination:\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.4906410256410256\n",
      "\n",
      "Best results for KNN 3-fold on larger combination:\n",
      "Best Parameters: {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.49930986887508627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def runKNN(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "    print(\"************SAHPE od DATA:\", Z.shape)\n",
    " \n",
    "    \n",
    "    # Define the KNN model\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11, 15, 20],\n",
    "        'metric': ['cosine', 'euclidean'],  # Distance metrics\n",
    "        'weights': ['uniform', 'distance'],  # Neighbor weighting schemes\n",
    "    }\n",
    "\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),  \n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': make_scorer(matthews_corrcoef)\n",
    "\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-knn-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"n_neighbors,metric,weights,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            mcc = grid_search.cv_results_['mean_test_mcc'][idx]\n",
    "\n",
    "            \n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['n_neighbors']},{param['metric']},{param['weights']},{accuracy},{precision},{recall},{f1},{mcc},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"KNN analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run KNN on equal combination\n",
    "print(\"\\nStarting KNN analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_knn_equal, best_score_5folds_knn_equal = runKNN(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_knn_equal, best_score_3folds_knn_equal = runKNN(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for KNN 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_knn_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_knn_equal}\")\n",
    "\n",
    "print(\"\\nBest results for KNN 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_knn_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_knn_equal}\")\n",
    "\n",
    "# Run KNN on larger non-flaky combination\n",
    "print(\"\\nStarting KNN analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_knn_larger, best_score_5folds_knn_larger = runKNN(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_knn_larger, best_score_3folds_knn_larger = runKNN(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for KNN 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_knn_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_knn_larger}\")\n",
    "\n",
    "print(\"\\nBest results for KNN 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_knn_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_knn_larger}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1a814",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410e6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e4436c1",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba4000e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting SVM analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7834279325765394\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7422003284072249\n",
      "\n",
      "Best results for SVM 5-fold on equal combination:\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7834279325765394\n",
      "\n",
      "Best results for SVM 3-fold on equal combination:\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7422003284072249\n",
      "\n",
      "Starting SVM analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "************SAHPE od DATA: (299, 11986)\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.5901648351648352\n",
      "************SAHPE od DATA: (299, 11986)\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.6675450153711023\n",
      "\n",
      "Best results for SVM 5-fold on larger combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.5901648351648352\n",
      "\n",
      "Best results for SVM 3-fold on larger combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.6675450153711023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "\n",
    "\n",
    "def runSVM(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()    \n",
    "    print(\"************SAHPE od DATA:\", Z.shape)\n",
    "\n",
    "    # Define the SVM model\n",
    "    svm = SVC()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization parameter\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # Kernel types\n",
    "    }\n",
    "\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': make_scorer(matthews_corrcoef)\n",
    "\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    outFile = f\"{combination_label}-params-svm-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"n_neighbors,metric,weights,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            mcc = grid_search.cv_results_['mean_test_mcc'][idx]\n",
    "\n",
    "            \n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['C']},{param['kernel']},{accuracy},{precision},{recall},{f1},{mcc},{preparationTime}\\n\")\n",
    "\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run SVM on equal combination\n",
    "print(\"\\nStarting SVM analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_svm_equal, best_score_5folds_svm_equal = runSVM(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_svm_equal, best_score_3folds_svm_equal = runSVM(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_svm_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_svm_equal}\")\n",
    "\n",
    "print(\"\\nBest results for SVM 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_svm_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_svm_equal}\")\n",
    "\n",
    "# Run SVM on larger non-flaky combination\n",
    "print(\"\\nStarting SVM analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_svm_larger, best_score_5folds_svm_larger = runSVM(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_svm_larger, best_score_3folds_svm_larger = runSVM(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_svm_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_svm_larger}\")\n",
    "\n",
    "print(\"\\nBest results for SVM 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_svm_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_svm_larger}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2dd8f",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "554dd8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting NB analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'alpha': 0.01}\n",
      "Best F1 Score: 0.7342533936651584\n",
      "Naive Bayes analysis completed for 5-folds. Results saved to: equal-params-nb-5-folds.csv\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Parameters: {'alpha': 0.001}\n",
      "Best F1 Score: 0.7428735632183908\n",
      "Naive Bayes analysis completed for 3-folds. Results saved to: equal-params-nb-3-folds.csv\n",
      "\n",
      "Best results for NB 5-fold on equal combination:\n",
      "Best Parameters: {'alpha': 0.01}\n",
      "Best F1 Score: 0.7342533936651584\n",
      "\n",
      "Best results for NB 3-fold on equal combination:\n",
      "Best Parameters: {'alpha': 0.001}\n",
      "Best F1 Score: 0.7428735632183908\n",
      "\n",
      "Starting NB analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "************SAHPE od DATA: (299, 11986)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'alpha': 0.001}\n",
      "Best F1 Score: 0.6996031746031746\n",
      "Naive Bayes analysis completed for 5-folds. Results saved to: larger-params-nb-5-folds.csv\n",
      "************SAHPE od DATA: (299, 11986)\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Parameters: {'alpha': 0.1}\n",
      "Best F1 Score: 0.7162068965517241\n",
      "Naive Bayes analysis completed for 3-folds. Results saved to: larger-params-nb-3-folds.csv\n",
      "\n",
      "Best results for NB 5-fold on larger combination:\n",
      "Best Parameters: {'alpha': 0.001}\n",
      "Best F1 Score: 0.6996031746031746\n",
      "\n",
      "Best results for NB 3-fold on larger combination:\n",
      "Best Parameters: {'alpha': 0.1}\n",
      "Best F1 Score: 0.7162068965517241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "def runNB(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "    print(\"************SAHPE od DATA:\", Z.shape)\n",
    "\n",
    "    # Define the NB model\n",
    "    nb = MultinomialNB()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0], \n",
    "    }\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': make_scorer(matthews_corrcoef)\n",
    "\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(nb, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-nb-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"alpha,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            mcc = grid_search.cv_results_['mean_test_mcc'][idx]\n",
    "\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['alpha']},{accuracy},{precision},{recall},{f1},{mcc},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"Naive Bayes analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run NB on equal combination\n",
    "print(\"\\nStarting NB analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_nb_equal, best_score_5folds_nb_equal = runNB(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_nb_equal, best_score_3folds_nb_equal = runNB(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for NB 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_nb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_nb_equal}\")\n",
    "\n",
    "print(\"\\nBest results for NB 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_nb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_nb_equal}\")\n",
    "\n",
    "# Run NB on larger non-flaky combination\n",
    "print(\"\\nStarting NB analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_nb_larger, best_score_5folds_nb_larger = runNB(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_nb_larger, best_score_3folds_nb_larger = runNB(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for NB 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_nb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_nb_larger}\")\n",
    "\n",
    "print(\"\\nBest results for NB 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_nb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_nb_larger}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8185e97",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac1b2a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGBoost analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best Parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best F1 Score: 0.8720367094206104\n",
      "XGBoost analysis completed for 5-folds. Results saved to: equal-params-xgb-5-folds.csv\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "Best Parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "Best F1 Score: 0.8780172413793105\n",
      "XGBoost analysis completed for 3-folds. Results saved to: equal-params-xgb-3-folds.csv\n",
      "\n",
      "Best results for XGBoost 5-fold on equal combination:\n",
      "Best Parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best F1 Score: 0.8720367094206104\n",
      "\n",
      "Best results for XGBoost 3-fold on equal combination:\n",
      "Best Parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "Best F1 Score: 0.8780172413793105\n",
      "\n",
      "Starting XGBoost analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "************SAHPE od DATA: (299, 11986)\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best Parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best F1 Score: 0.858235294117647\n",
      "XGBoost analysis completed for 5-folds. Results saved to: larger-params-xgb-5-folds.csv\n",
      "************SAHPE od DATA: (299, 11986)\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "Best Parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 50}\n",
      "Best F1 Score: 0.8724867724867725\n",
      "XGBoost analysis completed for 3-folds. Results saved to: larger-params-xgb-3-folds.csv\n",
      "\n",
      "Best results for XGBoost 5-fold on larger combination:\n",
      "Best Parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best F1 Score: 0.858235294117647\n",
      "\n",
      "Best results for XGBoost 3-fold on larger combination:\n",
      "Best Parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 50}\n",
      "Best F1 Score: 0.8724867724867725\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def runXGB(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "    print(\"************SAHPE od DATA:\", Z.shape)\n",
    "\n",
    "    # Define XGBoost model\n",
    "    xgb_model = XGBClassifier(eval_metric=\"logloss\")\n",
    "\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'eta': [0.01, 0.1, 0.3, 0.5],  # Learning rate\n",
    "        'max_depth': [3, 5, 7, 10],    # Tree depth\n",
    "        'n_estimators': [50, 100, 200, 300],  # Number of boosting rounds\n",
    "    }\n",
    "\n",
    "    # Custom scoring functions (without MCC)\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),  # Handle undefined precision\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),  # Handle undefined F1 score\n",
    "        'mcc': make_scorer(matthews_corrcoef)\n",
    "\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(\n",
    "        xgb_model, param_grid, cv=skf, scoring=scoring,\n",
    "        refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for F1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-xgb-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"eta,max_depth,n_estimators,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            mcc = grid_search.cv_results_['mean_test_mcc'][idx]\n",
    "\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['eta']},{param['max_depth']},{param['n_estimators']},{accuracy},{precision},{recall},{f1},{mcc},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"XGBoost analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run XGBoost on equal combination\n",
    "print(\"\\nStarting XGBoost analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_xgb_equal, best_score_5folds_xgb_equal = runXGB(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_xgb_equal, best_score_3folds_xgb_equal = runXGB(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for XGBoost 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_xgb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_xgb_equal}\")\n",
    "\n",
    "print(\"\\nBest results for XGBoost 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_xgb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_xgb_equal}\")\n",
    "\n",
    "# Run XGBoost on larger non-flaky combination\n",
    "print(\"\\nStarting XGBoost analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_xgb_larger, best_score_5folds_xgb_larger = runXGB(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_xgb_larger, best_score_3folds_xgb_larger = runXGB(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for XGBoost 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_xgb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_xgb_larger}\")\n",
    "\n",
    "print(\"\\nBest results for XGBoost 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_xgb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_xgb_larger}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f73beb",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2eeed817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Random Forest analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "Best Parameters: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best F1 Score: 0.8860484544695071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'criterion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Run Random Forest on equal combination\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting Random Forest analysis for flaky vs smaller non-flaky files (equal combination)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m best_params_5folds_rf_equal, best_score_5folds_rf_equal \u001b[38;5;241m=\u001b[39m runRF(Z_equal, dataLabelsListEqual, outDirEqual, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m best_params_3folds_rf_equal, best_score_3folds_rf_equal \u001b[38;5;241m=\u001b[39m runRF(Z_equal, dataLabelsListEqual, outDirEqual, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[42], line 59\u001b[0m, in \u001b[0;36mrunRF\u001b[1;34m(Z, dataLabelsList, outDir, n_splits, combination_label)\u001b[0m\n\u001b[0;32m     56\u001b[0m         mcc \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_mcc\u001b[39m\u001b[38;5;124m'\u001b[39m][idx]\n\u001b[0;32m     58\u001b[0m         preparationTime \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m v0) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataLabelsList)  \n\u001b[1;32m---> 59\u001b[0m         fo\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmcc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreparationTime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest analysis completed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_splits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-folds. Results saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutFile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_params, best_score\n",
      "\u001b[1;31mKeyError\u001b[0m: 'criterion'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def runRF(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "    print(\"************SAHPE od DATA:\", Z.shape)\n",
    "\n",
    "    # Define the Random Forest model\n",
    "    rf_model = RandomForestClassifier()\n",
    "\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200, 300],  # Number of trees in the forest\n",
    "        'max_depth': [3, 5, 7, 10, None],  # Maximum depth of the tree\n",
    "        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
    "    }\n",
    "\n",
    "    # Custom scoring functions (without MCC)\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': make_scorer(matthews_corrcoef)\n",
    "\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(\n",
    "        rf_model, param_grid, cv=skf, scoring=scoring,\n",
    "        refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for F1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-rf-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"n_estimators,max_depth,min_samples_split,min_samples_leaf,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            mcc = grid_search.cv_results_['mean_test_mcc'][idx]\n",
    "\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['n_estimators']},{param['max_depth']},{param['min_samples_split']},{param['min_samples_leaf']},{param['criterion']},{accuracy},{precision},{recall},{f1},{mcc},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"Random Forest analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run Random Forest on equal combination\n",
    "print(\"\\nStarting Random Forest analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_rf_equal, best_score_5folds_rf_equal = runRF(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_rf_equal, best_score_3folds_rf_equal = runRF(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Random Forest 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_rf_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_rf_equal}\")\n",
    "\n",
    "print(\"\\nBest results for Random Forest 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_rf_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_rf_equal}\")\n",
    "\n",
    "# Run Random Forest on larger non-flaky combination\n",
    "print(\"\\nStarting Random Forest analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_rf_larger, best_score_5folds_rf_larger = runRF(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_rf_larger, best_score_3folds_rf_larger = runRF(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Random Forest 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_rf_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_rf_larger}\")\n",
    "\n",
    "print(\"\\nBest results for Random Forest 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_rf_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_rf_larger}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c09b9",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def runDT(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "    print(\"************SAHPE od DATA:\", Z.shape)\n",
    "\n",
    "    # Define the Decision Tree model\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "        'max_depth': [None, 10, 30, 50, 100, 300, 500],  # Maximum depth of each tree\n",
    "        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 5, 10],  # Minimum number of samples required to be at a leaf node\n",
    "        'max_features': [None, 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    }\n",
    "\n",
    "    # Custom scoring functions (without MCC)\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),  \n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': make_scorer(matthews_corrcoef)\n",
    "\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(\n",
    "        dt_model, param_grid, cv=skf, scoring=scoring,\n",
    "        refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for F1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"criterion,max_depth,min_samples_split,min_samples_leaf,max_features,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            mcc = grid_search.cv_results_['mean_test_mcc'][idx]\n",
    "\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['criterion']},{param['max_depth']},{param['min_samples_split']},{param['min_samples_leaf']},{param['max_features']},{accuracy},{precision},{recall},{f1},{mcc},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run Decision Tree on equal combination\n",
    "print(\"\\nStarting Decision Tree analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_dt_equal, best_score_5folds_dt_equal = runDT(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_dt_equal, best_score_3folds_dt_equal = runDT(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Decision Tree 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_dt_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_dt_equal}\")\n",
    "\n",
    "print(\"\\nBest results for Decision Tree 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_dt_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_dt_equal}\")\n",
    "\n",
    "# Run Decision Tree on larger non-flaky combination\n",
    "print(\"\\nStarting Decision Tree analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_dt_larger, best_score_5folds_dt_larger = runDT(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_dt_larger, best_score_3folds_dt_larger = runDT(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for Decision Tree 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_dt_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_dt_larger}\")\n",
    "\n",
    "print(\"\\nBest results for Decision Tree 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_dt_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_dt_larger}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428cec90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
