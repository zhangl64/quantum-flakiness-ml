{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e03351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: equal-params-dt-5-folds-Threshold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: equal-params-dt-3-folds-Threshold.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.6611732229123534, 'accuracy': 0.6163742690058479, 'precision': 0.6089466089466089, 'recall': 0.7422222222222222, 'mcc': 0.24063172927077958}, 0.2: {'f1': 0.6611732229123534, 'accuracy': 0.6163742690058479, 'precision': 0.6089466089466089, 'recall': 0.7422222222222222, 'mcc': 0.24063172927077958}, 0.30000000000000004: {'f1': 0.6611732229123534, 'accuracy': 0.6163742690058479, 'precision': 0.6089466089466089, 'recall': 0.7422222222222222, 'mcc': 0.24063172927077958}, 0.4: {'f1': 0.6711111111111111, 'accuracy': 0.6374269005847953, 'precision': 0.6232323232323231, 'recall': 0.7422222222222222, 'mcc': 0.2846701982983649}, 0.5: {'f1': 0.6711111111111111, 'accuracy': 0.6374269005847953, 'precision': 0.6232323232323231, 'recall': 0.7422222222222222, 'mcc': 0.2846701982983649}, 0.6: {'f1': 0.6650505050505051, 'accuracy': 0.6374269005847953, 'precision': 0.6242579642579642, 'recall': 0.72, 'mcc': 0.27966290551620937}, 0.7000000000000001: {'f1': 0.6436125965537729, 'accuracy': 0.6269005847953215, 'precision': 0.6281468531468531, 'recall': 0.6777777777777778, 'mcc': 0.2610942127175587}, 0.8: {'f1': 0.6436125965537729, 'accuracy': 0.6269005847953215, 'precision': 0.6281468531468531, 'recall': 0.6777777777777778, 'mcc': 0.2610942127175587}, 0.9: {'f1': 0.6436125965537729, 'accuracy': 0.6269005847953215, 'precision': 0.6281468531468531, 'recall': 0.6777777777777778, 'mcc': 0.2610942127175587}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.6840686274509804, 'accuracy': 0.680779569892473, 'precision': 0.6715225563909774, 'recall': 0.7055555555555556, 'mcc': 0.3698556312832304}, 0.2: {'f1': 0.6840686274509804, 'accuracy': 0.680779569892473, 'precision': 0.6715225563909774, 'recall': 0.7055555555555556, 'mcc': 0.3698556312832304}, 0.30000000000000004: {'f1': 0.6840686274509804, 'accuracy': 0.680779569892473, 'precision': 0.6715225563909774, 'recall': 0.7055555555555556, 'mcc': 0.3698556312832304}, 0.4: {'f1': 0.6617985125084517, 'accuracy': 0.6703629032258064, 'precision': 0.6731251204935416, 'recall': 0.6638888888888889, 'mcc': 0.3509030917791934}, 0.5: {'f1': 0.6617985125084517, 'accuracy': 0.6703629032258064, 'precision': 0.6731251204935416, 'recall': 0.6638888888888889, 'mcc': 0.3509030917791934}, 0.6: {'f1': 0.6567099567099567, 'accuracy': 0.67002688172043, 'precision': 0.6865079365079364, 'recall': 0.6416666666666667, 'mcc': 0.3492800343463746}, 0.7000000000000001: {'f1': 0.6314604935294591, 'accuracy': 0.6592741935483871, 'precision': 0.6940170940170941, 'recall': 0.6, 'mcc': 0.33457468100081594}, 0.8: {'f1': 0.6314604935294591, 'accuracy': 0.6592741935483871, 'precision': 0.6940170940170941, 'recall': 0.6, 'mcc': 0.33457468100081594}, 0.9: {'f1': 0.6314604935294591, 'accuracy': 0.6592741935483871, 'precision': 0.6940170940170941, 'recall': 0.6, 'mcc': 0.33457468100081594}}\n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: larger-params-dt-5-folds-Threshold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: larger-params-dt-3-folds-Threshold.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.4636819613135403, 'accuracy': 0.823879781420765, 'precision': 0.45883838383838393, 'recall': 0.49111111111111116, 'mcc': 0.3671760353873348}, 0.2: {'f1': 0.4636819613135403, 'accuracy': 0.823879781420765, 'precision': 0.45883838383838393, 'recall': 0.49111111111111116, 'mcc': 0.3671760353873348}, 0.30000000000000004: {'f1': 0.47257085020242917, 'accuracy': 0.8305464480874317, 'precision': 0.475, 'recall': 0.49111111111111116, 'mcc': 0.379761608129611}, 0.4: {'f1': 0.4758697838109603, 'accuracy': 0.8406010928961749, 'precision': 0.5089682539682541, 'recall': 0.47111111111111115, 'mcc': 0.39270846194837994}, 0.5: {'f1': 0.4758697838109603, 'accuracy': 0.8406010928961749, 'precision': 0.5089682539682541, 'recall': 0.47111111111111115, 'mcc': 0.39270846194837994}, 0.6: {'f1': 0.4242763772175537, 'accuracy': 0.8306010928961749, 'precision': 0.47777777777777786, 'recall': 0.4066666666666666, 'mcc': 0.33806002013962416}, 0.7000000000000001: {'f1': 0.38676721970839617, 'accuracy': 0.8239344262295083, 'precision': 0.44825396825396824, 'recall': 0.36444444444444446, 'mcc': 0.29806323466652757}, 0.8: {'f1': 0.40010055304172953, 'accuracy': 0.8372677595628415, 'precision': 0.47111111111111115, 'recall': 0.36444444444444446, 'mcc': 0.3188178658240155}, 0.9: {'f1': 0.40010055304172953, 'accuracy': 0.8372677595628415, 'precision': 0.47111111111111115, 'recall': 0.36444444444444446, 'mcc': 0.3188178658240155}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.5378151260504201, 'accuracy': 0.8405940594059406, 'precision': 0.4902534113060429, 'recall': 0.5972222222222222, 'mcc': 0.4462799412741485}, 0.2: {'f1': 0.5378151260504201, 'accuracy': 0.8405940594059406, 'precision': 0.4902534113060429, 'recall': 0.5972222222222222, 'mcc': 0.4462799412741485}, 0.30000000000000004: {'f1': 0.5378151260504201, 'accuracy': 0.8405940594059406, 'precision': 0.4902534113060429, 'recall': 0.5972222222222222, 'mcc': 0.4462799412741485}, 0.4: {'f1': 0.5383297258297258, 'accuracy': 0.8472607260726073, 'precision': 0.5085784313725491, 'recall': 0.5763888888888888, 'mcc': 0.45012189277866493}, 0.5: {'f1': 0.5383297258297258, 'accuracy': 0.8472607260726073, 'precision': 0.5085784313725491, 'recall': 0.5763888888888888, 'mcc': 0.45012189277866493}, 0.6: {'f1': 0.42484567901234566, 'accuracy': 0.8305280528052804, 'precision': 0.45543672014260245, 'recall': 0.4055555555555556, 'mcc': 0.32983672761800203}, 0.7000000000000001: {'f1': 0.4295499800876145, 'accuracy': 0.8338613861386138, 'precision': 0.46401515151515155, 'recall': 0.4055555555555556, 'mcc': 0.336379329761126}, 0.8: {'f1': 0.41685156738920176, 'accuracy': 0.8338613861386138, 'precision': 0.46401515151515155, 'recall': 0.38472222222222224, 'mcc': 0.3257912787014097}, 0.9: {'f1': 0.41685156738920176, 'accuracy': 0.8338613861386138, 'precision': 0.46401515151515155, 'recall': 0.38472222222222224, 'mcc': 0.3257912787014097}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define Decision Tree model with given parameters\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=params.get('criterion', 'entropy'),\n",
    "        max_depth=params.get('max_depth', None),\n",
    "        min_samples_split=params.get('min_samples_split', 2),\n",
    "        min_samples_leaf=params.get('min_samples_leaf', 1),\n",
    "        max_features=params.get('max_features', None),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "        # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize metrics storage for each threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_threshold = {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                             for threshold in thresholds}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Accumulate metrics for the current threshold\n",
    "            metrics_per_threshold[threshold]['f1'] += f1\n",
    "            metrics_per_threshold[threshold]['accuracy'] += accuracy\n",
    "            metrics_per_threshold[threshold]['precision'] += precision\n",
    "            metrics_per_threshold[threshold]['recall'] += recall\n",
    "            metrics_per_threshold[threshold]['mcc'] += mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Average metrics over all folds\n",
    "    for threshold in thresholds:\n",
    "        metrics_per_threshold[threshold]['f1'] /= successFold\n",
    "        metrics_per_threshold[threshold]['accuracy'] /= successFold\n",
    "        metrics_per_threshold[threshold]['precision'] /= successFold\n",
    "        metrics_per_threshold[threshold]['recall'] /= successFold\n",
    "        metrics_per_threshold[threshold]['mcc'] /= successFold\n",
    "\n",
    "    # Save the results for each threshold\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each threshold\n",
    "        for threshold in thresholds:\n",
    "            fo.write(f\"{threshold},{metrics_per_threshold[threshold]['accuracy']},{metrics_per_threshold[threshold]['precision']},\"\n",
    "                     f\"{metrics_per_threshold[threshold]['recall']},{metrics_per_threshold[threshold]['f1']},{metrics_per_threshold[threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_threshold\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    params = {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"max_depth\": 300,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\" : 'log2'\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3c980",
   "metadata": {},
   "source": [
    "Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c255f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: equal-params-dt-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: equal-params-dt-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.7777777777777778, 'accuracy': 0.7894736842105263, 'precision': 0.875, 'recall': 0.7, 'mcc': 0.5955432118425306}, 0.2: {'f1': 0.7777777777777778, 'accuracy': 0.7894736842105263, 'precision': 0.875, 'recall': 0.7, 'mcc': 0.5955432118425306}, 0.30000000000000004: {'f1': 0.7777777777777778, 'accuracy': 0.7894736842105263, 'precision': 0.875, 'recall': 0.7, 'mcc': 0.5955432118425306}, 0.4: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.5: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.6: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.7000000000000001: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.8: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.9: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}}, 2: {0.1: {'f1': 0.5, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.5, 'mcc': -0.05555555555555555}, 0.2: {'f1': 0.5, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.5, 'mcc': -0.05555555555555555}, 0.30000000000000004: {'f1': 0.5, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.5, 'mcc': -0.05555555555555555}, 0.4: {'f1': 0.5, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.5, 'mcc': -0.05555555555555555}, 0.5: {'f1': 0.5, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.5, 'mcc': -0.05555555555555555}, 0.6: {'f1': 0.5, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.5, 'mcc': -0.05555555555555555}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.5, 'mcc': -0.05555555555555555}, 0.8: {'f1': 0.5, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.5, 'mcc': -0.05555555555555555}, 0.9: {'f1': 0.5, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.5, 'mcc': -0.05555555555555555}}, 3: {0.1: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4, 'recall': 0.4444444444444444, 'mcc': -0.15555555555555556}, 0.2: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4, 'recall': 0.4444444444444444, 'mcc': -0.15555555555555556}, 0.30000000000000004: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4, 'recall': 0.4444444444444444, 'mcc': -0.15555555555555556}, 0.4: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4, 'recall': 0.4444444444444444, 'mcc': -0.15555555555555556}, 0.5: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4, 'recall': 0.4444444444444444, 'mcc': -0.15555555555555556}, 0.6: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4, 'recall': 0.4444444444444444, 'mcc': -0.15555555555555556}, 0.7000000000000001: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4, 'recall': 0.4444444444444444, 'mcc': -0.15555555555555556}, 0.8: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4, 'recall': 0.4444444444444444, 'mcc': -0.15555555555555556}, 0.9: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4, 'recall': 0.4444444444444444, 'mcc': -0.15555555555555556}}, 4: {0.1: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}, 0.2: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}, 0.30000000000000004: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}, 0.4: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}, 0.5: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}, 0.6: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}, 0.7000000000000001: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}, 0.8: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}, 0.9: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}}, 5: {0.1: {'f1': 0.5333333333333333, 'accuracy': 0.6111111111111112, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.2357022603955158}, 0.2: {'f1': 0.5333333333333333, 'accuracy': 0.6111111111111112, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.2357022603955158}, 0.30000000000000004: {'f1': 0.5333333333333333, 'accuracy': 0.6111111111111112, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.2357022603955158}, 0.4: {'f1': 0.5333333333333333, 'accuracy': 0.6111111111111112, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.2357022603955158}, 0.5: {'f1': 0.5333333333333333, 'accuracy': 0.6111111111111112, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.2357022603955158}, 0.6: {'f1': 0.5333333333333333, 'accuracy': 0.6111111111111112, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.2357022603955158}, 0.7000000000000001: {'f1': 0.5333333333333333, 'accuracy': 0.6111111111111112, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.2357022603955158}, 0.8: {'f1': 0.5333333333333333, 'accuracy': 0.6111111111111112, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.2357022603955158}, 0.9: {'f1': 0.5333333333333333, 'accuracy': 0.6111111111111112, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.2357022603955158}}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.717948717948718, 'accuracy': 0.65625, 'precision': 0.6086956521739131, 'recall': 0.875, 'mcc': 0.34752402342845795}, 0.2: {'f1': 0.717948717948718, 'accuracy': 0.65625, 'precision': 0.6086956521739131, 'recall': 0.875, 'mcc': 0.34752402342845795}, 0.30000000000000004: {'f1': 0.7027027027027027, 'accuracy': 0.65625, 'precision': 0.6190476190476191, 'recall': 0.8125, 'mcc': 0.3289758474798845}, 0.4: {'f1': 0.7058823529411765, 'accuracy': 0.6875, 'precision': 0.6666666666666666, 'recall': 0.75, 'mcc': 0.3779644730092272}, 0.5: {'f1': 0.7058823529411765, 'accuracy': 0.6875, 'precision': 0.6666666666666666, 'recall': 0.75, 'mcc': 0.3779644730092272}, 0.6: {'f1': 0.7058823529411765, 'accuracy': 0.6875, 'precision': 0.6666666666666666, 'recall': 0.75, 'mcc': 0.3779644730092272}, 0.7000000000000001: {'f1': 0.7272727272727273, 'accuracy': 0.71875, 'precision': 0.7058823529411765, 'recall': 0.75, 'mcc': 0.4383570037596047}, 0.8: {'f1': 0.7272727272727273, 'accuracy': 0.71875, 'precision': 0.7058823529411765, 'recall': 0.75, 'mcc': 0.4383570037596047}, 0.9: {'f1': 0.7272727272727273, 'accuracy': 0.71875, 'precision': 0.7058823529411765, 'recall': 0.75, 'mcc': 0.4383570037596047}}, 2: {0.1: {'f1': 0.7428571428571429, 'accuracy': 0.7096774193548387, 'precision': 0.6842105263157895, 'recall': 0.8125, 'mcc': 0.4232160702351261}, 0.2: {'f1': 0.7428571428571429, 'accuracy': 0.7096774193548387, 'precision': 0.6842105263157895, 'recall': 0.8125, 'mcc': 0.4232160702351261}, 0.30000000000000004: {'f1': 0.6875, 'accuracy': 0.6774193548387096, 'precision': 0.6875, 'recall': 0.6875, 'mcc': 0.3541666666666667}, 0.4: {'f1': 0.6875, 'accuracy': 0.6774193548387096, 'precision': 0.6875, 'recall': 0.6875, 'mcc': 0.3541666666666667}, 0.5: {'f1': 0.6875, 'accuracy': 0.6774193548387096, 'precision': 0.6875, 'recall': 0.6875, 'mcc': 0.3541666666666667}, 0.6: {'f1': 0.6875, 'accuracy': 0.6774193548387096, 'precision': 0.6875, 'recall': 0.6875, 'mcc': 0.3541666666666667}, 0.7000000000000001: {'f1': 0.6875, 'accuracy': 0.6774193548387096, 'precision': 0.6875, 'recall': 0.6875, 'mcc': 0.3541666666666667}, 0.8: {'f1': 0.6875, 'accuracy': 0.6774193548387096, 'precision': 0.6875, 'recall': 0.6875, 'mcc': 0.3541666666666667}, 0.9: {'f1': 0.6875, 'accuracy': 0.6774193548387096, 'precision': 0.6875, 'recall': 0.6875, 'mcc': 0.3541666666666667}}, 3: {0.1: {'f1': 0.5806451612903226, 'accuracy': 0.5806451612903226, 'precision': 0.5625, 'recall': 0.6, 'mcc': 0.1625}, 0.2: {'f1': 0.5806451612903226, 'accuracy': 0.5806451612903226, 'precision': 0.5625, 'recall': 0.6, 'mcc': 0.1625}, 0.30000000000000004: {'f1': 0.5806451612903226, 'accuracy': 0.5806451612903226, 'precision': 0.5625, 'recall': 0.6, 'mcc': 0.1625}, 0.4: {'f1': 0.5806451612903226, 'accuracy': 0.5806451612903226, 'precision': 0.5625, 'recall': 0.6, 'mcc': 0.1625}, 0.5: {'f1': 0.5806451612903226, 'accuracy': 0.5806451612903226, 'precision': 0.5625, 'recall': 0.6, 'mcc': 0.1625}, 0.6: {'f1': 0.48, 'accuracy': 0.5806451612903226, 'precision': 0.6, 'recall': 0.4, 'mcc': 0.16035674514745463}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.6129032258064516, 'precision': 0.6666666666666666, 'recall': 0.4, 'mcc': 0.23395480008935163}, 0.8: {'f1': 0.5, 'accuracy': 0.6129032258064516, 'precision': 0.6666666666666666, 'recall': 0.4, 'mcc': 0.23395480008935163}, 0.9: {'f1': 0.5, 'accuracy': 0.6129032258064516, 'precision': 0.6666666666666666, 'recall': 0.4, 'mcc': 0.23395480008935163}}}\n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: larger-params-dt-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: larger-params-dt-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.43478260869565216, 'accuracy': 0.7868852459016393, 'precision': 0.38461538461538464, 'recall': 0.5, 'mcc': 0.31021348007089783}, 0.2: {'f1': 0.43478260869565216, 'accuracy': 0.7868852459016393, 'precision': 0.38461538461538464, 'recall': 0.5, 'mcc': 0.31021348007089783}, 0.30000000000000004: {'f1': 0.43478260869565216, 'accuracy': 0.7868852459016393, 'precision': 0.38461538461538464, 'recall': 0.5, 'mcc': 0.31021348007089783}, 0.4: {'f1': 0.45454545454545453, 'accuracy': 0.8032786885245902, 'precision': 0.4166666666666667, 'recall': 0.5, 'mcc': 0.3378298165161036}, 0.5: {'f1': 0.45454545454545453, 'accuracy': 0.8032786885245902, 'precision': 0.4166666666666667, 'recall': 0.5, 'mcc': 0.3378298165161036}, 0.6: {'f1': 0.3, 'accuracy': 0.7704918032786885, 'precision': 0.3, 'recall': 0.3, 'mcc': 0.1627450980392157}, 0.7000000000000001: {'f1': 0.3157894736842105, 'accuracy': 0.7868852459016393, 'precision': 0.3333333333333333, 'recall': 0.3, 'mcc': 0.19035966593076642}, 0.8: {'f1': 0.3157894736842105, 'accuracy': 0.7868852459016393, 'precision': 0.3333333333333333, 'recall': 0.3, 'mcc': 0.19035966593076642}, 0.9: {'f1': 0.3157894736842105, 'accuracy': 0.7868852459016393, 'precision': 0.3333333333333333, 'recall': 0.3, 'mcc': 0.19035966593076642}}, 2: {0.1: {'f1': 0.3225806451612903, 'accuracy': 0.65, 'precision': 0.23809523809523808, 'recall': 0.5, 'mcc': 0.14064216928154863}, 0.2: {'f1': 0.3225806451612903, 'accuracy': 0.65, 'precision': 0.23809523809523808, 'recall': 0.5, 'mcc': 0.14064216928154863}, 0.30000000000000004: {'f1': 0.2962962962962963, 'accuracy': 0.6833333333333333, 'precision': 0.23529411764705882, 'recall': 0.4, 'mcc': 0.11578554637629863}, 0.4: {'f1': 0.2962962962962963, 'accuracy': 0.6833333333333333, 'precision': 0.23529411764705882, 'recall': 0.4, 'mcc': 0.11578554637629863}, 0.5: {'f1': 0.2962962962962963, 'accuracy': 0.6833333333333333, 'precision': 0.23529411764705882, 'recall': 0.4, 'mcc': 0.11578554637629863}, 0.6: {'f1': 0.23076923076923078, 'accuracy': 0.6666666666666666, 'precision': 0.1875, 'recall': 0.3, 'mcc': 0.033709993123162106}, 0.7000000000000001: {'f1': 0.23076923076923078, 'accuracy': 0.6666666666666666, 'precision': 0.1875, 'recall': 0.3, 'mcc': 0.033709993123162106}, 0.8: {'f1': 0.23076923076923078, 'accuracy': 0.6666666666666666, 'precision': 0.1875, 'recall': 0.3, 'mcc': 0.033709993123162106}, 0.9: {'f1': 0.23076923076923078, 'accuracy': 0.6666666666666666, 'precision': 0.1875, 'recall': 0.3, 'mcc': 0.033709993123162106}}, 3: {0.1: {'f1': 0.5, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.6666666666666666, 'mcc': 0.40422604172722165}, 0.2: {'f1': 0.5, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.6666666666666666, 'mcc': 0.40422604172722165}, 0.30000000000000004: {'f1': 0.47619047619047616, 'accuracy': 0.8166666666666667, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': 0.37340802240746923}, 0.4: {'f1': 0.47619047619047616, 'accuracy': 0.8166666666666667, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': 0.37340802240746923}, 0.5: {'f1': 0.47619047619047616, 'accuracy': 0.8166666666666667, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': 0.37340802240746923}, 0.6: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}, 0.7000000000000001: {'f1': 0.5333333333333333, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.48231869560964785}, 0.8: {'f1': 0.5333333333333333, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.48231869560964785}, 0.9: {'f1': 0.5333333333333333, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.48231869560964785}}, 4: {0.1: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}, 0.2: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}, 0.30000000000000004: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}, 0.4: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}, 0.5: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}, 0.6: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}, 0.7000000000000001: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}, 0.8: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}, 0.9: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.4383570037596047}}, 5: {0.1: {'f1': 0.25, 'accuracy': 0.8, 'precision': 0.2857142857142857, 'recall': 0.2222222222222222, 'mcc': 0.13812794737179585}, 0.2: {'f1': 0.25, 'accuracy': 0.8, 'precision': 0.2857142857142857, 'recall': 0.2222222222222222, 'mcc': 0.13812794737179585}, 0.30000000000000004: {'f1': 0.26666666666666666, 'accuracy': 0.8166666666666667, 'precision': 0.3333333333333333, 'recall': 0.2222222222222222, 'mcc': 0.17114534360342343}, 0.4: {'f1': 0.26666666666666666, 'accuracy': 0.8166666666666667, 'precision': 0.3333333333333333, 'recall': 0.2222222222222222, 'mcc': 0.17114534360342343}, 0.5: {'f1': 0.26666666666666666, 'accuracy': 0.8166666666666667, 'precision': 0.3333333333333333, 'recall': 0.2222222222222222, 'mcc': 0.17114534360342343}, 0.6: {'f1': 0.15384615384615385, 'accuracy': 0.8166666666666667, 'precision': 0.25, 'recall': 0.1111111111111111, 'mcc': 0.07484811885651198}, 0.7000000000000001: {'f1': 0.18181818181818182, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.1111111111111111, 'mcc': 0.18201783862232032}, 0.8: {'f1': 0.18181818181818182, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.1111111111111111, 'mcc': 0.18201783862232032}, 0.9: {'f1': 0.18181818181818182, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.1111111111111111, 'mcc': 0.18201783862232032}}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.5555555555555556, 'accuracy': 0.8415841584158416, 'precision': 0.5, 'recall': 0.625, 'mcc': 0.46485994798630487}, 0.2: {'f1': 0.5555555555555556, 'accuracy': 0.8415841584158416, 'precision': 0.5, 'recall': 0.625, 'mcc': 0.46485994798630487}, 0.30000000000000004: {'f1': 0.5555555555555556, 'accuracy': 0.8415841584158416, 'precision': 0.5, 'recall': 0.625, 'mcc': 0.46485994798630487}, 0.4: {'f1': 0.5555555555555556, 'accuracy': 0.8415841584158416, 'precision': 0.5, 'recall': 0.625, 'mcc': 0.46485994798630487}, 0.5: {'f1': 0.5555555555555556, 'accuracy': 0.8415841584158416, 'precision': 0.5, 'recall': 0.625, 'mcc': 0.46485994798630487}, 0.6: {'f1': 0.6451612903225806, 'accuracy': 0.8910891089108911, 'precision': 0.6666666666666666, 'recall': 0.625, 'mcc': 0.5813349261807936}, 0.7000000000000001: {'f1': 0.5714285714285714, 'accuracy': 0.8811881188118812, 'precision': 0.6666666666666666, 'recall': 0.5, 'mcc': 0.511123244138233}, 0.8: {'f1': 0.5714285714285714, 'accuracy': 0.8811881188118812, 'precision': 0.6666666666666666, 'recall': 0.5, 'mcc': 0.511123244138233}, 0.9: {'f1': 0.5714285714285714, 'accuracy': 0.8811881188118812, 'precision': 0.6666666666666666, 'recall': 0.5, 'mcc': 0.511123244138233}}, 2: {0.1: {'f1': 0.6153846153846154, 'accuracy': 0.85, 'precision': 0.5217391304347826, 'recall': 0.75, 'mcc': 0.5392801207044663}, 0.2: {'f1': 0.6153846153846154, 'accuracy': 0.85, 'precision': 0.5217391304347826, 'recall': 0.75, 'mcc': 0.5392801207044663}, 0.30000000000000004: {'f1': 0.6153846153846154, 'accuracy': 0.85, 'precision': 0.5217391304347826, 'recall': 0.75, 'mcc': 0.5392801207044663}, 0.4: {'f1': 0.631578947368421, 'accuracy': 0.86, 'precision': 0.5454545454545454, 'recall': 0.75, 'mcc': 0.558389928096229}, 0.5: {'f1': 0.631578947368421, 'accuracy': 0.86, 'precision': 0.5454545454545454, 'recall': 0.75, 'mcc': 0.558389928096229}, 0.6: {'f1': 0.6285714285714286, 'accuracy': 0.87, 'precision': 0.5789473684210527, 'recall': 0.6875, 'mcc': 0.5534700482779445}, 0.7000000000000001: {'f1': 0.6666666666666666, 'accuracy': 0.89, 'precision': 0.6470588235294118, 'recall': 0.6875, 'mcc': 0.6012667603656328}, 0.8: {'f1': 0.6666666666666666, 'accuracy': 0.89, 'precision': 0.6470588235294118, 'recall': 0.6875, 'mcc': 0.6012667603656328}, 0.9: {'f1': 0.6666666666666666, 'accuracy': 0.89, 'precision': 0.6470588235294118, 'recall': 0.6875, 'mcc': 0.6012667603656328}}, 3: {0.1: {'f1': 0.35294117647058826, 'accuracy': 0.78, 'precision': 0.3157894736842105, 'recall': 0.4, 'mcc': 0.22487239817113244}, 0.2: {'f1': 0.35294117647058826, 'accuracy': 0.78, 'precision': 0.3157894736842105, 'recall': 0.4, 'mcc': 0.22487239817113244}, 0.30000000000000004: {'f1': 0.3870967741935484, 'accuracy': 0.81, 'precision': 0.375, 'recall': 0.4, 'mcc': 0.27500954910846337}, 0.4: {'f1': 0.4, 'accuracy': 0.82, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.29411764705882354}, 0.5: {'f1': 0.4, 'accuracy': 0.82, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.29411764705882354}, 0.6: {'f1': 0.41379310344827586, 'accuracy': 0.83, 'precision': 0.42857142857142855, 'recall': 0.4, 'mcc': 0.31477212878897204}, 0.7000000000000001: {'f1': 0.41379310344827586, 'accuracy': 0.83, 'precision': 0.42857142857142855, 'recall': 0.4, 'mcc': 0.31477212878897204}, 0.8: {'f1': 0.41379310344827586, 'accuracy': 0.83, 'precision': 0.42857142857142855, 'recall': 0.4, 'mcc': 0.31477212878897204}, 0.9: {'f1': 0.41379310344827586, 'accuracy': 0.83, 'precision': 0.42857142857142855, 'recall': 0.4, 'mcc': 0.31477212878897204}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define Decision Tree model with given parameters\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=params.get('criterion', 'entropy'),\n",
    "        max_depth=params.get('max_depth', None),\n",
    "        min_samples_split=params.get('min_samples_split', 2),\n",
    "        min_samples_leaf=params.get('min_samples_leaf', 1),\n",
    "        max_features=params.get('max_features', None),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "       # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_fold = {fold+1: {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                                 for threshold in thresholds}\n",
    "                        for fold in range(n_splits)}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold for this fold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Store metrics for the current threshold for this fold\n",
    "            metrics_per_fold[fold+1][threshold]['f1'] = f1\n",
    "            metrics_per_fold[fold+1][threshold]['accuracy'] = accuracy\n",
    "            metrics_per_fold[fold+1][threshold]['precision'] = precision\n",
    "            metrics_per_fold[fold+1][threshold]['recall'] = recall\n",
    "            metrics_per_fold[fold+1][threshold]['mcc'] = mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Save the results for each threshold and fold\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold-allKfold_one_hyperparameter.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"fold,threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each fold and each threshold\n",
    "        for fold in range(1, successFold + 1):\n",
    "            for threshold in thresholds:\n",
    "                fo.write(f\"{fold},{threshold},{metrics_per_fold[fold][threshold]['accuracy']},{metrics_per_fold[fold][threshold]['precision']},\"\n",
    "                         f\"{metrics_per_fold[fold][threshold]['recall']},{metrics_per_fold[fold][threshold]['f1']},{metrics_per_fold[fold][threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_fold\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    params = {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"max_depth\": 300,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\" : 'log2'\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b5b1d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Decision Tree analysis with Grid Search completed. Results saved to: equal-params-dt-5-folds-Threshold-allKfold-Gridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "    fold  threshold  accuracy  precision    recall        f1       mcc  \\\n",
      "0      1        0.1  0.789474   0.714286  1.000000  0.833333  0.629941   \n",
      "1      1        0.2  0.789474   0.714286  1.000000  0.833333  0.629941   \n",
      "2      1        0.3  0.736842   0.692308  0.900000  0.782609  0.489345   \n",
      "3      1        0.4  0.736842   0.692308  0.900000  0.782609  0.489345   \n",
      "4      1        0.5  0.736842   0.692308  0.900000  0.782609  0.489345   \n",
      "5      1        0.6  0.736842   0.692308  0.900000  0.782609  0.489345   \n",
      "6      1        0.7  0.789474   0.800000  0.800000  0.800000  0.577778   \n",
      "7      1        0.8  0.789474   0.800000  0.800000  0.800000  0.577778   \n",
      "8      1        0.9  0.789474   0.800000  0.800000  0.800000  0.577778   \n",
      "9      2        0.1  0.789474   0.800000  0.800000  0.800000  0.577778   \n",
      "10     2        0.2  0.789474   0.800000  0.800000  0.800000  0.577778   \n",
      "11     2        0.3  0.789474   0.875000  0.700000  0.777778  0.595543   \n",
      "12     2        0.4  0.789474   0.875000  0.700000  0.777778  0.595543   \n",
      "13     2        0.5  0.736842   0.857143  0.600000  0.705882  0.506048   \n",
      "14     2        0.6  0.736842   0.857143  0.600000  0.705882  0.506048   \n",
      "15     2        0.7  0.736842   0.857143  0.600000  0.705882  0.506048   \n",
      "16     2        0.8  0.736842   0.857143  0.600000  0.705882  0.506048   \n",
      "17     2        0.9  0.631579   0.800000  0.400000  0.533333  0.327569   \n",
      "18     3        0.1  0.789474   0.692308  1.000000  0.818182  0.644503   \n",
      "19     3        0.2  0.789474   0.692308  1.000000  0.818182  0.644503   \n",
      "20     3        0.3  0.842105   0.750000  1.000000  0.857143  0.724569   \n",
      "21     3        0.4  0.842105   0.750000  1.000000  0.857143  0.724569   \n",
      "22     3        0.5  0.842105   0.750000  1.000000  0.857143  0.724569   \n",
      "23     3        0.6  0.842105   0.750000  1.000000  0.857143  0.724569   \n",
      "24     3        0.7  0.842105   0.875000  0.777778  0.823529  0.685437   \n",
      "25     3        0.8  0.842105   0.875000  0.777778  0.823529  0.685437   \n",
      "26     3        0.9  0.736842   0.833333  0.555556  0.666667  0.489345   \n",
      "27     4        0.1  0.736842   0.666667  0.888889  0.761905  0.506048   \n",
      "28     4        0.2  0.736842   0.666667  0.888889  0.761905  0.506048   \n",
      "29     4        0.3  0.842105   0.875000  0.777778  0.823529  0.685437   \n",
      "30     4        0.4  0.842105   0.875000  0.777778  0.823529  0.685437   \n",
      "31     4        0.5  0.842105   0.875000  0.777778  0.823529  0.685437   \n",
      "32     4        0.6  0.842105   0.875000  0.777778  0.823529  0.685437   \n",
      "33     4        0.7  0.842105   0.875000  0.777778  0.823529  0.685437   \n",
      "34     4        0.8  0.842105   0.875000  0.777778  0.823529  0.685437   \n",
      "35     4        0.9  0.842105   0.875000  0.777778  0.823529  0.685437   \n",
      "36     5        0.1  0.666667   0.615385  0.888889  0.727273  0.372104   \n",
      "37     5        0.2  0.666667   0.615385  0.888889  0.727273  0.372104   \n",
      "38     5        0.3  0.722222   0.666667  0.888889  0.761905  0.471405   \n",
      "39     5        0.4  0.722222   0.666667  0.888889  0.761905  0.471405   \n",
      "40     5        0.5  0.722222   0.666667  0.888889  0.761905  0.471405   \n",
      "41     5        0.6  0.722222   0.666667  0.888889  0.761905  0.471405   \n",
      "42     5        0.7  0.611111   0.625000  0.555556  0.588235  0.223607   \n",
      "43     5        0.8  0.611111   0.625000  0.555556  0.588235  0.223607   \n",
      "44     5        0.9  0.555556   0.571429  0.444444  0.500000  0.113961   \n",
      "\n",
      "   criterion max_depth max_features  min_samples_leaf  min_samples_split  \n",
      "0       gini      None         None                 5                  2  \n",
      "1       gini      None         None                 5                  2  \n",
      "2       gini      None         None                 5                  2  \n",
      "3       gini      None         None                 5                  2  \n",
      "4       gini      None         None                 5                  2  \n",
      "5       gini      None         None                 5                  2  \n",
      "6       gini      None         None                 5                  2  \n",
      "7       gini      None         None                 5                  2  \n",
      "8       gini      None         None                 5                  2  \n",
      "9       gini      None         None                 5                  2  \n",
      "10      gini      None         None                 5                  2  \n",
      "11      gini      None         None                 5                  2  \n",
      "12      gini      None         None                 5                  2  \n",
      "13      gini      None         None                 5                  2  \n",
      "14      gini      None         None                 5                  2  \n",
      "15      gini      None         None                 5                  2  \n",
      "16      gini      None         None                 5                  2  \n",
      "17      gini      None         None                 5                  2  \n",
      "18      gini      None         None                 5                  2  \n",
      "19      gini      None         None                 5                  2  \n",
      "20      gini      None         None                 5                  2  \n",
      "21      gini      None         None                 5                  2  \n",
      "22      gini      None         None                 5                  2  \n",
      "23      gini      None         None                 5                  2  \n",
      "24      gini      None         None                 5                  2  \n",
      "25      gini      None         None                 5                  2  \n",
      "26      gini      None         None                 5                  2  \n",
      "27      gini      None         None                 5                  2  \n",
      "28      gini      None         None                 5                  2  \n",
      "29      gini      None         None                 5                  2  \n",
      "30      gini      None         None                 5                  2  \n",
      "31      gini      None         None                 5                  2  \n",
      "32      gini      None         None                 5                  2  \n",
      "33      gini      None         None                 5                  2  \n",
      "34      gini      None         None                 5                  2  \n",
      "35      gini      None         None                 5                  2  \n",
      "36      gini      None         None                 5                  2  \n",
      "37      gini      None         None                 5                  2  \n",
      "38      gini      None         None                 5                  2  \n",
      "39      gini      None         None                 5                  2  \n",
      "40      gini      None         None                 5                  2  \n",
      "41      gini      None         None                 5                  2  \n",
      "42      gini      None         None                 5                  2  \n",
      "43      gini      None         None                 5                  2  \n",
      "44      gini      None         None                 5                  2  \n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Decision Tree analysis with Grid Search completed. Results saved to: larger-params-dt-5-folds-Threshold-allKfold-Gridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "    fold  threshold  accuracy  precision    recall        f1       mcc  \\\n",
      "0      1        0.1  0.737705   0.285714  0.400000  0.333333  0.179529   \n",
      "1      1        0.2  0.737705   0.285714  0.400000  0.333333  0.179529   \n",
      "2      1        0.3  0.819672   0.444444  0.400000  0.421053  0.315219   \n",
      "3      1        0.4  0.819672   0.444444  0.400000  0.421053  0.315219   \n",
      "4      1        0.5  0.819672   0.444444  0.400000  0.421053  0.315219   \n",
      "5      1        0.6  0.819672   0.428571  0.300000  0.352941  0.257364   \n",
      "6      1        0.7  0.836066   0.500000  0.200000  0.285714  0.240470   \n",
      "7      1        0.8  0.836066   0.500000  0.200000  0.285714  0.240470   \n",
      "8      1        0.9  0.819672   0.333333  0.100000  0.153846  0.104064   \n",
      "9      2        0.1  0.800000   0.444444  0.800000  0.571429  0.487950   \n",
      "10     2        0.2  0.800000   0.444444  0.800000  0.571429  0.487950   \n",
      "11     2        0.3  0.816667   0.470588  0.800000  0.592593  0.512765   \n",
      "12     2        0.4  0.816667   0.470588  0.800000  0.592593  0.512765   \n",
      "13     2        0.5  0.833333   0.500000  0.800000  0.615385  0.539360   \n",
      "14     2        0.6  0.850000   0.545455  0.600000  0.571429  0.481571   \n",
      "15     2        0.7  0.866667   0.625000  0.500000  0.555556  0.482382   \n",
      "16     2        0.8  0.866667   0.625000  0.500000  0.555556  0.482382   \n",
      "17     2        0.9  0.866667   0.666667  0.400000  0.500000  0.447214   \n",
      "18     3        0.1  0.700000   0.285714  0.666667  0.400000  0.278900   \n",
      "19     3        0.2  0.700000   0.285714  0.666667  0.400000  0.278900   \n",
      "20     3        0.3  0.716667   0.300000  0.666667  0.413793  0.297044   \n",
      "21     3        0.4  0.716667   0.300000  0.666667  0.413793  0.297044   \n",
      "22     3        0.5  0.750000   0.312500  0.555556  0.400000  0.274430   \n",
      "23     3        0.6  0.750000   0.312500  0.555556  0.400000  0.274430   \n",
      "24     3        0.7  0.766667   0.333333  0.555556  0.416667  0.296432   \n",
      "25     3        0.8  0.766667   0.333333  0.555556  0.416667  0.296432   \n",
      "26     3        0.9  0.816667   0.400000  0.444444  0.421053  0.313112   \n",
      "27     4        0.1  0.833333   0.470588  0.888889  0.615385  0.564524   \n",
      "28     4        0.2  0.833333   0.470588  0.888889  0.615385  0.564524   \n",
      "29     4        0.3  0.833333   0.470588  0.888889  0.615385  0.564524   \n",
      "30     4        0.4  0.850000   0.500000  0.888889  0.640000  0.591080   \n",
      "31     4        0.5  0.900000   0.615385  0.888889  0.727273  0.685456   \n",
      "32     4        0.6  0.883333   0.750000  0.333333  0.461538  0.449089   \n",
      "33     4        0.7  0.883333   0.750000  0.333333  0.461538  0.449089   \n",
      "34     4        0.8  0.883333   0.750000  0.333333  0.461538  0.449089   \n",
      "35     4        0.9  0.900000   1.000000  0.333333  0.500000  0.546119   \n",
      "36     5        0.1  0.800000   0.384615  0.555556  0.454545  0.345561   \n",
      "37     5        0.2  0.800000   0.384615  0.555556  0.454545  0.345561   \n",
      "38     5        0.3  0.816667   0.400000  0.444444  0.421053  0.313112   \n",
      "39     5        0.4  0.816667   0.400000  0.444444  0.421053  0.313112   \n",
      "40     5        0.5  0.833333   0.444444  0.444444  0.444444  0.346405   \n",
      "41     5        0.6  0.850000   0.500000  0.444444  0.470588  0.384465   \n",
      "42     5        0.7  0.850000   0.500000  0.444444  0.470588  0.384465   \n",
      "43     5        0.8  0.850000   0.500000  0.444444  0.470588  0.384465   \n",
      "44     5        0.9  0.850000   0.500000  0.333333  0.400000  0.326732   \n",
      "\n",
      "   criterion max_depth max_features  min_samples_leaf  min_samples_split  \n",
      "0       gini      None         None                 5                  2  \n",
      "1       gini      None         None                 5                  2  \n",
      "2       gini      None         None                 5                  2  \n",
      "3       gini      None         None                 5                  2  \n",
      "4       gini      None         None                 5                  2  \n",
      "5       gini      None         None                 5                  2  \n",
      "6       gini      None         None                 5                  2  \n",
      "7       gini      None         None                 5                  2  \n",
      "8       gini      None         None                 5                  2  \n",
      "9       gini      None         None                 5                  2  \n",
      "10      gini      None         None                 5                  2  \n",
      "11      gini      None         None                 5                  2  \n",
      "12      gini      None         None                 5                  2  \n",
      "13      gini      None         None                 5                  2  \n",
      "14      gini      None         None                 5                  2  \n",
      "15      gini      None         None                 5                  2  \n",
      "16      gini      None         None                 5                  2  \n",
      "17      gini      None         None                 5                  2  \n",
      "18      gini      None         None                 5                  2  \n",
      "19      gini      None         None                 5                  2  \n",
      "20      gini      None         None                 5                  2  \n",
      "21      gini      None         None                 5                  2  \n",
      "22      gini      None         None                 5                  2  \n",
      "23      gini      None         None                 5                  2  \n",
      "24      gini      None         None                 5                  2  \n",
      "25      gini      None         None                 5                  2  \n",
      "26      gini      None         None                 5                  2  \n",
      "27      gini      None         None                 5                  2  \n",
      "28      gini      None         None                 5                  2  \n",
      "29      gini      None         None                 5                  2  \n",
      "30      gini      None         None                 5                  2  \n",
      "31      gini      None         None                 5                  2  \n",
      "32      gini      None         None                 5                  2  \n",
      "33      gini      None         None                 5                  2  \n",
      "34      gini      None         None                 5                  2  \n",
      "35      gini      None         None                 5                  2  \n",
      "36      gini      None         None                 5                  2  \n",
      "37      gini      None         None                 5                  2  \n",
      "38      gini      None         None                 5                  2  \n",
      "39      gini      None         None                 5                  2  \n",
      "40      gini      None         None                 5                  2  \n",
      "41      gini      None         None                 5                  2  \n",
      "42      gini      None         None                 5                  2  \n",
      "43      gini      None         None                 5                  2  \n",
      "44      gini      None         None                 5                  2  \n"
     ]
    }
   ],
   "source": [
    "#DT with hyperparameter tune\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef, make_scorer\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Grid Search Decision Tree with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define the Decision Tree model and GridSearchCV\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(dt_model, param_grid, scoring='f1', cv=skf, n_jobs=-1)\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best model after grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "    # Now perform cross-validation with the best model across thresholds\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_fold = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the best model on this fold\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            metrics_per_fold.append({\n",
    "                'fold': fold + 1,\n",
    "                'threshold': threshold,\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'mcc': mcc,\n",
    "                **best_params\n",
    "            })\n",
    "\n",
    "    if len(metrics_per_fold) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return best_params, None\n",
    "\n",
    "    # Save the results for each threshold and fold\n",
    "    df_results = pd.DataFrame(metrics_per_fold)\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold-allKfold-Gridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"Decision Tree analysis with Grid Search completed. Results saved to: {outFile}\")\n",
    "    return best_params, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "        'max_depth': [None, 10, 30, 50, 100, 300, 500],  # Maximum depth of each tree\n",
    "        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 5, 10],  # Minimum number of samples required to be at a leaf node\n",
    "        'max_features': [None, 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd9877",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e124ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Random Forest analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Random Forest analysis completed for 5 folds. Results saved to: equal-params-rf-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Random Forest analysis completed for 3 folds. Results saved to: equal-params-rf-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.7142857142857143, 'accuracy': 0.5789473684210527, 'precision': 0.5555555555555556, 'recall': 1.0, 'mcc': 0.24845199749997662}, 0.2: {'f1': 0.7407407407407407, 'accuracy': 0.631578947368421, 'precision': 0.5882352941176471, 'recall': 1.0, 'mcc': 0.3615507630310936}, 0.30000000000000004: {'f1': 0.75, 'accuracy': 0.6842105263157895, 'precision': 0.6428571428571429, 'recall': 0.9, 'mcc': 0.3905632887762015}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.631578947368421, 'precision': 0.6363636363636364, 'recall': 0.7, 'mcc': 0.2584432806109095}, 0.5: {'f1': 0.5333333333333333, 'accuracy': 0.631578947368421, 'precision': 0.8, 'recall': 0.4, 'mcc': 0.32756920994133026}, 0.6: {'f1': 0.3333333333333333, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.32539568672798425}, 0.7000000000000001: {'f1': 0.18181818181818182, 'accuracy': 0.5263157894736842, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.22360679774997896}, 0.8: {'f1': 0.18181818181818182, 'accuracy': 0.5263157894736842, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.22360679774997896}, 0.9: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 2: {0.1: {'f1': 0.7142857142857143, 'accuracy': 0.5789473684210527, 'precision': 0.5555555555555556, 'recall': 1.0, 'mcc': 0.24845199749997662}, 0.2: {'f1': 0.7692307692307693, 'accuracy': 0.6842105263157895, 'precision': 0.625, 'recall': 1.0, 'mcc': 0.45643546458763845}, 0.30000000000000004: {'f1': 0.782608695652174, 'accuracy': 0.7368421052631579, 'precision': 0.6923076923076923, 'recall': 0.9, 'mcc': 0.4893451639269458}, 0.4: {'f1': 0.7619047619047619, 'accuracy': 0.7368421052631579, 'precision': 0.7272727272727273, 'recall': 0.8, 'mcc': 0.47193990372426947}, 0.5: {'f1': 0.7, 'accuracy': 0.6842105263157895, 'precision': 0.7, 'recall': 0.7, 'mcc': 0.36666666666666664}, 0.6: {'f1': 0.4, 'accuracy': 0.5263157894736842, 'precision': 0.6, 'recall': 0.3, 'mcc': 0.08819171036881969}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 3: {0.1: {'f1': 0.6428571428571429, 'accuracy': 0.47368421052631576, 'precision': 0.47368421052631576, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.5925925925925926, 'accuracy': 0.42105263157894735, 'precision': 0.4444444444444444, 'recall': 0.8888888888888888, 'mcc': -0.24845199749997662}, 0.30000000000000004: {'f1': 0.64, 'accuracy': 0.5263157894736842, 'precision': 0.5, 'recall': 0.8888888888888888, 'mcc': 0.12171612389003691}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.5789473684210527, 'precision': 0.5333333333333333, 'recall': 0.8888888888888888, 'mcc': 0.23134069792952236}, 0.5: {'f1': 0.7, 'accuracy': 0.6842105263157895, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'mcc': 0.3820465887291705}, 0.6: {'f1': 0.42857142857142855, 'accuracy': 0.5789473684210527, 'precision': 0.6, 'recall': 0.3333333333333333, 'mcc': 0.15118578920369088}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24845199749997662}, 0.8: {'f1': 0.0, 'accuracy': 0.5263157894736842, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.5263157894736842, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 4: {0.1: {'f1': 0.6428571428571429, 'accuracy': 0.47368421052631576, 'precision': 0.47368421052631576, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.5263157894736842, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.22360679774997896}, 0.30000000000000004: {'f1': 0.75, 'accuracy': 0.6842105263157895, 'precision': 0.6, 'recall': 1.0, 'mcc': 0.4898979485566356}, 0.4: {'f1': 0.782608695652174, 'accuracy': 0.7368421052631579, 'precision': 0.6428571428571429, 'recall': 1.0, 'mcc': 0.5669467095138409}, 0.5: {'f1': 0.6666666666666666, 'accuracy': 0.631578947368421, 'precision': 0.5833333333333334, 'recall': 0.7777777777777778, 'mcc': 0.2875273163926476}, 0.6: {'f1': 0.5333333333333333, 'accuracy': 0.631578947368421, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.26257545381445874}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24845199749997662}, 0.8: {'f1': 0.2, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24845199749997662}, 0.9: {'f1': 0.0, 'accuracy': 0.5263157894736842, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 5: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.782608695652174, 'accuracy': 0.7222222222222222, 'precision': 0.6428571428571429, 'recall': 1.0, 'mcc': 0.5345224838248488}, 0.30000000000000004: {'f1': 0.8, 'accuracy': 0.7777777777777778, 'precision': 0.7272727272727273, 'recall': 0.8888888888888888, 'mcc': 0.5698028822981898}, 0.4: {'f1': 0.8888888888888888, 'accuracy': 0.8888888888888888, 'precision': 0.8888888888888888, 'recall': 0.8888888888888888, 'mcc': 0.7777777777777778}, 0.5: {'f1': 0.9411764705882353, 'accuracy': 0.9444444444444444, 'precision': 1.0, 'recall': 0.8888888888888888, 'mcc': 0.8944271909999159}, 0.6: {'f1': 0.7142857142857143, 'accuracy': 0.7777777777777778, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.6201736729460423}, 0.7000000000000001: {'f1': 0.36363636363636365, 'accuracy': 0.6111111111111112, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.3535533905932738}, 0.8: {'f1': 0.2, 'accuracy': 0.5555555555555556, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24253562503633297}, 0.9: {'f1': 0.0, 'accuracy': 0.5, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.6956521739130435, 'accuracy': 0.5625, 'precision': 0.5333333333333333, 'recall': 1.0, 'mcc': 0.2581988897471611}, 0.30000000000000004: {'f1': 0.7317073170731707, 'accuracy': 0.65625, 'precision': 0.6, 'recall': 0.9375, 'mcc': 0.37796447300922725}, 0.4: {'f1': 0.6470588235294118, 'accuracy': 0.625, 'precision': 0.6111111111111112, 'recall': 0.6875, 'mcc': 0.2519763153394848}, 0.5: {'f1': 0.6428571428571429, 'accuracy': 0.6875, 'precision': 0.75, 'recall': 0.5625, 'mcc': 0.3872983346207417}, 0.6: {'f1': 0.64, 'accuracy': 0.71875, 'precision': 0.8888888888888888, 'recall': 0.5, 'mcc': 0.4865336327998411}, 0.7000000000000001: {'f1': 0.3, 'accuracy': 0.5625, 'precision': 0.75, 'recall': 0.1875, 'mcc': 0.1889822365046136}, 0.8: {'f1': 0.21052631578947367, 'accuracy': 0.53125, 'precision': 0.6666666666666666, 'recall': 0.125, 'mcc': 0.10721125348377948}, 0.9: {'f1': 0.0, 'accuracy': 0.5, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 2: {0.1: {'f1': 0.6818181818181818, 'accuracy': 0.5483870967741935, 'precision': 0.5357142857142857, 'recall': 0.9375, 'mcc': 0.11973018608653985}, 0.2: {'f1': 0.7142857142857143, 'accuracy': 0.6129032258064516, 'precision': 0.5769230769230769, 'recall': 0.9375, 'mcc': 0.277407873365426}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.6129032258064516, 'precision': 0.6, 'recall': 0.75, 'mcc': 0.2263009527424072}, 0.4: {'f1': 0.625, 'accuracy': 0.6129032258064516, 'precision': 0.625, 'recall': 0.625, 'mcc': 0.225}, 0.5: {'f1': 0.5925925925925926, 'accuracy': 0.6451612903225806, 'precision': 0.7272727272727273, 'recall': 0.5, 'mcc': 0.3133397807202561}, 0.6: {'f1': 0.5, 'accuracy': 0.6129032258064516, 'precision': 0.75, 'recall': 0.375, 'mcc': 0.27600278301474435}, 0.7000000000000001: {'f1': 0.21052631578947367, 'accuracy': 0.5161290322580645, 'precision': 0.6666666666666666, 'recall': 0.125, 'mcc': 0.09860132971832693}, 0.8: {'f1': 0.21052631578947367, 'accuracy': 0.5161290322580645, 'precision': 0.6666666666666666, 'recall': 0.125, 'mcc': 0.09860132971832693}, 0.9: {'f1': 0.1111111111111111, 'accuracy': 0.4838709677419355, 'precision': 0.5, 'recall': 0.0625, 'mcc': -0.008475793795260131}}, 3: {0.1: {'f1': 0.6521739130434783, 'accuracy': 0.4838709677419355, 'precision': 0.4838709677419355, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.6976744186046512, 'accuracy': 0.5806451612903226, 'precision': 0.5357142857142857, 'recall': 1.0, 'mcc': 0.3169328455231937}, 0.30000000000000004: {'f1': 0.7222222222222222, 'accuracy': 0.6774193548387096, 'precision': 0.6190476190476191, 'recall': 0.8666666666666667, 'mcc': 0.3919831548048891}, 0.4: {'f1': 0.7272727272727273, 'accuracy': 0.7096774193548387, 'precision': 0.6666666666666666, 'recall': 0.8, 'mcc': 0.4304142310105583}, 0.5: {'f1': 0.8, 'accuracy': 0.8064516129032258, 'precision': 0.8, 'recall': 0.8, 'mcc': 0.6125}, 0.6: {'f1': 0.6153846153846154, 'accuracy': 0.6774193548387096, 'precision': 0.7272727272727273, 'recall': 0.5333333333333333, 'mcc': 0.36121113610807304}, 0.7000000000000001: {'f1': 0.47619047619047616, 'accuracy': 0.6451612903225806, 'precision': 0.8333333333333334, 'recall': 0.3333333333333333, 'mcc': 0.34258007985157446}, 0.8: {'f1': 0.3333333333333333, 'accuracy': 0.6129032258064516, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.3380617018914066}, 0.9: {'f1': 0.23529411764705882, 'accuracy': 0.5806451612903226, 'precision': 1.0, 'recall': 0.13333333333333333, 'mcc': 0.2712254014483242}}}\n",
      "Starting Random Forest analysis for flaky vs larger non-flaky files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Random Forest analysis completed for 5 folds. Results saved to: larger-params-rf-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Random Forest analysis completed for 3 folds. Results saved to: larger-params-rf-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.391304347826087, 'accuracy': 0.5409836065573771, 'precision': 0.25, 'recall': 0.9, 'mcc': 0.27896868894513}, 0.2: {'f1': 0.4827586206896552, 'accuracy': 0.7540983606557377, 'precision': 0.3684210526315789, 'recall': 0.7, 'mcc': 0.371502561269277}, 0.30000000000000004: {'f1': 0.5217391304347826, 'accuracy': 0.819672131147541, 'precision': 0.46153846153846156, 'recall': 0.6, 'mcc': 0.41834503598132505}, 0.4: {'f1': 0.5333333333333333, 'accuracy': 0.8852459016393442, 'precision': 0.8, 'recall': 0.4, 'mcc': 0.5133784403042143}, 0.5: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}, 0.6: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}, 0.7000000000000001: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}, 0.8: {'f1': 0.0, 'accuracy': 0.8360655737704918, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.8360655737704918, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 2: {0.1: {'f1': 0.3111111111111111, 'accuracy': 0.48333333333333334, 'precision': 0.2, 'recall': 0.7, 'mcc': 0.10583005244258363}, 0.2: {'f1': 0.3125, 'accuracy': 0.6333333333333333, 'precision': 0.22727272727272727, 'recall': 0.5, 'mcc': 0.12373764497794919}, 0.30000000000000004: {'f1': 0.2608695652173913, 'accuracy': 0.7166666666666667, 'precision': 0.23076923076923078, 'recall': 0.3, 'mcc': 0.09046162753149249}, 0.4: {'f1': 0.3157894736842105, 'accuracy': 0.7833333333333333, 'precision': 0.3333333333333333, 'recall': 0.3, 'mcc': 0.18786728732554486}, 0.5: {'f1': 0.46153846153846156, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.3, 'mcc': 0.5129891760425771}, 0.6: {'f1': 0.18181818181818182, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291111254869791}, 0.7000000000000001: {'f1': 0.18181818181818182, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291111254869791}, 0.8: {'f1': 0.0, 'accuracy': 0.8333333333333334, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.8333333333333334, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 3: {0.1: {'f1': 0.36, 'accuracy': 0.4666666666666667, 'precision': 0.21951219512195122, 'recall': 1.0, 'mcc': 0.2859703709908572}, 0.2: {'f1': 0.4666666666666667, 'accuracy': 0.7333333333333333, 'precision': 0.3333333333333333, 'recall': 0.7777777777777778, 'mcc': 0.37675904400756577}, 0.30000000000000004: {'f1': 0.6363636363636364, 'accuracy': 0.8666666666666667, 'precision': 0.5384615384615384, 'recall': 0.7777777777777778, 'mcc': 0.5721576125703091}, 0.4: {'f1': 0.4, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.3333333333333333, 'mcc': 0.32673201960653564}, 0.5: {'f1': 0.18181818181818182, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.1111111111111111, 'mcc': 0.18201783862232032}, 0.6: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 4: {0.1: {'f1': 0.34782608695652173, 'accuracy': 0.5, 'precision': 0.21621621621621623, 'recall': 0.8888888888888888, 'mcc': 0.23520481704398008}, 0.2: {'f1': 0.45161290322580644, 'accuracy': 0.7166666666666667, 'precision': 0.3181818181818182, 'recall': 0.7777777777777778, 'mcc': 0.35837977540673743}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.8833333333333333, 'precision': 0.5833333333333334, 'recall': 0.7777777777777778, 'mcc': 0.6067880364121375}, 0.4: {'f1': 0.5333333333333333, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.48231869560964785}, 0.5: {'f1': 0.46153846153846156, 'accuracy': 0.8833333333333333, 'precision': 0.75, 'recall': 0.3333333333333333, 'mcc': 0.44908871313907184}, 0.6: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.8: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 5: {0.1: {'f1': 0.43243243243243246, 'accuracy': 0.65, 'precision': 0.2857142857142857, 'recall': 0.8888888888888888, 'mcc': 0.35552856456843185}, 0.2: {'f1': 0.56, 'accuracy': 0.8166666666666667, 'precision': 0.4375, 'recall': 0.7777777777777778, 'mcc': 0.48553038055886144}, 0.30000000000000004: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.4: {'f1': 0.3076923076923077, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.2222222222222222, 'mcc': 0.2619684159977919}, 0.5: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.6: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.8: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.3855421686746988, 'accuracy': 0.49504950495049505, 'precision': 0.23880597014925373, 'recall': 1.0, 'mcc': 0.3090669637145023}, 0.2: {'f1': 0.5217391304347826, 'accuracy': 0.7821782178217822, 'precision': 0.4, 'recall': 0.75, 'mcc': 0.43008255310521637}, 0.30000000000000004: {'f1': 0.45161290322580644, 'accuracy': 0.8316831683168316, 'precision': 0.4666666666666667, 'recall': 0.4375, 'mcc': 0.35257585782653333}, 0.4: {'f1': 0.48, 'accuracy': 0.8712871287128713, 'precision': 0.6666666666666666, 'recall': 0.375, 'mcc': 0.4353688502932043}, 0.5: {'f1': 0.43478260869565216, 'accuracy': 0.8712871287128713, 'precision': 0.7142857142857143, 'recall': 0.3125, 'mcc': 0.4154417599270597}, 0.6: {'f1': 0.3157894736842105, 'accuracy': 0.8712871287128713, 'precision': 1.0, 'recall': 0.1875, 'mcc': 0.40327106395129336}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 2: {0.1: {'f1': 0.4117647058823529, 'accuracy': 0.6, 'precision': 0.2692307692307692, 'recall': 0.875, 'mcc': 0.31011759753023416}, 0.2: {'f1': 0.5853658536585366, 'accuracy': 0.83, 'precision': 0.48, 'recall': 0.75, 'mcc': 0.5039526306789697}, 0.30000000000000004: {'f1': 0.5384615384615384, 'accuracy': 0.88, 'precision': 0.7, 'recall': 0.4375, 'mcc': 0.49099025303098287}, 0.4: {'f1': 0.3, 'accuracy': 0.86, 'precision': 0.75, 'recall': 0.1875, 'mcc': 0.3285086098506883}, 0.5: {'f1': 0.11764705882352941, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23028309323591917}, 0.6: {'f1': 0.11764705882352941, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23028309323591917}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.84, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.84, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.84, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 3: {0.1: {'f1': 0.35294117647058826, 'accuracy': 0.56, 'precision': 0.22641509433962265, 'recall': 0.8, 'mcc': 0.22725480107141366}, 0.2: {'f1': 0.391304347826087, 'accuracy': 0.72, 'precision': 0.2903225806451613, 'recall': 0.6, 'mcc': 0.2634078856355648}, 0.30000000000000004: {'f1': 0.35294117647058826, 'accuracy': 0.78, 'precision': 0.3157894736842105, 'recall': 0.4, 'mcc': 0.22487239817113244}, 0.4: {'f1': 0.34782608695652173, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.26666666666666666, 'mcc': 0.28904404865536687}, 0.5: {'f1': 0.4, 'accuracy': 0.88, 'precision': 0.8, 'recall': 0.26666666666666666, 'mcc': 0.41762016803210306}, 0.6: {'f1': 0.3333333333333333, 'accuracy': 0.88, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4186379485411743}, 0.7000000000000001: {'f1': 0.125, 'accuracy': 0.86, 'precision': 1.0, 'recall': 0.06666666666666667, 'mcc': 0.23924685418842448}, 0.8: {'f1': 0.125, 'accuracy': 0.86, 'precision': 1.0, 'recall': 0.06666666666666667, 'mcc': 0.23924685418842448}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Random forest with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define Random Forest model with given parameters\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=params.get('n_estimators', 100),\n",
    "        criterion=params.get('criterion', 'entropy'),\n",
    "        max_depth=params.get('max_depth', None),\n",
    "        min_samples_split=params.get('min_samples_split', 2),\n",
    "        min_samples_leaf=params.get('min_samples_leaf', 1),\n",
    "        max_features=params.get('max_features', 'auto'),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_fold = {fold+1: {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                                 for threshold in thresholds}\n",
    "                        for fold in range(n_splits)}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = rf_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold for this fold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Store metrics for the current threshold for this fold\n",
    "            metrics_per_fold[fold+1][threshold]['f1'] = f1\n",
    "            metrics_per_fold[fold+1][threshold]['accuracy'] = accuracy\n",
    "            metrics_per_fold[fold+1][threshold]['precision'] = precision\n",
    "            metrics_per_fold[fold+1][threshold]['recall'] = recall\n",
    "            metrics_per_fold[fold+1][threshold]['mcc'] = mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Save the results for each threshold and fold\n",
    "    outFile = f\"{combination_label}-params-rf-{n_splits}-folds-Threshold-allKfold_one_hyperparameter.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"fold,threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each fold and each threshold\n",
    "        for fold in range(1, successFold + 1):\n",
    "            for threshold in thresholds:\n",
    "                fo.write(f\"{fold},{threshold},{metrics_per_fold[fold][threshold]['accuracy']},{metrics_per_fold[fold][threshold]['precision']},\" \n",
    "                         f\"{metrics_per_fold[fold][threshold]['recall']},{metrics_per_fold[fold][threshold]['f1']},{metrics_per_fold[fold][threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"Random Forest analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_fold\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 10,\n",
    "        \"criterion\": \"gini\",\n",
    "        \"max_depth\": 30,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 2,\n",
    "        \"max_features\" : 'log2'\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Random Forest analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Random Forest analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform Random Forest analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Random Forest analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3361522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting XGBoost analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost analysis completed for 5 folds. Results saved to: equal-params-xgb-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost analysis completed for 3 folds. Results saved to: equal-params-xgb-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Results for 5-fold on equal combination:\n",
      "Parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Metrics per fold and threshold: {1: {0.1: {'f1': 0.5454545454545454, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.6, 'mcc': -0.06900655593423542}, 0.2: {'f1': 0.42105263157894735, 'accuracy': 0.42105263157894735, 'precision': 0.4444444444444444, 'recall': 0.4, 'mcc': -0.15555555555555556}, 0.30000000000000004: {'f1': 0.4444444444444444, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.4, 'mcc': -0.044946657497549475}, 0.4: {'f1': 0.5, 'accuracy': 0.5789473684210527, 'precision': 0.6666666666666666, 'recall': 0.4, 'mcc': 0.19096396641051544}, 0.5: {'f1': 0.5, 'accuracy': 0.5789473684210527, 'precision': 0.6666666666666666, 'recall': 0.4, 'mcc': 0.19096396641051544}, 0.6: {'f1': 0.5, 'accuracy': 0.5789473684210527, 'precision': 0.6666666666666666, 'recall': 0.4, 'mcc': 0.19096396641051544}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.5789473684210527, 'precision': 0.6666666666666666, 'recall': 0.4, 'mcc': 0.19096396641051544}, 0.8: {'f1': 0.5333333333333333, 'accuracy': 0.631578947368421, 'precision': 0.8, 'recall': 0.4, 'mcc': 0.32756920994133026}, 0.9: {'f1': 0.5333333333333333, 'accuracy': 0.631578947368421, 'precision': 0.8, 'recall': 0.4, 'mcc': 0.32756920994133026}}, 2: {0.1: {'f1': 0.72, 'accuracy': 0.631578947368421, 'precision': 0.6, 'recall': 0.9, 'mcc': 0.2857738033247041}, 0.2: {'f1': 0.75, 'accuracy': 0.6842105263157895, 'precision': 0.6428571428571429, 'recall': 0.9, 'mcc': 0.3905632887762015}, 0.30000000000000004: {'f1': 0.75, 'accuracy': 0.6842105263157895, 'precision': 0.6428571428571429, 'recall': 0.9, 'mcc': 0.3905632887762015}, 0.4: {'f1': 0.8181818181818182, 'accuracy': 0.7894736842105263, 'precision': 0.75, 'recall': 0.9, 'mcc': 0.5865557254410011}, 0.5: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.9, 'recall': 0.9, 'mcc': 0.7888888888888889}, 0.6: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8888888888888888, 'recall': 0.8, 'mcc': 0.6888888888888889}, 0.7000000000000001: {'f1': 0.7777777777777778, 'accuracy': 0.7894736842105263, 'precision': 0.875, 'recall': 0.7, 'mcc': 0.5955432118425306}, 0.8: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.9: {'f1': 0.42857142857142855, 'accuracy': 0.5789473684210527, 'precision': 0.75, 'recall': 0.3, 'mcc': 0.23134069792952236}}, 3: {0.1: {'f1': 0.64, 'accuracy': 0.5263157894736842, 'precision': 0.5, 'recall': 0.8888888888888888, 'mcc': 0.12171612389003691}, 0.2: {'f1': 0.6956521739130435, 'accuracy': 0.631578947368421, 'precision': 0.5714285714285714, 'recall': 0.8888888888888888, 'mcc': 0.32756920994133026}, 0.30000000000000004: {'f1': 0.7272727272727273, 'accuracy': 0.6842105263157895, 'precision': 0.6153846153846154, 'recall': 0.8888888888888888, 'mcc': 0.41773367652300253}, 0.4: {'f1': 0.7, 'accuracy': 0.6842105263157895, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'mcc': 0.3820465887291705}, 0.5: {'f1': 0.7, 'accuracy': 0.6842105263157895, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'mcc': 0.3820465887291705}, 0.6: {'f1': 0.7368421052631579, 'accuracy': 0.7368421052631579, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.4777777777777778}, 0.7000000000000001: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.75, 'recall': 0.6666666666666666, 'mcc': 0.47193990372426947}, 0.8: {'f1': 0.5333333333333333, 'accuracy': 0.631578947368421, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.26257545381445874}, 0.9: {'f1': 0.6153846153846154, 'accuracy': 0.7368421052631579, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.5443310539518174}}, 4: {0.1: {'f1': 0.72, 'accuracy': 0.631578947368421, 'precision': 0.5625, 'recall': 1.0, 'mcc': 0.4107919181288746}, 0.2: {'f1': 0.72, 'accuracy': 0.631578947368421, 'precision': 0.5625, 'recall': 1.0, 'mcc': 0.4107919181288746}, 0.30000000000000004: {'f1': 0.72, 'accuracy': 0.631578947368421, 'precision': 0.5625, 'recall': 1.0, 'mcc': 0.4107919181288746}, 0.4: {'f1': 0.75, 'accuracy': 0.6842105263157895, 'precision': 0.6, 'recall': 1.0, 'mcc': 0.4898979485566356}, 0.5: {'f1': 0.8181818181818182, 'accuracy': 0.7894736842105263, 'precision': 0.6923076923076923, 'recall': 1.0, 'mcc': 0.6445033866354896}, 0.6: {'f1': 0.8571428571428571, 'accuracy': 0.8421052631578947, 'precision': 0.75, 'recall': 1.0, 'mcc': 0.724568837309472}, 0.7000000000000001: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}, 0.8: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8, 'recall': 0.8888888888888888, 'mcc': 0.6888888888888889}, 0.9: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.75, 'recall': 0.6666666666666666, 'mcc': 0.47193990372426947}}, 5: {0.1: {'f1': 0.75, 'accuracy': 0.6666666666666666, 'precision': 0.6, 'recall': 1.0, 'mcc': 0.4472135954999579}, 0.2: {'f1': 0.7619047619047619, 'accuracy': 0.7222222222222222, 'precision': 0.6666666666666666, 'recall': 0.8888888888888888, 'mcc': 0.4714045207910316}, 0.30000000000000004: {'f1': 0.7368421052631579, 'accuracy': 0.7222222222222222, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.4472135954999579}, 0.4: {'f1': 0.7368421052631579, 'accuracy': 0.7222222222222222, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.4472135954999579}, 0.5: {'f1': 0.7368421052631579, 'accuracy': 0.7222222222222222, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.4472135954999579}, 0.6: {'f1': 0.8, 'accuracy': 0.8333333333333334, 'precision': 1.0, 'recall': 0.6666666666666666, 'mcc': 0.7071067811865475}, 0.7000000000000001: {'f1': 0.6153846153846154, 'accuracy': 0.7222222222222222, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.5345224838248488}, 0.8: {'f1': 0.5, 'accuracy': 0.6666666666666666, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.4472135954999579}, 0.9: {'f1': 0.2, 'accuracy': 0.5555555555555556, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24253562503633297}}}\n",
      "Results for 3-fold on equal combination:\n",
      "Parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Metrics per fold and threshold: {1: {0.1: {'f1': 0.7567567567567568, 'accuracy': 0.71875, 'precision': 0.6666666666666666, 'recall': 0.875, 'mcc': 0.4605661864718383}, 0.2: {'f1': 0.7567567567567568, 'accuracy': 0.71875, 'precision': 0.6666666666666666, 'recall': 0.875, 'mcc': 0.4605661864718383}, 0.30000000000000004: {'f1': 0.7777777777777778, 'accuracy': 0.75, 'precision': 0.7, 'recall': 0.875, 'mcc': 0.5163977794943222}, 0.4: {'f1': 0.7777777777777778, 'accuracy': 0.75, 'precision': 0.7, 'recall': 0.875, 'mcc': 0.5163977794943222}, 0.5: {'f1': 0.8235294117647058, 'accuracy': 0.8125, 'precision': 0.7777777777777778, 'recall': 0.875, 'mcc': 0.629940788348712}, 0.6: {'f1': 0.8387096774193549, 'accuracy': 0.84375, 'precision': 0.8666666666666667, 'recall': 0.8125, 'mcc': 0.6888467201936644}, 0.7000000000000001: {'f1': 0.8666666666666667, 'accuracy': 0.875, 'precision': 0.9285714285714286, 'recall': 0.8125, 'mcc': 0.7559289460184544}, 0.8: {'f1': 0.8275862068965517, 'accuracy': 0.84375, 'precision': 0.9230769230769231, 'recall': 0.75, 'mcc': 0.6999132392733555}, 0.9: {'f1': 0.64, 'accuracy': 0.71875, 'precision': 0.8888888888888888, 'recall': 0.5, 'mcc': 0.4865336327998411}}, 2: {0.1: {'f1': 0.717948717948718, 'accuracy': 0.6451612903225806, 'precision': 0.6086956521739131, 'recall': 0.875, 'mcc': 0.3140721323960884}, 0.2: {'f1': 0.8, 'accuracy': 0.7741935483870968, 'precision': 0.7368421052631579, 'recall': 0.875, 'mcc': 0.5557382740461252}, 0.30000000000000004: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}, 0.4: {'f1': 0.75, 'accuracy': 0.7419354838709677, 'precision': 0.75, 'recall': 0.75, 'mcc': 0.48333333333333334}, 0.5: {'f1': 0.8, 'accuracy': 0.8064516129032258, 'precision': 0.8571428571428571, 'recall': 0.75, 'mcc': 0.619252282479235}, 0.6: {'f1': 0.7586206896551724, 'accuracy': 0.7741935483870968, 'precision': 0.8461538461538461, 'recall': 0.6875, 'mcc': 0.5612263992588653}, 0.7000000000000001: {'f1': 0.7142857142857143, 'accuracy': 0.7419354838709677, 'precision': 0.8333333333333334, 'recall': 0.625, 'mcc': 0.5044393564418674}, 0.8: {'f1': 0.64, 'accuracy': 0.7096774193548387, 'precision': 0.8888888888888888, 'recall': 0.5, 'mcc': 0.4770842982214229}, 0.9: {'f1': 0.5454545454545454, 'accuracy': 0.6774193548387096, 'precision': 1.0, 'recall': 0.375, 'mcc': 0.47434164902525694}}, 3: {0.1: {'f1': 0.7142857142857143, 'accuracy': 0.6129032258064516, 'precision': 0.5555555555555556, 'recall': 1.0, 'mcc': 0.37267799624996495}, 0.2: {'f1': 0.75, 'accuracy': 0.6774193548387096, 'precision': 0.6, 'recall': 1.0, 'mcc': 0.47434164902525694}, 0.30000000000000004: {'f1': 0.8108108108108109, 'accuracy': 0.7741935483870968, 'precision': 0.6818181818181818, 'recall': 1.0, 'mcc': 0.6192921178835779}, 0.4: {'f1': 0.7647058823529411, 'accuracy': 0.7419354838709677, 'precision': 0.6842105263157895, 'recall': 0.8666666666666667, 'mcc': 0.5044393564418674}, 0.5: {'f1': 0.7272727272727273, 'accuracy': 0.7096774193548387, 'precision': 0.6666666666666666, 'recall': 0.8, 'mcc': 0.4304142310105583}, 0.6: {'f1': 0.6875, 'accuracy': 0.6774193548387096, 'precision': 0.6470588235294118, 'recall': 0.7333333333333333, 'mcc': 0.3598357857649609}, 0.7000000000000001: {'f1': 0.6428571428571429, 'accuracy': 0.6774193548387096, 'precision': 0.6923076923076923, 'recall': 0.6, 'mcc': 0.3544587784792833}, 0.8: {'f1': 0.6666666666666666, 'accuracy': 0.7096774193548387, 'precision': 0.75, 'recall': 0.6, 'mcc': 0.4232160702351261}, 0.9: {'f1': 0.72, 'accuracy': 0.7741935483870968, 'precision': 0.9, 'recall': 0.6, 'mcc': 0.5746116701117124}}}\n",
      "Starting XGBoost analysis for flaky vs larger non-flaky files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost analysis completed for 5 folds. Results saved to: larger-params-xgb-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "XGBoost analysis completed for 3 folds. Results saved to: larger-params-xgb-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Results for 5-fold on larger non-flaky combination:\n",
      "Parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Metrics per fold and threshold: {1: {0.1: {'f1': 0.5555555555555556, 'accuracy': 0.8688524590163934, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.4838541850227607}, 0.2: {'f1': 0.5882352941176471, 'accuracy': 0.8852459016393442, 'precision': 0.7142857142857143, 'recall': 0.5, 'mcc': 0.5352255958259309}, 0.30000000000000004: {'f1': 0.5, 'accuracy': 0.8688524590163934, 'precision': 0.6666666666666666, 'recall': 0.4, 'mcc': 0.4485137534646401}, 0.4: {'f1': 0.42857142857142855, 'accuracy': 0.8688524590163934, 'precision': 0.75, 'recall': 0.3, 'mcc': 0.41935664191718136}, 0.5: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}, 0.6: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}, 0.7000000000000001: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}, 0.8: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}, 0.9: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}}, 2: {0.1: {'f1': 0.56, 'accuracy': 0.8166666666666667, 'precision': 0.4666666666666667, 'recall': 0.7, 'mcc': 0.46475800154489}, 0.2: {'f1': 0.6086956521739131, 'accuracy': 0.85, 'precision': 0.5384615384615384, 'recall': 0.7, 'mcc': 0.5246774396826565}, 0.30000000000000004: {'f1': 0.7, 'accuracy': 0.9, 'precision': 0.7, 'recall': 0.7, 'mcc': 0.64}, 0.4: {'f1': 0.7, 'accuracy': 0.9, 'precision': 0.7, 'recall': 0.7, 'mcc': 0.64}, 0.5: {'f1': 0.631578947368421, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.6, 'mcc': 0.5636018619766345}, 0.6: {'f1': 0.631578947368421, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.6, 'mcc': 0.5636018619766345}, 0.7000000000000001: {'f1': 0.5555555555555556, 'accuracy': 0.8666666666666667, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.4823819106188661}, 0.8: {'f1': 0.47058823529411764, 'accuracy': 0.85, 'precision': 0.5714285714285714, 'recall': 0.4, 'mcc': 0.3947089411806863}, 0.9: {'f1': 0.4, 'accuracy': 0.85, 'precision': 0.6, 'recall': 0.3, 'mcc': 0.3505839284808859}}, 3: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.8666666666666667, 'precision': 0.5333333333333333, 'recall': 0.8888888888888888, 'mcc': 0.6198132639817399}, 0.2: {'f1': 0.5882352941176471, 'accuracy': 0.8833333333333333, 'precision': 0.625, 'recall': 0.5555555555555556, 'mcc': 0.5217732845620352}, 0.30000000000000004: {'f1': 0.5333333333333333, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.48231869560964785}, 0.4: {'f1': 0.5333333333333333, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.48231869560964785}, 0.5: {'f1': 0.5333333333333333, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.48231869560964785}, 0.6: {'f1': 0.42857142857142855, 'accuracy': 0.8666666666666667, 'precision': 0.6, 'recall': 0.3333333333333333, 'mcc': 0.3799802978286742}, 0.7000000000000001: {'f1': 0.3076923076923077, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.2222222222222222, 'mcc': 0.2619684159977919}, 0.8: {'f1': 0.0, 'accuracy': 0.8333333333333334, 'precision': 0.0, 'recall': 0.0, 'mcc': -0.054690281762322934}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 4: {0.1: {'f1': 0.8, 'accuracy': 0.9333333333333333, 'precision': 0.7272727272727273, 'recall': 0.8888888888888888, 'mcc': 0.7659920289562161}, 0.2: {'f1': 0.7058823529411765, 'accuracy': 0.9166666666666666, 'precision': 0.75, 'recall': 0.6666666666666666, 'mcc': 0.6590820436573076}, 0.30000000000000004: {'f1': 0.7142857142857143, 'accuracy': 0.9333333333333333, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.7177405625652734}, 0.4: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.5: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.6: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.8: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.9: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}}, 5: {0.1: {'f1': 0.5714285714285714, 'accuracy': 0.9, 'precision': 0.8, 'recall': 0.4444444444444444, 'mcc': 0.5488604301969738}, 0.2: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.30000000000000004: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.4: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.5: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.6: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.8: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.9: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}}}\n",
      "Results for 3-fold on larger non-flaky combination:\n",
      "Parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Metrics per fold and threshold: {1: {0.1: {'f1': 0.631578947368421, 'accuracy': 0.8613861386138614, 'precision': 0.5454545454545454, 'recall': 0.75, 'mcc': 0.559376363155382}, 0.2: {'f1': 0.7586206896551724, 'accuracy': 0.9306930693069307, 'precision': 0.8461538461538461, 'recall': 0.6875, 'mcc': 0.7239445181531854}, 0.30000000000000004: {'f1': 0.64, 'accuracy': 0.9108910891089109, 'precision': 0.8888888888888888, 'recall': 0.5, 'mcc': 0.6257249276941292}, 0.4: {'f1': 0.64, 'accuracy': 0.9108910891089109, 'precision': 0.8888888888888888, 'recall': 0.5, 'mcc': 0.6257249276941292}, 0.5: {'f1': 0.5217391304347826, 'accuracy': 0.8910891089108911, 'precision': 0.8571428571428571, 'recall': 0.375, 'mcc': 0.5222092351245992}, 0.6: {'f1': 0.38095238095238093, 'accuracy': 0.8712871287128713, 'precision': 0.8, 'recall': 0.25, 'mcc': 0.4010097549055531}, 0.7000000000000001: {'f1': 0.38095238095238093, 'accuracy': 0.8712871287128713, 'precision': 0.8, 'recall': 0.25, 'mcc': 0.4010097549055531}, 0.8: {'f1': 0.38095238095238093, 'accuracy': 0.8712871287128713, 'precision': 0.8, 'recall': 0.25, 'mcc': 0.4010097549055531}, 0.9: {'f1': 0.2222222222222222, 'accuracy': 0.8613861386138614, 'precision': 1.0, 'recall': 0.125, 'mcc': 0.32760224712787356}}, 2: {0.1: {'f1': 0.5142857142857142, 'accuracy': 0.83, 'precision': 0.47368421052631576, 'recall': 0.5625, 'mcc': 0.41440722207745595}, 0.2: {'f1': 0.4827586206896552, 'accuracy': 0.85, 'precision': 0.5384615384615384, 'recall': 0.4375, 'mcc': 0.39905629488495203}, 0.30000000000000004: {'f1': 0.4166666666666667, 'accuracy': 0.86, 'precision': 0.625, 'recall': 0.3125, 'mcc': 0.37402824402602614}, 0.4: {'f1': 0.38095238095238093, 'accuracy': 0.87, 'precision': 0.8, 'recall': 0.25, 'mcc': 0.4005009394574071}, 0.5: {'f1': 0.38095238095238093, 'accuracy': 0.87, 'precision': 0.8, 'recall': 0.25, 'mcc': 0.4005009394574071}, 0.6: {'f1': 0.21052631578947367, 'accuracy': 0.85, 'precision': 0.6666666666666666, 'recall': 0.125, 'mcc': 0.24305102621022315}, 0.7000000000000001: {'f1': 0.2222222222222222, 'accuracy': 0.86, 'precision': 1.0, 'recall': 0.125, 'mcc': 0.32732683535398854}, 0.8: {'f1': 0.0, 'accuracy': 0.84, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.84, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 3: {0.1: {'f1': 0.7333333333333333, 'accuracy': 0.92, 'precision': 0.7333333333333333, 'recall': 0.7333333333333333, 'mcc': 0.6862745098039216}, 0.2: {'f1': 0.7407407407407407, 'accuracy': 0.93, 'precision': 0.8333333333333334, 'recall': 0.6666666666666666, 'mcc': 0.7066865096598595}, 0.30000000000000004: {'f1': 0.6923076923076923, 'accuracy': 0.92, 'precision': 0.8181818181818182, 'recall': 0.6, 'mcc': 0.6578712398995471}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.92, 'precision': 0.8888888888888888, 'recall': 0.5333333333333333, 'mcc': 0.6507656214676136}, 0.5: {'f1': 0.5714285714285714, 'accuracy': 0.91, 'precision': 1.0, 'recall': 0.4, 'mcc': 0.6014167670256413}, 0.6: {'f1': 0.42105263157894735, 'accuracy': 0.89, 'precision': 1.0, 'recall': 0.26666666666666666, 'mcc': 0.485912657903775}, 0.7000000000000001: {'f1': 0.42105263157894735, 'accuracy': 0.89, 'precision': 1.0, 'recall': 0.26666666666666666, 'mcc': 0.485912657903775}, 0.8: {'f1': 0.42105263157894735, 'accuracy': 0.89, 'precision': 1.0, 'recall': 0.26666666666666666, 'mcc': 0.485912657903775}, 0.9: {'f1': 0.23529411764705882, 'accuracy': 0.87, 'precision': 1.0, 'recall': 0.13333333333333333, 'mcc': 0.3400680204068024}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:15:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# XGBoost with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define XGBoost model with given parameters\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=int(params.get('n_estimators', 100.0)),\n",
    "        max_depth=int(params.get('max_depth', 5.0)),\n",
    "        learning_rate=params.get('eta', 0.1),\n",
    "        subsample=params.get('subsample', 1),\n",
    "        colsample_bytree=params.get('colsample_bytree', 1),\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_fold = {fold+1: {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                                 for threshold in thresholds}\n",
    "                        for fold in range(n_splits)}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = xgb_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold for this fold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Store metrics for the current threshold for this fold\n",
    "            metrics_per_fold[fold+1][threshold]['f1'] = f1\n",
    "            metrics_per_fold[fold+1][threshold]['accuracy'] = accuracy\n",
    "            metrics_per_fold[fold+1][threshold]['precision'] = precision\n",
    "            metrics_per_fold[fold+1][threshold]['recall'] = recall\n",
    "            metrics_per_fold[fold+1][threshold]['mcc'] = mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Save the results for each threshold and fold\n",
    "    outFile = f\"{combination_label}-params-xgb-{n_splits}-folds-Threshold-allKfold_one_hyperparameter.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"fold,threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each fold and each threshold\n",
    "        for fold in range(1, successFold + 1):\n",
    "            for threshold in thresholds:\n",
    "                fo.write(f\"{fold},{threshold},{metrics_per_fold[fold][threshold]['accuracy']},{metrics_per_fold[fold][threshold]['precision']},\" \n",
    "                         f\"{metrics_per_fold[fold][threshold]['recall']},{metrics_per_fold[fold][threshold]['f1']},{metrics_per_fold[fold][threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"XGBoost analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_fold\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Update the parameters as per your request\n",
    "    params = {\n",
    "        \"eta\": 0.1,  # This is the learning_rate\n",
    "        \"max_depth\": 5.0,\n",
    "        \"n_estimators\": 100.0\n",
    "    }\n",
    "\n",
    "    # Ensure max_depth and n_estimators are integers\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform XGBoost analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting XGBoost analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Results for 5-fold on equal combination:\")\n",
    "    print(f\"Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Metrics per fold and threshold: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Results for 3-fold on equal combination:\")\n",
    "    print(f\"Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Metrics per fold and threshold: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform XGBoost analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting XGBoost analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Metrics per fold and threshold: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Metrics per fold and threshold: {best_score_3folds_2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6430f9b",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f29170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KNN analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "KNN analysis completed for 5 folds. Results saved to: equal-params-knn-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "KNN analysis completed for 3 folds. Results saved to: equal-params-knn-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'n_neighbors': 5, 'metric': 'cosine', 'weights': 'distance'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.6428571428571429, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.9, 'mcc': -0.22360679774997896}, 0.2: {'f1': 0.6923076923076923, 'accuracy': 0.5789473684210527, 'precision': 0.5625, 'recall': 0.9, 'mcc': 0.16735967034880075}, 0.30000000000000004: {'f1': 0.6956521739130435, 'accuracy': 0.631578947368421, 'precision': 0.6153846153846154, 'recall': 0.8, 'mcc': 0.26257545381445874}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.631578947368421, 'precision': 0.6363636363636364, 'recall': 0.7, 'mcc': 0.2584432806109095}, 0.5: {'f1': 0.4444444444444444, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.4, 'mcc': -0.044946657497549475}, 0.6: {'f1': 0.47058823529411764, 'accuracy': 0.5263157894736842, 'precision': 0.5714285714285714, 'recall': 0.4, 'mcc': 0.06900655593423542}, 0.7000000000000001: {'f1': 0.4, 'accuracy': 0.5263157894736842, 'precision': 0.6, 'recall': 0.3, 'mcc': 0.08819171036881969}, 0.8: {'f1': 0.2857142857142857, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.2, 'mcc': -0.027216552697590865}, 0.9: {'f1': 0.3333333333333333, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.32539568672798425}}, 2: {0.1: {'f1': 0.6896551724137931, 'accuracy': 0.5263157894736842, 'precision': 0.5263157894736842, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.72, 'accuracy': 0.631578947368421, 'precision': 0.6, 'recall': 0.9, 'mcc': 0.2857738033247041}, 0.30000000000000004: {'f1': 0.7272727272727273, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.8, 'mcc': 0.3680349649825889}, 0.4: {'f1': 0.8, 'accuracy': 0.7894736842105263, 'precision': 0.8, 'recall': 0.8, 'mcc': 0.5777777777777777}, 0.5: {'f1': 0.8421052631578947, 'accuracy': 0.8421052631578947, 'precision': 0.8888888888888888, 'recall': 0.8, 'mcc': 0.6888888888888889}, 0.6: {'f1': 0.7777777777777778, 'accuracy': 0.7894736842105263, 'precision': 0.875, 'recall': 0.7, 'mcc': 0.5955432118425306}, 0.7000000000000001: {'f1': 0.7777777777777778, 'accuracy': 0.7894736842105263, 'precision': 0.875, 'recall': 0.7, 'mcc': 0.5955432118425306}, 0.8: {'f1': 0.625, 'accuracy': 0.6842105263157895, 'precision': 0.8333333333333334, 'recall': 0.5, 'mcc': 0.41773367652300253}, 0.9: {'f1': 0.5714285714285714, 'accuracy': 0.6842105263157895, 'precision': 1.0, 'recall': 0.4, 'mcc': 0.4898979485566356}}, 3: {0.1: {'f1': 0.72, 'accuracy': 0.631578947368421, 'precision': 0.5625, 'recall': 1.0, 'mcc': 0.4107919181288746}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.631578947368421, 'precision': 0.5833333333333334, 'recall': 0.7777777777777778, 'mcc': 0.2875273163926476}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.631578947368421, 'precision': 0.5833333333333334, 'recall': 0.7777777777777778, 'mcc': 0.2875273163926476}, 0.4: {'f1': 0.7368421052631579, 'accuracy': 0.7368421052631579, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.4777777777777778}, 0.5: {'f1': 0.8235294117647058, 'accuracy': 0.8421052631578947, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6854365268376295}, 0.6: {'f1': 0.8235294117647058, 'accuracy': 0.8421052631578947, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6854365268376295}, 0.7000000000000001: {'f1': 0.8, 'accuracy': 0.8421052631578947, 'precision': 1.0, 'recall': 0.6666666666666666, 'mcc': 0.7161148740394329}, 0.8: {'f1': 0.7142857142857143, 'accuracy': 0.7894736842105263, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.629940788348712}, 0.9: {'f1': 0.2, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24845199749997662}}, 4: {0.1: {'f1': 0.6923076923076923, 'accuracy': 0.5789473684210527, 'precision': 0.5294117647058824, 'recall': 1.0, 'mcc': 0.32539568672798425}, 0.2: {'f1': 0.75, 'accuracy': 0.6842105263157895, 'precision': 0.6, 'recall': 1.0, 'mcc': 0.4898979485566356}, 0.30000000000000004: {'f1': 0.7619047619047619, 'accuracy': 0.7368421052631579, 'precision': 0.6666666666666666, 'recall': 0.8888888888888888, 'mcc': 0.5060480768510598}, 0.4: {'f1': 0.7777777777777778, 'accuracy': 0.7894736842105263, 'precision': 0.7777777777777778, 'recall': 0.7777777777777778, 'mcc': 0.5777777777777777}, 0.5: {'f1': 0.8235294117647058, 'accuracy': 0.8421052631578947, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6854365268376295}, 0.6: {'f1': 0.7142857142857143, 'accuracy': 0.7894736842105263, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.629940788348712}, 0.7000000000000001: {'f1': 0.6153846153846154, 'accuracy': 0.7368421052631579, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.5443310539518174}, 0.8: {'f1': 0.6153846153846154, 'accuracy': 0.7368421052631579, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.5443310539518174}, 0.9: {'f1': 0.5, 'accuracy': 0.6842105263157895, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.45643546458763845}}, 5: {0.1: {'f1': 0.64, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.8888888888888888, 'mcc': 0.0}, 0.2: {'f1': 0.7, 'accuracy': 0.6666666666666666, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'mcc': 0.34188172937891387}, 0.30000000000000004: {'f1': 0.7368421052631579, 'accuracy': 0.7222222222222222, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.4472135954999579}, 0.4: {'f1': 0.75, 'accuracy': 0.7777777777777778, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.5698028822981898}, 0.5: {'f1': 0.6666666666666666, 'accuracy': 0.7222222222222222, 'precision': 0.8333333333333334, 'recall': 0.5555555555555556, 'mcc': 0.4714045207910316}, 0.6: {'f1': 0.7142857142857143, 'accuracy': 0.7777777777777778, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.6201736729460423}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.6666666666666666, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.4472135954999579}, 0.8: {'f1': 0.5, 'accuracy': 0.6666666666666666, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.4472135954999579}, 0.9: {'f1': 0.36363636363636365, 'accuracy': 0.6111111111111112, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.3535533905932738}}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'n_neighbors': 5, 'metric': 'cosine', 'weights': 'distance'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.6382978723404256, 'accuracy': 0.46875, 'precision': 0.4838709677419355, 'recall': 0.9375, 'mcc': -0.1796053020267749}, 0.2: {'f1': 0.6976744186046512, 'accuracy': 0.59375, 'precision': 0.5555555555555556, 'recall': 0.9375, 'mcc': 0.25819888974716115}, 0.30000000000000004: {'f1': 0.6486486486486487, 'accuracy': 0.59375, 'precision': 0.5714285714285714, 'recall': 0.75, 'mcc': 0.19738550848793068}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.65625, 'precision': 0.6470588235294118, 'recall': 0.6875, 'mcc': 0.31311214554257477}, 0.5: {'f1': 0.6451612903225806, 'accuracy': 0.65625, 'precision': 0.6666666666666666, 'recall': 0.625, 'mcc': 0.31311214554257477}, 0.6: {'f1': 0.56, 'accuracy': 0.65625, 'precision': 0.7777777777777778, 'recall': 0.4375, 'mcc': 0.34752402342845795}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.625, 'precision': 0.75, 'recall': 0.375, 'mcc': 0.2886751345948129}, 0.8: {'f1': 0.45454545454545453, 'accuracy': 0.625, 'precision': 0.8333333333333334, 'recall': 0.3125, 'mcc': 0.32025630761017426}, 0.9: {'f1': 0.47619047619047616, 'accuracy': 0.65625, 'precision': 1.0, 'recall': 0.3125, 'mcc': 0.43033148291193524}}, 2: {0.1: {'f1': 0.7317073170731707, 'accuracy': 0.6451612903225806, 'precision': 0.6, 'recall': 0.9375, 'mcc': 0.34258007985157446}, 0.2: {'f1': 0.6857142857142857, 'accuracy': 0.6451612903225806, 'precision': 0.631578947368421, 'recall': 0.75, 'mcc': 0.290693866424127}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.6451612903225806, 'precision': 0.6470588235294118, 'recall': 0.6875, 'mcc': 0.28870545602072445}, 0.4: {'f1': 0.6, 'accuracy': 0.6129032258064516, 'precision': 0.6428571428571429, 'recall': 0.5625, 'mcc': 0.23012753740782382}, 0.5: {'f1': 0.6153846153846154, 'accuracy': 0.6774193548387096, 'precision': 0.8, 'recall': 0.5, 'mcc': 0.3919831548048891}, 0.6: {'f1': 0.5833333333333334, 'accuracy': 0.6774193548387096, 'precision': 0.875, 'recall': 0.4375, 'mcc': 0.4235215118674525}, 0.7000000000000001: {'f1': 0.38095238095238093, 'accuracy': 0.5806451612903226, 'precision': 0.8, 'recall': 0.25, 'mcc': 0.24910094751181108}, 0.8: {'f1': 0.3157894736842105, 'accuracy': 0.5806451612903226, 'precision': 1.0, 'recall': 0.1875, 'mcc': 0.3169328455231937}, 0.9: {'f1': 0.0, 'accuracy': 0.4838709677419355, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 3: {0.1: {'f1': 0.6521739130434783, 'accuracy': 0.4838709677419355, 'precision': 0.4838709677419355, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.75, 'accuracy': 0.6774193548387096, 'precision': 0.6, 'recall': 1.0, 'mcc': 0.47434164902525694}, 0.30000000000000004: {'f1': 0.7428571428571429, 'accuracy': 0.7096774193548387, 'precision': 0.65, 'recall': 0.8666666666666667, 'mcc': 0.44824996408592194}, 0.4: {'f1': 0.7586206896551724, 'accuracy': 0.7741935483870968, 'precision': 0.7857142857142857, 'recall': 0.7333333333333333, 'mcc': 0.5481219527349985}, 0.5: {'f1': 0.7692307692307693, 'accuracy': 0.8064516129032258, 'precision': 0.9090909090909091, 'recall': 0.6666666666666666, 'mcc': 0.6310315028394047}, 0.6: {'f1': 0.7692307692307693, 'accuracy': 0.8064516129032258, 'precision': 0.9090909090909091, 'recall': 0.6666666666666666, 'mcc': 0.6310315028394047}, 0.7000000000000001: {'f1': 0.6086956521739131, 'accuracy': 0.7096774193548387, 'precision': 0.875, 'recall': 0.4666666666666667, 'mcc': 0.46159086124879656}, 0.8: {'f1': 0.5454545454545454, 'accuracy': 0.6774193548387096, 'precision': 0.8571428571428571, 'recall': 0.4, 'mcc': 0.4033896556503579}, 0.9: {'f1': 0.23529411764705882, 'accuracy': 0.5806451612903226, 'precision': 1.0, 'recall': 0.13333333333333333, 'mcc': 0.2712254014483242}}}\n",
      "Starting KNN analysis for flaky vs larger non-flaky files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "KNN analysis completed for 5 folds. Results saved to: larger-params-knn-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "KNN analysis completed for 3 folds. Results saved to: larger-params-knn-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'n_neighbors': 5, 'metric': 'cosine', 'weights': 'distance'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.2962962962962963, 'accuracy': 0.6885245901639344, 'precision': 0.23529411764705882, 'recall': 0.4, 'mcc': 0.11981076267551573}, 0.2: {'f1': 0.42105263157894735, 'accuracy': 0.819672131147541, 'precision': 0.4444444444444444, 'recall': 0.4, 'mcc': 0.3152192317563229}, 0.30000000000000004: {'f1': 0.2857142857142857, 'accuracy': 0.8360655737704918, 'precision': 0.5, 'recall': 0.2, 'mcc': 0.24047024221824384}, 0.4: {'f1': 0.3076923076923077, 'accuracy': 0.8524590163934426, 'precision': 0.6666666666666666, 'recall': 0.2, 'mcc': 0.3088361395624583}, 0.5: {'f1': 0.3076923076923077, 'accuracy': 0.8524590163934426, 'precision': 0.6666666666666666, 'recall': 0.2, 'mcc': 0.3088361395624583}, 0.6: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}, 0.7000000000000001: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}, 0.8: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}, 0.9: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}}, 2: {0.1: {'f1': 0.5454545454545454, 'accuracy': 0.75, 'precision': 0.391304347826087, 'recall': 0.9, 'mcc': 0.47523882300946035}, 0.2: {'f1': 0.56, 'accuracy': 0.8166666666666667, 'precision': 0.4666666666666667, 'recall': 0.7, 'mcc': 0.46475800154489}, 0.30000000000000004: {'f1': 0.5263157894736842, 'accuracy': 0.85, 'precision': 0.5555555555555556, 'recall': 0.5, 'mcc': 0.4383570037596047}, 0.4: {'f1': 0.47058823529411764, 'accuracy': 0.85, 'precision': 0.5714285714285714, 'recall': 0.4, 'mcc': 0.3947089411806863}, 0.5: {'f1': 0.4, 'accuracy': 0.85, 'precision': 0.6, 'recall': 0.3, 'mcc': 0.3505839284808859}, 0.6: {'f1': 0.46153846153846156, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.3, 'mcc': 0.5129891760425771}, 0.7000000000000001: {'f1': 0.46153846153846156, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.3, 'mcc': 0.5129891760425771}, 0.8: {'f1': 0.46153846153846156, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.3, 'mcc': 0.5129891760425771}, 0.9: {'f1': 0.46153846153846156, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.3, 'mcc': 0.5129891760425771}}, 3: {0.1: {'f1': 0.5384615384615384, 'accuracy': 0.8, 'precision': 0.4117647058823529, 'recall': 0.7777777777777778, 'mcc': 0.46094194507635605}, 0.2: {'f1': 0.7, 'accuracy': 0.9, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'mcc': 0.6453633629788592}, 0.30000000000000004: {'f1': 0.75, 'accuracy': 0.9333333333333333, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.7197193047267257}, 0.4: {'f1': 0.5714285714285714, 'accuracy': 0.9, 'precision': 0.8, 'recall': 0.4444444444444444, 'mcc': 0.5488604301969738}, 0.5: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.6: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.8: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 4: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.85, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.6416889479197478}, 0.2: {'f1': 0.7777777777777778, 'accuracy': 0.9333333333333333, 'precision': 0.7777777777777778, 'recall': 0.7777777777777778, 'mcc': 0.738562091503268}, 0.30000000000000004: {'f1': 0.6153846153846154, 'accuracy': 0.9166666666666666, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.6362090102803518}, 0.4: {'f1': 0.6153846153846154, 'accuracy': 0.9166666666666666, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.6362090102803518}, 0.5: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.6: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.8: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.9: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}}, 5: {0.1: {'f1': 0.36363636363636365, 'accuracy': 0.7666666666666667, 'precision': 0.3076923076923077, 'recall': 0.4444444444444444, 'mcc': 0.2322620011424027}, 0.2: {'f1': 0.4, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.3333333333333333, 'mcc': 0.32673201960653564}, 0.30000000000000004: {'f1': 0.3333333333333333, 'accuracy': 0.8666666666666667, 'precision': 0.6666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.33195449253833836}, 0.4: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.5: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.6: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.8: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.9: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'n_neighbors': 5, 'metric': 'cosine', 'weights': 'distance'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.46153846153846156, 'accuracy': 0.7227722772277227, 'precision': 0.3333333333333333, 'recall': 0.75, 'mcc': 0.3565165808180456}, 0.2: {'f1': 0.6285714285714286, 'accuracy': 0.8712871287128713, 'precision': 0.5789473684210527, 'recall': 0.6875, 'mcc': 0.5543963391957871}, 0.30000000000000004: {'f1': 0.5384615384615384, 'accuracy': 0.8811881188118812, 'precision': 0.7, 'recall': 0.4375, 'mcc': 0.4916965668965636}, 0.4: {'f1': 0.5384615384615384, 'accuracy': 0.8811881188118812, 'precision': 0.7, 'recall': 0.4375, 'mcc': 0.4916965668965636}, 0.5: {'f1': 0.45454545454545453, 'accuracy': 0.8811881188118812, 'precision': 0.8333333333333334, 'recall': 0.3125, 'mcc': 0.4645328445588004}, 0.6: {'f1': 0.47619047619047616, 'accuracy': 0.8910891089108911, 'precision': 1.0, 'recall': 0.3125, 'mcc': 0.5260158822063582}, 0.7000000000000001: {'f1': 0.47619047619047616, 'accuracy': 0.8910891089108911, 'precision': 1.0, 'recall': 0.3125, 'mcc': 0.5260158822063582}, 0.8: {'f1': 0.4, 'accuracy': 0.8811881188118812, 'precision': 1.0, 'recall': 0.25, 'mcc': 0.46805145544956234}, 0.9: {'f1': 0.3157894736842105, 'accuracy': 0.8712871287128713, 'precision': 1.0, 'recall': 0.1875, 'mcc': 0.40327106395129336}}, 2: {0.1: {'f1': 0.4727272727272727, 'accuracy': 0.71, 'precision': 0.3333333333333333, 'recall': 0.8125, 'mcc': 0.37805052069913186}, 0.2: {'f1': 0.5116279069767442, 'accuracy': 0.79, 'precision': 0.4074074074074074, 'recall': 0.6875, 'mcc': 0.41042472510575595}, 0.30000000000000004: {'f1': 0.4117647058823529, 'accuracy': 0.8, 'precision': 0.3888888888888889, 'recall': 0.4375, 'mcc': 0.29251921745363624}, 0.4: {'f1': 0.4666666666666667, 'accuracy': 0.84, 'precision': 0.5, 'recall': 0.4375, 'mcc': 0.3741916351883901}, 0.5: {'f1': 0.38095238095238093, 'accuracy': 0.87, 'precision': 0.8, 'recall': 0.25, 'mcc': 0.4005009394574071}, 0.6: {'f1': 0.21052631578947367, 'accuracy': 0.85, 'precision': 0.6666666666666666, 'recall': 0.125, 'mcc': 0.24305102621022315}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.84, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.84, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.84, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 3: {0.1: {'f1': 0.4489795918367347, 'accuracy': 0.73, 'precision': 0.3235294117647059, 'recall': 0.7333333333333333, 'mcc': 0.3488072417664324}, 0.2: {'f1': 0.5161290322580645, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.5333333333333333, 'mcc': 0.4277926319464986}, 0.30000000000000004: {'f1': 0.5185185185185185, 'accuracy': 0.87, 'precision': 0.5833333333333334, 'recall': 0.4666666666666667, 'mcc': 0.4481426646623499}, 0.4: {'f1': 0.5384615384615384, 'accuracy': 0.88, 'precision': 0.6363636363636364, 'recall': 0.4666666666666667, 'mcc': 0.4788586576139561}, 0.5: {'f1': 0.6363636363636364, 'accuracy': 0.92, 'precision': 1.0, 'recall': 0.4666666666666667, 'mcc': 0.6530875113574286}, 0.6: {'f1': 0.5714285714285714, 'accuracy': 0.91, 'precision': 1.0, 'recall': 0.4, 'mcc': 0.6014167670256413}, 0.7000000000000001: {'f1': 0.3333333333333333, 'accuracy': 0.88, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4186379485411743}, 0.8: {'f1': 0.3333333333333333, 'accuracy': 0.88, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4186379485411743}, 0.9: {'f1': 0.23529411764705882, 'accuracy': 0.87, 'precision': 1.0, 'recall': 0.13333333333333333, 'mcc': 0.3400680204068024}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# KNN with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define KNN model with given parameters\n",
    "    knn_model = KNeighborsClassifier(\n",
    "        n_neighbors=int(params.get('n_neighbors', 5)),\n",
    "        metric=params.get('metric', 'cosine'),\n",
    "        weights=params.get('weights', 'distance')\n",
    "    )\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_fold = {fold+1: {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                                 for threshold in thresholds}\n",
    "                        for fold in range(n_splits)}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        knn_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = knn_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold for this fold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Store metrics for the current threshold for this fold\n",
    "            metrics_per_fold[fold+1][threshold]['f1'] = f1\n",
    "            metrics_per_fold[fold+1][threshold]['accuracy'] = accuracy\n",
    "            metrics_per_fold[fold+1][threshold]['precision'] = precision\n",
    "            metrics_per_fold[fold+1][threshold]['recall'] = recall\n",
    "            metrics_per_fold[fold+1][threshold]['mcc'] = mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Save the results for each threshold and fold\n",
    "    outFile = f\"{combination_label}-params-knn-{n_splits}-folds-Threshold-allKfold_one_hyperparameter.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"fold,threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each fold and each threshold\n",
    "        for fold in range(1, successFold + 1):\n",
    "            for threshold in thresholds:\n",
    "                fo.write(f\"{fold},{threshold},{metrics_per_fold[fold][threshold]['accuracy']},{metrics_per_fold[fold][threshold]['precision']},\" \n",
    "                         f\"{metrics_per_fold[fold][threshold]['recall']},{metrics_per_fold[fold][threshold]['f1']},{metrics_per_fold[fold][threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"KNN analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_fold\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Update the parameters for KNN with cosine distance and distance-based weights\n",
    "    params = {\n",
    "        \"n_neighbors\": 5,       # Number of neighbors\n",
    "        \"metric\": 'cosine',     # Metric to use for distance calculation\n",
    "        \"weights\": 'distance'   # Weight points by the inverse of their distance\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform KNN analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting KNN analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform KNN analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting KNN analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96d39b9",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648dad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SVM analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "SVM analysis completed for 5 folds. Results saved to: equal-params-svm-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "SVM analysis completed for 3 folds. Results saved to: equal-params-svm-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear', 'degree': 3, 'gamma': 'scale'}\n",
      "Best Metrics: {1: {0.1: {'f1': 0.6896551724137931, 'accuracy': 0.5263157894736842, 'precision': 0.5263157894736842, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.6896551724137931, 'accuracy': 0.5263157894736842, 'precision': 0.5263157894736842, 'recall': 1.0, 'mcc': 0.0}, 0.30000000000000004: {'f1': 0.6896551724137931, 'accuracy': 0.5263157894736842, 'precision': 0.5263157894736842, 'recall': 1.0, 'mcc': 0.0}, 0.4: {'f1': 0.6428571428571429, 'accuracy': 0.47368421052631576, 'precision': 0.5, 'recall': 0.9, 'mcc': -0.22360679774997896}, 0.5: {'f1': 0.631578947368421, 'accuracy': 0.631578947368421, 'precision': 0.6666666666666666, 'recall': 0.6, 'mcc': 0.26666666666666666}, 0.6: {'f1': 0.5714285714285714, 'accuracy': 0.6842105263157895, 'precision': 1.0, 'recall': 0.4, 'mcc': 0.4898979485566356}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 2: {0.1: {'f1': 0.6896551724137931, 'accuracy': 0.5263157894736842, 'precision': 0.5263157894736842, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.6896551724137931, 'accuracy': 0.5263157894736842, 'precision': 0.5263157894736842, 'recall': 1.0, 'mcc': 0.0}, 0.30000000000000004: {'f1': 0.6896551724137931, 'accuracy': 0.5263157894736842, 'precision': 0.5263157894736842, 'recall': 1.0, 'mcc': 0.0}, 0.4: {'f1': 0.64, 'accuracy': 0.5263157894736842, 'precision': 0.5333333333333333, 'recall': 0.8, 'mcc': 0.027216552697590865}, 0.5: {'f1': 0.5333333333333333, 'accuracy': 0.631578947368421, 'precision': 0.8, 'recall': 0.4, 'mcc': 0.32756920994133026}, 0.6: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.47368421052631576, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 3: {0.1: {'f1': 0.6153846153846154, 'accuracy': 0.47368421052631576, 'precision': 0.47058823529411764, 'recall': 0.8888888888888888, 'mcc': -0.018077538151554683}, 0.2: {'f1': 0.6153846153846154, 'accuracy': 0.47368421052631576, 'precision': 0.47058823529411764, 'recall': 0.8888888888888888, 'mcc': -0.018077538151554683}, 0.30000000000000004: {'f1': 0.6956521739130435, 'accuracy': 0.631578947368421, 'precision': 0.5714285714285714, 'recall': 0.8888888888888888, 'mcc': 0.32756920994133026}, 0.4: {'f1': 0.7, 'accuracy': 0.6842105263157895, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'mcc': 0.3820465887291705}, 0.5: {'f1': 0.7777777777777778, 'accuracy': 0.7894736842105263, 'precision': 0.7777777777777778, 'recall': 0.7777777777777778, 'mcc': 0.5777777777777777}, 0.6: {'f1': 0.5333333333333333, 'accuracy': 0.631578947368421, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.26257545381445874}, 0.7000000000000001: {'f1': 0.3076923076923077, 'accuracy': 0.5263157894736842, 'precision': 0.5, 'recall': 0.2222222222222222, 'mcc': 0.027216552697590865}, 0.8: {'f1': 0.3333333333333333, 'accuracy': 0.5789473684210527, 'precision': 0.6666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.16735967034880075}, 0.9: {'f1': 0.18181818181818182, 'accuracy': 0.5263157894736842, 'precision': 0.5, 'recall': 0.1111111111111111, 'mcc': 0.018077538151554683}}, 4: {0.1: {'f1': 0.5925925925925926, 'accuracy': 0.42105263157894735, 'precision': 0.4444444444444444, 'recall': 0.8888888888888888, 'mcc': -0.24845199749997662}, 0.2: {'f1': 0.64, 'accuracy': 0.5263157894736842, 'precision': 0.5, 'recall': 0.8888888888888888, 'mcc': 0.12171612389003691}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.5789473684210527, 'precision': 0.5333333333333333, 'recall': 0.8888888888888888, 'mcc': 0.23134069792952236}, 0.4: {'f1': 0.7, 'accuracy': 0.6842105263157895, 'precision': 0.6363636363636364, 'recall': 0.7777777777777778, 'mcc': 0.3820465887291705}, 0.5: {'f1': 0.75, 'accuracy': 0.7894736842105263, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.5865557254410011}, 0.6: {'f1': 0.18181818181818182, 'accuracy': 0.5263157894736842, 'precision': 0.5, 'recall': 0.1111111111111111, 'mcc': 0.018077538151554683}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24845199749997662}, 0.8: {'f1': 0.2, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24845199749997662}, 0.9: {'f1': 0.2, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24845199749997662}}, 5: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.5: {'f1': 0.6666666666666666, 'accuracy': 0.7222222222222222, 'precision': 0.8333333333333334, 'recall': 0.5555555555555556, 'mcc': 0.4714045207910316}, 0.6: {'f1': 0.2, 'accuracy': 0.5555555555555556, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24253562503633297}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.5555555555555556, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24253562503633297}, 0.8: {'f1': 0.0, 'accuracy': 0.5, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.5, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear', 'degree': 3, 'gamma': 'scale'}\n",
      "Best Metrics: {1: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.5: {'f1': 0.6153846153846154, 'accuracy': 0.53125, 'precision': 0.5217391304347826, 'recall': 0.75, 'mcc': 0.06950480468569159}, 0.6: {'f1': 0.0, 'accuracy': 0.5, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.5, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.5, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.5, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 2: {0.1: {'f1': 0.7111111111111111, 'accuracy': 0.5806451612903226, 'precision': 0.5517241379310345, 'recall': 1.0, 'mcc': 0.2712254014483242}, 0.2: {'f1': 0.7317073170731707, 'accuracy': 0.6451612903225806, 'precision': 0.6, 'recall': 0.9375, 'mcc': 0.34258007985157446}, 0.30000000000000004: {'f1': 0.7692307692307693, 'accuracy': 0.7096774193548387, 'precision': 0.6521739130434783, 'recall': 0.9375, 'mcc': 0.46159086124879656}, 0.4: {'f1': 0.6857142857142857, 'accuracy': 0.6451612903225806, 'precision': 0.631578947368421, 'recall': 0.75, 'mcc': 0.290693866424127}, 0.5: {'f1': 0.7096774193548387, 'accuracy': 0.7096774193548387, 'precision': 0.7333333333333333, 'recall': 0.6875, 'mcc': 0.42083333333333334}, 0.6: {'f1': 0.6666666666666666, 'accuracy': 0.6774193548387096, 'precision': 0.7142857142857143, 'recall': 0.625, 'mcc': 0.3598357857649609}, 0.7000000000000001: {'f1': 0.6153846153846154, 'accuracy': 0.6774193548387096, 'precision': 0.8, 'recall': 0.5, 'mcc': 0.3919831548048891}, 0.8: {'f1': 0.36363636363636365, 'accuracy': 0.5483870967741935, 'precision': 0.6666666666666666, 'recall': 0.25, 'mcc': 0.14757295747452437}, 0.9: {'f1': 0.0, 'accuracy': 0.45161290322580644, 'precision': 0.0, 'recall': 0.0, 'mcc': -0.18856180831641267}}, 3: {0.1: {'f1': 0.6818181818181818, 'accuracy': 0.5483870967741935, 'precision': 0.5172413793103449, 'recall': 1.0, 'mcc': 0.2542738138578039}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.5483870967741935, 'precision': 0.5185185185185185, 'recall': 0.9333333333333333, 'mcc': 0.18012769818748306}, 0.30000000000000004: {'f1': 0.7567567567567568, 'accuracy': 0.7096774193548387, 'precision': 0.6363636363636364, 'recall': 0.9333333333333333, 'mcc': 0.4770842982214229}, 0.4: {'f1': 0.6896551724137931, 'accuracy': 0.7096774193548387, 'precision': 0.7142857142857143, 'recall': 0.6666666666666666, 'mcc': 0.4184137043778615}, 0.5: {'f1': 0.5384615384615384, 'accuracy': 0.6129032258064516, 'precision': 0.6363636363636364, 'recall': 0.4666666666666667, 'mcc': 0.2263009527424072}, 0.6: {'f1': 0.5, 'accuracy': 0.6129032258064516, 'precision': 0.6666666666666666, 'recall': 0.4, 'mcc': 0.23395480008935163}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.5161290322580645, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.5161290322580645, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.5161290322580645, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}}\n",
      "Starting SVM analysis for flaky vs larger non-flaky files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "SVM analysis completed for 5 folds. Results saved to: larger-params-svm-5-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "SVM analysis completed for 3 folds. Results saved to: larger-params-svm-3-folds-Threshold-allKfold_one_hyperparameter.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear', 'degree': 3, 'gamma': 'scale'}\n",
      "Best Metrics: {1: {0.1: {'f1': 0.24242424242424243, 'accuracy': 0.18032786885245902, 'precision': 0.14285714285714285, 'recall': 0.8, 'mcc': -0.19053220464898674}, 0.2: {'f1': 0.26666666666666666, 'accuracy': 0.819672131147541, 'precision': 0.4, 'recall': 0.2, 'mcc': 0.19053220464898674}, 0.30000000000000004: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}, 0.4: {'f1': 0.0, 'accuracy': 0.8360655737704918, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.5: {'f1': 0.0, 'accuracy': 0.8360655737704918, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.6: {'f1': 0.0, 'accuracy': 0.8360655737704918, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.8360655737704918, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.8360655737704918, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.8360655737704918, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 2: {0.1: {'f1': 0.32727272727272727, 'accuracy': 0.38333333333333336, 'precision': 0.2, 'recall': 0.9, 'mcc': 0.15491933384829668}, 0.2: {'f1': 0.5714285714285714, 'accuracy': 0.85, 'precision': 0.5454545454545454, 'recall': 0.6, 'mcc': 0.4815713303308872}, 0.30000000000000004: {'f1': 0.26666666666666666, 'accuracy': 0.8166666666666667, 'precision': 0.4, 'recall': 0.2, 'mcc': 0.18877596148970777}, 0.4: {'f1': 0.14285714285714285, 'accuracy': 0.8, 'precision': 0.25, 'recall': 0.1, 'mcc': 0.05976143046671968}, 0.5: {'f1': 0.0, 'accuracy': 0.8, 'precision': 0.0, 'recall': 0.0, 'mcc': -0.08304547985373997}, 0.6: {'f1': 0.0, 'accuracy': 0.8, 'precision': 0.0, 'recall': 0.0, 'mcc': -0.08304547985373997}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.8333333333333334, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.8333333333333334, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.8333333333333334, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 3: {0.1: {'f1': 0.3783783783783784, 'accuracy': 0.6166666666666667, 'precision': 0.25, 'recall': 0.7777777777777778, 'mcc': 0.2619684159977919}, 0.2: {'f1': 0.5714285714285714, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.6666666666666666, 'mcc': 0.4900980294098034}, 0.30000000000000004: {'f1': 0.4, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.3333333333333333, 'mcc': 0.32673201960653564}, 0.4: {'f1': 0.3076923076923077, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.2222222222222222, 'mcc': 0.2619684159977919}, 0.5: {'f1': 0.18181818181818182, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.1111111111111111, 'mcc': 0.18201783862232032}, 0.6: {'f1': 0.18181818181818182, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.1111111111111111, 'mcc': 0.18201783862232032}, 0.7000000000000001: {'f1': 0.18181818181818182, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.1111111111111111, 'mcc': 0.18201783862232032}, 0.8: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 4: {0.1: {'f1': 0.3333333333333333, 'accuracy': 0.4, 'precision': 0.2, 'recall': 1.0, 'mcc': 0.242535625036333}, 0.2: {'f1': 0.8571428571428571, 'accuracy': 0.95, 'precision': 0.75, 'recall': 1.0, 'mcc': 0.8401680504168058}, 0.30000000000000004: {'f1': 0.42857142857142855, 'accuracy': 0.8666666666666667, 'precision': 0.6, 'recall': 0.3333333333333333, 'mcc': 0.3799802978286742}, 0.4: {'f1': 0.3076923076923077, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.2222222222222222, 'mcc': 0.2619684159977919}, 0.5: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.6: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.8: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 5: {0.1: {'f1': 0.375, 'accuracy': 0.5, 'precision': 0.23076923076923078, 'recall': 1.0, 'mcc': 0.3082573996425538}, 0.2: {'f1': 0.5333333333333333, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.4444444444444444, 'mcc': 0.48231869560964785}, 0.30000000000000004: {'f1': 0.3333333333333333, 'accuracy': 0.8666666666666667, 'precision': 0.6666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.33195449253833836}, 0.4: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.5: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.6: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.8: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.9: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear', 'degree': 3, 'gamma': 'scale'}\n",
      "Best Metrics: {1: {0.1: {'f1': 0.27350427350427353, 'accuracy': 0.15841584158415842, 'precision': 0.15841584158415842, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.30000000000000004: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.4: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.5: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.6: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.8415841584158416, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 2: {0.1: {'f1': 0.29473684210526313, 'accuracy': 0.33, 'precision': 0.17721518987341772, 'recall': 0.875, 'mcc': 0.09107854436067812}, 0.2: {'f1': 0.5, 'accuracy': 0.84, 'precision': 0.5, 'recall': 0.5, 'mcc': 0.40476190476190477}, 0.30000000000000004: {'f1': 0.3076923076923077, 'accuracy': 0.82, 'precision': 0.4, 'recall': 0.25, 'mcc': 0.21821789023599236}, 0.4: {'f1': 0.2, 'accuracy': 0.84, 'precision': 0.5, 'recall': 0.125, 'mcc': 0.18931004635463394}, 0.5: {'f1': 0.2222222222222222, 'accuracy': 0.86, 'precision': 1.0, 'recall': 0.125, 'mcc': 0.32732683535398854}, 0.6: {'f1': 0.11764705882352941, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23028309323591917}, 0.7000000000000001: {'f1': 0.11764705882352941, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23028309323591917}, 0.8: {'f1': 0.11764705882352941, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23028309323591917}, 0.9: {'f1': 0.11764705882352941, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23028309323591917}}, 3: {0.1: {'f1': 0.2777777777777778, 'accuracy': 0.22, 'precision': 0.16129032258064516, 'recall': 1.0, 'mcc': 0.11525073729836975}, 0.2: {'f1': 0.19047619047619047, 'accuracy': 0.83, 'precision': 0.3333333333333333, 'recall': 0.13333333333333333, 'mcc': 0.12971734190749126}, 0.30000000000000004: {'f1': 0.125, 'accuracy': 0.86, 'precision': 1.0, 'recall': 0.06666666666666667, 'mcc': 0.23924685418842448}, 0.4: {'f1': 0.125, 'accuracy': 0.86, 'precision': 1.0, 'recall': 0.06666666666666667, 'mcc': 0.23924685418842448}, 0.5: {'f1': 0.125, 'accuracy': 0.86, 'precision': 1.0, 'recall': 0.06666666666666667, 'mcc': 0.23924685418842448}, 0.6: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC  # Using SVM\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# SVM with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define SVM model with the given parameters\n",
    "    svc_model = SVC(\n",
    "        C=params.get('C', 1.0),\n",
    "        kernel=params.get('kernel', 'rbf'),\n",
    "        degree=params.get('degree', 3),\n",
    "        gamma=params.get('gamma', 'scale'),\n",
    "        probability=True,  # Enables probability estimates\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_fold = {fold+1: {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                                 for threshold in thresholds}\n",
    "                        for fold in range(n_splits)}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        svc_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = svc_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold for this fold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Store metrics for the current threshold for this fold\n",
    "            metrics_per_fold[fold+1][threshold]['f1'] = f1\n",
    "            metrics_per_fold[fold+1][threshold]['accuracy'] = accuracy\n",
    "            metrics_per_fold[fold+1][threshold]['precision'] = precision\n",
    "            metrics_per_fold[fold+1][threshold]['recall'] = recall\n",
    "            metrics_per_fold[fold+1][threshold]['mcc'] = mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Save the results for each threshold and fold\n",
    "    outFile = f\"{combination_label}-params-svm-{n_splits}-folds-Threshold-allKfold_one_hyperparameter.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"fold,threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each fold and each threshold\n",
    "        for fold in range(1, successFold + 1):\n",
    "            for threshold in thresholds:\n",
    "                fo.write(f\"{fold},{threshold},{metrics_per_fold[fold][threshold]['accuracy']},{metrics_per_fold[fold][threshold]['precision']},\"\n",
    "                         f\"{metrics_per_fold[fold][threshold]['recall']},{metrics_per_fold[fold][threshold]['f1']},{metrics_per_fold[fold][threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"SVM analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_fold\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Updated SVM parameters\n",
    "    params = {\n",
    "        \"C\": 0.01,  # Lower C for a simpler decision boundary\n",
    "        \"kernel\": \"linear\",  # Linear kernel\n",
    "        \"degree\": 3,  # This parameter is ignored for linear kernel\n",
    "        \"gamma\": \"scale\",  # This parameter is ignored for linear kernel\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform SVM analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting SVM analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best Metrics: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best Metrics: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform SVM analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting SVM analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best Metrics: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best Metrics: {best_score_3folds_2}\")\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36f79a",
   "metadata": {},
   "source": [
    "NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bc77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbfe70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
