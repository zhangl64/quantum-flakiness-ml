{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7e03351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: equal-params-dt-5-folds-Threshold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: equal-params-dt-3-folds-Threshold.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.6185994397759104, 'accuracy': 0.6485380116959065, 'precision': 0.7146464646464646, 'recall': 0.5800000000000001, 'mcc': 0.3256764910632027}, 0.2: {'f1': 0.6185994397759104, 'accuracy': 0.6485380116959065, 'precision': 0.7146464646464646, 'recall': 0.5800000000000001, 'mcc': 0.3256764910632027}, 0.30000000000000004: {'f1': 0.627749766573296, 'accuracy': 0.6590643274853801, 'precision': 0.7340909090909091, 'recall': 0.5800000000000001, 'mcc': 0.347208240875173}, 0.4: {'f1': 0.607749766573296, 'accuracy': 0.6590643274853801, 'precision': 0.7392857142857142, 'recall': 0.5355555555555556, 'mcc': 0.34340108865684627}, 0.5: {'f1': 0.607749766573296, 'accuracy': 0.6590643274853801, 'precision': 0.7392857142857142, 'recall': 0.5355555555555556, 'mcc': 0.34340108865684627}, 0.6: {'f1': 0.6142857142857143, 'accuracy': 0.6695906432748538, 'precision': 0.7571428571428571, 'recall': 0.5355555555555556, 'mcc': 0.36719655881221364}, 0.7000000000000001: {'f1': 0.5776018099547511, 'accuracy': 0.6485380116959065, 'precision': 0.7535714285714286, 'recall': 0.49333333333333335, 'mcc': 0.3315991924473358}, 0.8: {'f1': 0.5599547511312217, 'accuracy': 0.6374269005847953, 'precision': 0.7428571428571429, 'recall': 0.47111111111111104, 'mcc': 0.30966994818926763}, 0.9: {'f1': 0.5599547511312217, 'accuracy': 0.6374269005847953, 'precision': 0.7428571428571429, 'recall': 0.47111111111111104, 'mcc': 0.30966994818926763}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.5688888888888889, 'accuracy': 0.617271505376344, 'precision': 0.6555555555555556, 'recall': 0.5305555555555556, 'mcc': 0.24441902897834086}, 0.2: {'f1': 0.5688888888888889, 'accuracy': 0.617271505376344, 'precision': 0.6555555555555556, 'recall': 0.5305555555555556, 'mcc': 0.24441902897834086}, 0.30000000000000004: {'f1': 0.5688888888888889, 'accuracy': 0.617271505376344, 'precision': 0.6555555555555556, 'recall': 0.5305555555555556, 'mcc': 0.24441902897834086}, 0.4: {'f1': 0.5628019323671497, 'accuracy': 0.6273521505376344, 'precision': 0.707936507936508, 'recall': 0.5083333333333333, 'mcc': 0.2794067419469954}, 0.5: {'f1': 0.5628019323671497, 'accuracy': 0.6273521505376344, 'precision': 0.707936507936508, 'recall': 0.5083333333333333, 'mcc': 0.2794067419469954}, 0.6: {'f1': 0.550103519668737, 'accuracy': 0.6165994623655914, 'precision': 0.7009189640768588, 'recall': 0.4875, 'mcc': 0.25669697857056895}, 0.7000000000000001: {'f1': 0.550103519668737, 'accuracy': 0.6165994623655914, 'precision': 0.7009189640768588, 'recall': 0.4875, 'mcc': 0.25669697857056895}, 0.8: {'f1': 0.550103519668737, 'accuracy': 0.6165994623655914, 'precision': 0.7009189640768588, 'recall': 0.4875, 'mcc': 0.25669697857056895}, 0.9: {'f1': 0.550103519668737, 'accuracy': 0.6165994623655914, 'precision': 0.7009189640768588, 'recall': 0.4875, 'mcc': 0.25669697857056895}}\n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: larger-params-dt-5-folds-Threshold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: larger-params-dt-3-folds-Threshold.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.4583223539745279, 'accuracy': 0.8170491803278688, 'precision': 0.4247863247863248, 'recall': 0.5022222222222222, 'mcc': 0.3525753421139758}, 0.2: {'f1': 0.4583223539745279, 'accuracy': 0.8170491803278688, 'precision': 0.4247863247863248, 'recall': 0.5022222222222222, 'mcc': 0.3525753421139758}, 0.30000000000000004: {'f1': 0.44900565759900796, 'accuracy': 0.8203825136612022, 'precision': 0.4261072261072261, 'recall': 0.48, 'mcc': 0.3448385152741559}, 0.4: {'f1': 0.45656565656565656, 'accuracy': 0.8336612021857924, 'precision': 0.4587301587301587, 'recall': 0.45999999999999996, 'mcc': 0.36031692792402065}, 0.5: {'f1': 0.45656565656565656, 'accuracy': 0.8336612021857924, 'precision': 0.4587301587301587, 'recall': 0.45999999999999996, 'mcc': 0.36031692792402065}, 0.6: {'f1': 0.46545454545454545, 'accuracy': 0.8436612021857923, 'precision': 0.4809523809523809, 'recall': 0.45999999999999996, 'mcc': 0.3775525325924177}, 0.7000000000000001: {'f1': 0.4616666666666666, 'accuracy': 0.8470491803278689, 'precision': 0.49393939393939384, 'recall': 0.43999999999999995, 'mcc': 0.37642685483246624}, 0.8: {'f1': 0.4206410256410257, 'accuracy': 0.8470491803278689, 'precision': 0.5666666666666667, 'recall': 0.36, 'mcc': 0.35944053682276456}, 0.9: {'f1': 0.4206410256410257, 'accuracy': 0.8470491803278689, 'precision': 0.5666666666666667, 'recall': 0.36, 'mcc': 0.35944053682276456}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.3619047619047619, 'accuracy': 0.7774917491749175, 'precision': 0.3254385964912281, 'recall': 0.4083333333333334, 'mcc': 0.23148314715012508}, 0.2: {'f1': 0.3619047619047619, 'accuracy': 0.7774917491749175, 'precision': 0.3254385964912281, 'recall': 0.4083333333333334, 'mcc': 0.23148314715012508}, 0.30000000000000004: {'f1': 0.35209235209235207, 'accuracy': 0.7774917491749175, 'precision': 0.3235867446393762, 'recall': 0.38611111111111107, 'mcc': 0.22023748815041774}, 0.4: {'f1': 0.35489347254053133, 'accuracy': 0.7807920792079207, 'precision': 0.3284600389863548, 'recall': 0.38611111111111107, 'mcc': 0.22495459413754962}, 0.5: {'f1': 0.35489347254053133, 'accuracy': 0.7807920792079207, 'precision': 0.3284600389863548, 'recall': 0.38611111111111107, 'mcc': 0.22495459413754962}, 0.6: {'f1': 0.33939393939393936, 'accuracy': 0.7874917491749175, 'precision': 0.33464052287581697, 'recall': 0.3444444444444444, 'mcc': 0.21288318533243114}, 0.7000000000000001: {'f1': 0.33939393939393936, 'accuracy': 0.7874917491749175, 'precision': 0.33464052287581697, 'recall': 0.3444444444444444, 'mcc': 0.21288318533243114}, 0.8: {'f1': 0.3441644562334218, 'accuracy': 0.8107920792079208, 'precision': 0.3738095238095238, 'recall': 0.3236111111111111, 'mcc': 0.2374370106707436}, 0.9: {'f1': 0.3441644562334218, 'accuracy': 0.8107920792079208, 'precision': 0.3738095238095238, 'recall': 0.3236111111111111, 'mcc': 0.2374370106707436}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define Decision Tree model with given parameters\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=params.get('criterion', 'entropy'),\n",
    "        max_depth=params.get('max_depth', None),\n",
    "        min_samples_split=params.get('min_samples_split', 2),\n",
    "        min_samples_leaf=params.get('min_samples_leaf', 1),\n",
    "        max_features=params.get('max_features', None),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "        # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize metrics storage for each threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_threshold = {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                             for threshold in thresholds}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Accumulate metrics for the current threshold\n",
    "            metrics_per_threshold[threshold]['f1'] += f1\n",
    "            metrics_per_threshold[threshold]['accuracy'] += accuracy\n",
    "            metrics_per_threshold[threshold]['precision'] += precision\n",
    "            metrics_per_threshold[threshold]['recall'] += recall\n",
    "            metrics_per_threshold[threshold]['mcc'] += mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Average metrics over all folds\n",
    "    for threshold in thresholds:\n",
    "        metrics_per_threshold[threshold]['f1'] /= successFold\n",
    "        metrics_per_threshold[threshold]['accuracy'] /= successFold\n",
    "        metrics_per_threshold[threshold]['precision'] /= successFold\n",
    "        metrics_per_threshold[threshold]['recall'] /= successFold\n",
    "        metrics_per_threshold[threshold]['mcc'] /= successFold\n",
    "\n",
    "    # Save the results for each threshold\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each threshold\n",
    "        for threshold in thresholds:\n",
    "            fo.write(f\"{threshold},{metrics_per_threshold[threshold]['accuracy']},{metrics_per_threshold[threshold]['precision']},\"\n",
    "                     f\"{metrics_per_threshold[threshold]['recall']},{metrics_per_threshold[threshold]['f1']},{metrics_per_threshold[threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_threshold\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    params = {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"max_depth\": 300,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\" : 'log2'\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9c255f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: equal-params-dt-5-folds-Threshold-allKfold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: equal-params-dt-3-folds-Threshold-allKfold.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.6, 'accuracy': 0.5789473684210527, 'precision': 0.6, 'recall': 0.6, 'mcc': 0.15555555555555556}, 0.2: {'f1': 0.6, 'accuracy': 0.5789473684210527, 'precision': 0.6, 'recall': 0.6, 'mcc': 0.15555555555555556}, 0.30000000000000004: {'f1': 0.6, 'accuracy': 0.5789473684210527, 'precision': 0.6, 'recall': 0.6, 'mcc': 0.15555555555555556}, 0.4: {'f1': 0.6, 'accuracy': 0.5789473684210527, 'precision': 0.6, 'recall': 0.6, 'mcc': 0.15555555555555556}, 0.5: {'f1': 0.6, 'accuracy': 0.5789473684210527, 'precision': 0.6, 'recall': 0.6, 'mcc': 0.15555555555555556}, 0.6: {'f1': 0.631578947368421, 'accuracy': 0.631578947368421, 'precision': 0.6666666666666666, 'recall': 0.6, 'mcc': 0.26666666666666666}, 0.7000000000000001: {'f1': 0.631578947368421, 'accuracy': 0.631578947368421, 'precision': 0.6666666666666666, 'recall': 0.6, 'mcc': 0.26666666666666666}, 0.8: {'f1': 0.631578947368421, 'accuracy': 0.631578947368421, 'precision': 0.6666666666666666, 'recall': 0.6, 'mcc': 0.26666666666666666}, 0.9: {'f1': 0.631578947368421, 'accuracy': 0.631578947368421, 'precision': 0.6666666666666666, 'recall': 0.6, 'mcc': 0.26666666666666666}}, 2: {0.1: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.2: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.30000000000000004: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.4: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.5: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.6: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.7000000000000001: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.8: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}, 0.9: {'f1': 0.7058823529411765, 'accuracy': 0.7368421052631579, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.5060480768510598}}, 3: {0.1: {'f1': 0.45454545454545453, 'accuracy': 0.3684210526315789, 'precision': 0.38461538461538464, 'recall': 0.5555555555555556, 'mcc': -0.26257545381445874}, 0.2: {'f1': 0.45454545454545453, 'accuracy': 0.3684210526315789, 'precision': 0.38461538461538464, 'recall': 0.5555555555555556, 'mcc': -0.26257545381445874}, 0.30000000000000004: {'f1': 0.47619047619047616, 'accuracy': 0.42105263157894735, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': -0.14951420452417674}, 0.4: {'f1': 0.47619047619047616, 'accuracy': 0.42105263157894735, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': -0.14951420452417674}, 0.5: {'f1': 0.47619047619047616, 'accuracy': 0.42105263157894735, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': -0.14951420452417674}, 0.6: {'f1': 0.47619047619047616, 'accuracy': 0.42105263157894735, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': -0.14951420452417674}, 0.7000000000000001: {'f1': 0.47619047619047616, 'accuracy': 0.42105263157894735, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': -0.14951420452417674}, 0.8: {'f1': 0.4, 'accuracy': 0.3684210526315789, 'precision': 0.36363636363636365, 'recall': 0.4444444444444444, 'mcc': -0.2584432806109095}, 0.9: {'f1': 0.4, 'accuracy': 0.3684210526315789, 'precision': 0.36363636363636365, 'recall': 0.4444444444444444, 'mcc': -0.2584432806109095}}, 4: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.5: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.6: {'f1': 0.5882352941176471, 'accuracy': 0.631578947368421, 'precision': 0.625, 'recall': 0.5555555555555556, 'mcc': 0.2584432806109095}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.5789473684210527, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.14951420452417674}, 0.8: {'f1': 0.4, 'accuracy': 0.5263157894736842, 'precision': 0.5, 'recall': 0.3333333333333333, 'mcc': 0.03580574370197164}, 0.9: {'f1': 0.4, 'accuracy': 0.5263157894736842, 'precision': 0.5, 'recall': 0.3333333333333333, 'mcc': 0.03580574370197164}}, 5: {0.1: {'f1': 0.5714285714285714, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.6666666666666666, 'mcc': 0.0}, 0.2: {'f1': 0.5714285714285714, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.6666666666666666, 'mcc': 0.0}, 0.30000000000000004: {'f1': 0.5714285714285714, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.6666666666666666, 'mcc': 0.0}, 0.4: {'f1': 0.5263157894736842, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.0}, 0.5: {'f1': 0.5263157894736842, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.0}, 0.6: {'f1': 0.5263157894736842, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.0}, 0.7000000000000001: {'f1': 0.5263157894736842, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.0}, 0.8: {'f1': 0.5263157894736842, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.0}, 0.9: {'f1': 0.5263157894736842, 'accuracy': 0.5, 'precision': 0.5, 'recall': 0.5555555555555556, 'mcc': 0.0}}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.7428571428571429, 'accuracy': 0.71875, 'precision': 0.6842105263157895, 'recall': 0.8125, 'mcc': 0.44539933408304444}, 0.2: {'f1': 0.7428571428571429, 'accuracy': 0.71875, 'precision': 0.6842105263157895, 'recall': 0.8125, 'mcc': 0.44539933408304444}, 0.30000000000000004: {'f1': 0.7428571428571429, 'accuracy': 0.71875, 'precision': 0.6842105263157895, 'recall': 0.8125, 'mcc': 0.44539933408304444}, 0.4: {'f1': 0.7096774193548387, 'accuracy': 0.71875, 'precision': 0.7333333333333333, 'recall': 0.6875, 'mcc': 0.4383570037596047}, 0.5: {'f1': 0.7096774193548387, 'accuracy': 0.71875, 'precision': 0.7333333333333333, 'recall': 0.6875, 'mcc': 0.4383570037596047}, 0.6: {'f1': 0.7096774193548387, 'accuracy': 0.71875, 'precision': 0.7333333333333333, 'recall': 0.6875, 'mcc': 0.4383570037596047}, 0.7000000000000001: {'f1': 0.6206896551724138, 'accuracy': 0.65625, 'precision': 0.6923076923076923, 'recall': 0.5625, 'mcc': 0.31814238148788887}, 0.8: {'f1': 0.6206896551724138, 'accuracy': 0.65625, 'precision': 0.6923076923076923, 'recall': 0.5625, 'mcc': 0.31814238148788887}, 0.9: {'f1': 0.6206896551724138, 'accuracy': 0.65625, 'precision': 0.6923076923076923, 'recall': 0.5625, 'mcc': 0.31814238148788887}}, 2: {0.1: {'f1': 0.6, 'accuracy': 0.6129032258064516, 'precision': 0.6428571428571429, 'recall': 0.5625, 'mcc': 0.23012753740782382}, 0.2: {'f1': 0.6, 'accuracy': 0.6129032258064516, 'precision': 0.6428571428571429, 'recall': 0.5625, 'mcc': 0.23012753740782382}, 0.30000000000000004: {'f1': 0.6, 'accuracy': 0.6129032258064516, 'precision': 0.6428571428571429, 'recall': 0.5625, 'mcc': 0.23012753740782382}, 0.4: {'f1': 0.6, 'accuracy': 0.6129032258064516, 'precision': 0.6428571428571429, 'recall': 0.5625, 'mcc': 0.23012753740782382}, 0.5: {'f1': 0.6, 'accuracy': 0.6129032258064516, 'precision': 0.6428571428571429, 'recall': 0.5625, 'mcc': 0.23012753740782382}, 0.6: {'f1': 0.46153846153846156, 'accuracy': 0.5483870967741935, 'precision': 0.6, 'recall': 0.375, 'mcc': 0.11581320482871722}, 0.7000000000000001: {'f1': 0.46153846153846156, 'accuracy': 0.5483870967741935, 'precision': 0.6, 'recall': 0.375, 'mcc': 0.11581320482871722}, 0.8: {'f1': 0.46153846153846156, 'accuracy': 0.5483870967741935, 'precision': 0.6, 'recall': 0.375, 'mcc': 0.11581320482871722}, 0.9: {'f1': 0.46153846153846156, 'accuracy': 0.5483870967741935, 'precision': 0.6, 'recall': 0.375, 'mcc': 0.11581320482871722}}, 3: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.6451612903225806, 'precision': 0.6111111111111112, 'recall': 0.7333333333333333, 'mcc': 0.2996020627622514}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.6451612903225806, 'precision': 0.6111111111111112, 'recall': 0.7333333333333333, 'mcc': 0.2996020627622514}, 0.30000000000000004: {'f1': 0.5333333333333333, 'accuracy': 0.5483870967741935, 'precision': 0.5333333333333333, 'recall': 0.5333333333333333, 'mcc': 0.09583333333333334}, 0.4: {'f1': 0.5333333333333333, 'accuracy': 0.5483870967741935, 'precision': 0.5333333333333333, 'recall': 0.5333333333333333, 'mcc': 0.09583333333333334}, 0.5: {'f1': 0.5333333333333333, 'accuracy': 0.5483870967741935, 'precision': 0.5333333333333333, 'recall': 0.5333333333333333, 'mcc': 0.09583333333333334}, 0.6: {'f1': 0.5517241379310345, 'accuracy': 0.5806451612903226, 'precision': 0.5714285714285714, 'recall': 0.5333333333333333, 'mcc': 0.15899720766358738}, 0.7000000000000001: {'f1': 0.5517241379310345, 'accuracy': 0.5806451612903226, 'precision': 0.5714285714285714, 'recall': 0.5333333333333333, 'mcc': 0.15899720766358738}, 0.8: {'f1': 0.5517241379310345, 'accuracy': 0.5806451612903226, 'precision': 0.5714285714285714, 'recall': 0.5333333333333333, 'mcc': 0.15899720766358738}, 0.9: {'f1': 0.5517241379310345, 'accuracy': 0.5806451612903226, 'precision': 0.5714285714285714, 'recall': 0.5333333333333333, 'mcc': 0.15899720766358738}}}\n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: larger-params-dt-5-folds-Threshold-allKfold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: larger-params-dt-3-folds-Threshold-allKfold.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.35294117647058826, 'accuracy': 0.819672131147541, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.2573637971418306}, 0.2: {'f1': 0.35294117647058826, 'accuracy': 0.819672131147541, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.2573637971418306}, 0.30000000000000004: {'f1': 0.35294117647058826, 'accuracy': 0.819672131147541, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.2573637971418306}, 0.4: {'f1': 0.35294117647058826, 'accuracy': 0.819672131147541, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.2573637971418306}, 0.5: {'f1': 0.35294117647058826, 'accuracy': 0.819672131147541, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.2573637971418306}, 0.6: {'f1': 0.375, 'accuracy': 0.8360655737704918, 'precision': 0.5, 'recall': 0.3, 'mcc': 0.29982169389212354}, 0.7000000000000001: {'f1': 0.2857142857142857, 'accuracy': 0.8360655737704918, 'precision': 0.5, 'recall': 0.2, 'mcc': 0.24047024221824384}, 0.8: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}, 0.9: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}}, 2: {0.1: {'f1': 0.45454545454545453, 'accuracy': 0.8, 'precision': 0.4166666666666667, 'recall': 0.5, 'mcc': 0.33541019662496846}, 0.2: {'f1': 0.45454545454545453, 'accuracy': 0.8, 'precision': 0.4166666666666667, 'recall': 0.5, 'mcc': 0.33541019662496846}, 0.30000000000000004: {'f1': 0.3, 'accuracy': 0.7666666666666667, 'precision': 0.3, 'recall': 0.3, 'mcc': 0.16}, 0.4: {'f1': 0.3, 'accuracy': 0.7666666666666667, 'precision': 0.3, 'recall': 0.3, 'mcc': 0.16}, 0.5: {'f1': 0.3, 'accuracy': 0.7666666666666667, 'precision': 0.3, 'recall': 0.3, 'mcc': 0.16}, 0.6: {'f1': 0.35294117647058826, 'accuracy': 0.8166666666666667, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.25539990311691463}, 0.7000000000000001: {'f1': 0.35294117647058826, 'accuracy': 0.8166666666666667, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.25539990311691463}, 0.8: {'f1': 0.35294117647058826, 'accuracy': 0.8166666666666667, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.25539990311691463}, 0.9: {'f1': 0.35294117647058826, 'accuracy': 0.8166666666666667, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.25539990311691463}}, 3: {0.1: {'f1': 0.23529411764705882, 'accuracy': 0.7833333333333333, 'precision': 0.25, 'recall': 0.2222222222222222, 'mcc': 0.10984700727621793}, 0.2: {'f1': 0.23529411764705882, 'accuracy': 0.7833333333333333, 'precision': 0.25, 'recall': 0.2222222222222222, 'mcc': 0.10984700727621793}, 0.30000000000000004: {'f1': 0.23529411764705882, 'accuracy': 0.7833333333333333, 'precision': 0.25, 'recall': 0.2222222222222222, 'mcc': 0.10984700727621793}, 0.4: {'f1': 0.23529411764705882, 'accuracy': 0.7833333333333333, 'precision': 0.25, 'recall': 0.2222222222222222, 'mcc': 0.10984700727621793}, 0.5: {'f1': 0.23529411764705882, 'accuracy': 0.7833333333333333, 'precision': 0.25, 'recall': 0.2222222222222222, 'mcc': 0.10984700727621793}, 0.6: {'f1': 0.23529411764705882, 'accuracy': 0.7833333333333333, 'precision': 0.25, 'recall': 0.2222222222222222, 'mcc': 0.10984700727621793}, 0.7000000000000001: {'f1': 0.23529411764705882, 'accuracy': 0.7833333333333333, 'precision': 0.25, 'recall': 0.2222222222222222, 'mcc': 0.10984700727621793}, 0.8: {'f1': 0.23529411764705882, 'accuracy': 0.7833333333333333, 'precision': 0.25, 'recall': 0.2222222222222222, 'mcc': 0.10984700727621793}, 0.9: {'f1': 0.23529411764705882, 'accuracy': 0.7833333333333333, 'precision': 0.25, 'recall': 0.2222222222222222, 'mcc': 0.10984700727621793}}, 4: {0.1: {'f1': 0.47619047619047616, 'accuracy': 0.8166666666666667, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': 0.37340802240746923}, 0.2: {'f1': 0.47619047619047616, 'accuracy': 0.8166666666666667, 'precision': 0.4166666666666667, 'recall': 0.5555555555555556, 'mcc': 0.37340802240746923}, 0.30000000000000004: {'f1': 0.5, 'accuracy': 0.8333333333333334, 'precision': 0.45454545454545453, 'recall': 0.5555555555555556, 'mcc': 0.4041060310241455}, 0.4: {'f1': 0.5, 'accuracy': 0.8333333333333334, 'precision': 0.45454545454545453, 'recall': 0.5555555555555556, 'mcc': 0.4041060310241455}, 0.5: {'f1': 0.5, 'accuracy': 0.8333333333333334, 'precision': 0.45454545454545453, 'recall': 0.5555555555555556, 'mcc': 0.4041060310241455}, 0.6: {'f1': 0.5, 'accuracy': 0.8333333333333334, 'precision': 0.45454545454545453, 'recall': 0.5555555555555556, 'mcc': 0.4041060310241455}, 0.7000000000000001: {'f1': 0.5555555555555556, 'accuracy': 0.8666666666666667, 'precision': 0.5555555555555556, 'recall': 0.5555555555555556, 'mcc': 0.477124183006536}, 0.8: {'f1': 0.26666666666666666, 'accuracy': 0.8166666666666667, 'precision': 0.3333333333333333, 'recall': 0.2222222222222222, 'mcc': 0.17114534360342343}, 0.9: {'f1': 0.26666666666666666, 'accuracy': 0.8166666666666667, 'precision': 0.3333333333333333, 'recall': 0.2222222222222222, 'mcc': 0.17114534360342343}}, 5: {0.1: {'f1': 0.631578947368421, 'accuracy': 0.8833333333333333, 'precision': 0.6, 'recall': 0.6666666666666666, 'mcc': 0.5636018619766345}, 0.2: {'f1': 0.631578947368421, 'accuracy': 0.8833333333333333, 'precision': 0.6, 'recall': 0.6666666666666666, 'mcc': 0.5636018619766345}, 0.30000000000000004: {'f1': 0.631578947368421, 'accuracy': 0.8833333333333333, 'precision': 0.6, 'recall': 0.6666666666666666, 'mcc': 0.5636018619766345}, 0.4: {'f1': 0.631578947368421, 'accuracy': 0.8833333333333333, 'precision': 0.6, 'recall': 0.6666666666666666, 'mcc': 0.5636018619766345}, 0.5: {'f1': 0.631578947368421, 'accuracy': 0.8833333333333333, 'precision': 0.6, 'recall': 0.6666666666666666, 'mcc': 0.5636018619766345}, 0.6: {'f1': 0.5555555555555556, 'accuracy': 0.8666666666666667, 'precision': 0.5555555555555556, 'recall': 0.5555555555555556, 'mcc': 0.477124183006536}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.8: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.9: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.375, 'accuracy': 0.801980198019802, 'precision': 0.375, 'recall': 0.375, 'mcc': 0.25735294117647056}, 0.2: {'f1': 0.375, 'accuracy': 0.801980198019802, 'precision': 0.375, 'recall': 0.375, 'mcc': 0.25735294117647056}, 0.30000000000000004: {'f1': 0.375, 'accuracy': 0.801980198019802, 'precision': 0.375, 'recall': 0.375, 'mcc': 0.25735294117647056}, 0.4: {'f1': 0.375, 'accuracy': 0.801980198019802, 'precision': 0.375, 'recall': 0.375, 'mcc': 0.25735294117647056}, 0.5: {'f1': 0.375, 'accuracy': 0.801980198019802, 'precision': 0.375, 'recall': 0.375, 'mcc': 0.25735294117647056}, 0.6: {'f1': 0.375, 'accuracy': 0.801980198019802, 'precision': 0.375, 'recall': 0.375, 'mcc': 0.25735294117647056}, 0.7000000000000001: {'f1': 0.375, 'accuracy': 0.801980198019802, 'precision': 0.375, 'recall': 0.375, 'mcc': 0.25735294117647056}, 0.8: {'f1': 0.375, 'accuracy': 0.801980198019802, 'precision': 0.375, 'recall': 0.375, 'mcc': 0.25735294117647056}, 0.9: {'f1': 0.375, 'accuracy': 0.801980198019802, 'precision': 0.375, 'recall': 0.375, 'mcc': 0.25735294117647056}}, 2: {0.1: {'f1': 0.5142857142857142, 'accuracy': 0.83, 'precision': 0.47368421052631576, 'recall': 0.5625, 'mcc': 0.41440722207745595}, 0.2: {'f1': 0.5142857142857142, 'accuracy': 0.83, 'precision': 0.47368421052631576, 'recall': 0.5625, 'mcc': 0.41440722207745595}, 0.30000000000000004: {'f1': 0.5142857142857142, 'accuracy': 0.83, 'precision': 0.47368421052631576, 'recall': 0.5625, 'mcc': 0.41440722207745595}, 0.4: {'f1': 0.5142857142857142, 'accuracy': 0.83, 'precision': 0.47368421052631576, 'recall': 0.5625, 'mcc': 0.41440722207745595}, 0.5: {'f1': 0.5142857142857142, 'accuracy': 0.83, 'precision': 0.47368421052631576, 'recall': 0.5625, 'mcc': 0.41440722207745595}, 0.6: {'f1': 0.5, 'accuracy': 0.84, 'precision': 0.5, 'recall': 0.5, 'mcc': 0.40476190476190477}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.84, 'precision': 0.5, 'recall': 0.5, 'mcc': 0.40476190476190477}, 0.8: {'f1': 0.5, 'accuracy': 0.84, 'precision': 0.5, 'recall': 0.5, 'mcc': 0.40476190476190477}, 0.9: {'f1': 0.5, 'accuracy': 0.84, 'precision': 0.5, 'recall': 0.5, 'mcc': 0.40476190476190477}}, 3: {0.1: {'f1': 0.38461538461538464, 'accuracy': 0.84, 'precision': 0.45454545454545453, 'recall': 0.3333333333333333, 'mcc': 0.299846075328365}, 0.2: {'f1': 0.38461538461538464, 'accuracy': 0.84, 'precision': 0.45454545454545453, 'recall': 0.3333333333333333, 'mcc': 0.299846075328365}, 0.30000000000000004: {'f1': 0.38461538461538464, 'accuracy': 0.84, 'precision': 0.45454545454545453, 'recall': 0.3333333333333333, 'mcc': 0.299846075328365}, 0.4: {'f1': 0.38461538461538464, 'accuracy': 0.84, 'precision': 0.45454545454545453, 'recall': 0.3333333333333333, 'mcc': 0.299846075328365}, 0.5: {'f1': 0.38461538461538464, 'accuracy': 0.84, 'precision': 0.45454545454545453, 'recall': 0.3333333333333333, 'mcc': 0.299846075328365}, 0.6: {'f1': 0.38461538461538464, 'accuracy': 0.84, 'precision': 0.45454545454545453, 'recall': 0.3333333333333333, 'mcc': 0.299846075328365}, 0.7000000000000001: {'f1': 0.4, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.3333333333333333, 'mcc': 0.32673201960653564}, 0.8: {'f1': 0.4, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.3333333333333333, 'mcc': 0.32673201960653564}, 0.9: {'f1': 0.4, 'accuracy': 0.85, 'precision': 0.5, 'recall': 0.3333333333333333, 'mcc': 0.32673201960653564}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define Decision Tree model with given parameters\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=params.get('criterion', 'entropy'),\n",
    "        max_depth=params.get('max_depth', None),\n",
    "        min_samples_split=params.get('min_samples_split', 2),\n",
    "        min_samples_leaf=params.get('min_samples_leaf', 1),\n",
    "        max_features=params.get('max_features', None),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "       # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_fold = {fold+1: {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                                 for threshold in thresholds}\n",
    "                        for fold in range(n_splits)}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold for this fold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Store metrics for the current threshold for this fold\n",
    "            metrics_per_fold[fold+1][threshold]['f1'] = f1\n",
    "            metrics_per_fold[fold+1][threshold]['accuracy'] = accuracy\n",
    "            metrics_per_fold[fold+1][threshold]['precision'] = precision\n",
    "            metrics_per_fold[fold+1][threshold]['recall'] = recall\n",
    "            metrics_per_fold[fold+1][threshold]['mcc'] = mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Save the results for each threshold and fold\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold-allKfold.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"fold,threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each fold and each threshold\n",
    "        for fold in range(1, successFold + 1):\n",
    "            for threshold in thresholds:\n",
    "                fo.write(f\"{fold},{threshold},{metrics_per_fold[fold][threshold]['accuracy']},{metrics_per_fold[fold][threshold]['precision']},\"\n",
    "                         f\"{metrics_per_fold[fold][threshold]['recall']},{metrics_per_fold[fold][threshold]['f1']},{metrics_per_fold[fold][threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_fold\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    params = {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"max_depth\": 300,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\" : 'log2'\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124ba5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
