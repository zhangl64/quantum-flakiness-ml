{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e03351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: equal-params-dt-5-folds-Threshold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: equal-params-dt-3-folds-Threshold.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.6611732229123534, 'accuracy': 0.6163742690058479, 'precision': 0.6089466089466089, 'recall': 0.7422222222222222, 'mcc': 0.24063172927077958}, 0.2: {'f1': 0.6611732229123534, 'accuracy': 0.6163742690058479, 'precision': 0.6089466089466089, 'recall': 0.7422222222222222, 'mcc': 0.24063172927077958}, 0.30000000000000004: {'f1': 0.6611732229123534, 'accuracy': 0.6163742690058479, 'precision': 0.6089466089466089, 'recall': 0.7422222222222222, 'mcc': 0.24063172927077958}, 0.4: {'f1': 0.6711111111111111, 'accuracy': 0.6374269005847953, 'precision': 0.6232323232323231, 'recall': 0.7422222222222222, 'mcc': 0.2846701982983649}, 0.5: {'f1': 0.6711111111111111, 'accuracy': 0.6374269005847953, 'precision': 0.6232323232323231, 'recall': 0.7422222222222222, 'mcc': 0.2846701982983649}, 0.6: {'f1': 0.6650505050505051, 'accuracy': 0.6374269005847953, 'precision': 0.6242579642579642, 'recall': 0.72, 'mcc': 0.27966290551620937}, 0.7000000000000001: {'f1': 0.6436125965537729, 'accuracy': 0.6269005847953215, 'precision': 0.6281468531468531, 'recall': 0.6777777777777778, 'mcc': 0.2610942127175587}, 0.8: {'f1': 0.6436125965537729, 'accuracy': 0.6269005847953215, 'precision': 0.6281468531468531, 'recall': 0.6777777777777778, 'mcc': 0.2610942127175587}, 0.9: {'f1': 0.6436125965537729, 'accuracy': 0.6269005847953215, 'precision': 0.6281468531468531, 'recall': 0.6777777777777778, 'mcc': 0.2610942127175587}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.6840686274509804, 'accuracy': 0.680779569892473, 'precision': 0.6715225563909774, 'recall': 0.7055555555555556, 'mcc': 0.3698556312832304}, 0.2: {'f1': 0.6840686274509804, 'accuracy': 0.680779569892473, 'precision': 0.6715225563909774, 'recall': 0.7055555555555556, 'mcc': 0.3698556312832304}, 0.30000000000000004: {'f1': 0.6840686274509804, 'accuracy': 0.680779569892473, 'precision': 0.6715225563909774, 'recall': 0.7055555555555556, 'mcc': 0.3698556312832304}, 0.4: {'f1': 0.6617985125084517, 'accuracy': 0.6703629032258064, 'precision': 0.6731251204935416, 'recall': 0.6638888888888889, 'mcc': 0.3509030917791934}, 0.5: {'f1': 0.6617985125084517, 'accuracy': 0.6703629032258064, 'precision': 0.6731251204935416, 'recall': 0.6638888888888889, 'mcc': 0.3509030917791934}, 0.6: {'f1': 0.6567099567099567, 'accuracy': 0.67002688172043, 'precision': 0.6865079365079364, 'recall': 0.6416666666666667, 'mcc': 0.3492800343463746}, 0.7000000000000001: {'f1': 0.6314604935294591, 'accuracy': 0.6592741935483871, 'precision': 0.6940170940170941, 'recall': 0.6, 'mcc': 0.33457468100081594}, 0.8: {'f1': 0.6314604935294591, 'accuracy': 0.6592741935483871, 'precision': 0.6940170940170941, 'recall': 0.6, 'mcc': 0.33457468100081594}, 0.9: {'f1': 0.6314604935294591, 'accuracy': 0.6592741935483871, 'precision': 0.6940170940170941, 'recall': 0.6, 'mcc': 0.33457468100081594}}\n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: larger-params-dt-5-folds-Threshold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: larger-params-dt-3-folds-Threshold.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.4636819613135403, 'accuracy': 0.823879781420765, 'precision': 0.45883838383838393, 'recall': 0.49111111111111116, 'mcc': 0.3671760353873348}, 0.2: {'f1': 0.4636819613135403, 'accuracy': 0.823879781420765, 'precision': 0.45883838383838393, 'recall': 0.49111111111111116, 'mcc': 0.3671760353873348}, 0.30000000000000004: {'f1': 0.47257085020242917, 'accuracy': 0.8305464480874317, 'precision': 0.475, 'recall': 0.49111111111111116, 'mcc': 0.379761608129611}, 0.4: {'f1': 0.4758697838109603, 'accuracy': 0.8406010928961749, 'precision': 0.5089682539682541, 'recall': 0.47111111111111115, 'mcc': 0.39270846194837994}, 0.5: {'f1': 0.4758697838109603, 'accuracy': 0.8406010928961749, 'precision': 0.5089682539682541, 'recall': 0.47111111111111115, 'mcc': 0.39270846194837994}, 0.6: {'f1': 0.4242763772175537, 'accuracy': 0.8306010928961749, 'precision': 0.47777777777777786, 'recall': 0.4066666666666666, 'mcc': 0.33806002013962416}, 0.7000000000000001: {'f1': 0.38676721970839617, 'accuracy': 0.8239344262295083, 'precision': 0.44825396825396824, 'recall': 0.36444444444444446, 'mcc': 0.29806323466652757}, 0.8: {'f1': 0.40010055304172953, 'accuracy': 0.8372677595628415, 'precision': 0.47111111111111115, 'recall': 0.36444444444444446, 'mcc': 0.3188178658240155}, 0.9: {'f1': 0.40010055304172953, 'accuracy': 0.8372677595628415, 'precision': 0.47111111111111115, 'recall': 0.36444444444444446, 'mcc': 0.3188178658240155}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {0.1: {'f1': 0.5378151260504201, 'accuracy': 0.8405940594059406, 'precision': 0.4902534113060429, 'recall': 0.5972222222222222, 'mcc': 0.4462799412741485}, 0.2: {'f1': 0.5378151260504201, 'accuracy': 0.8405940594059406, 'precision': 0.4902534113060429, 'recall': 0.5972222222222222, 'mcc': 0.4462799412741485}, 0.30000000000000004: {'f1': 0.5378151260504201, 'accuracy': 0.8405940594059406, 'precision': 0.4902534113060429, 'recall': 0.5972222222222222, 'mcc': 0.4462799412741485}, 0.4: {'f1': 0.5383297258297258, 'accuracy': 0.8472607260726073, 'precision': 0.5085784313725491, 'recall': 0.5763888888888888, 'mcc': 0.45012189277866493}, 0.5: {'f1': 0.5383297258297258, 'accuracy': 0.8472607260726073, 'precision': 0.5085784313725491, 'recall': 0.5763888888888888, 'mcc': 0.45012189277866493}, 0.6: {'f1': 0.42484567901234566, 'accuracy': 0.8305280528052804, 'precision': 0.45543672014260245, 'recall': 0.4055555555555556, 'mcc': 0.32983672761800203}, 0.7000000000000001: {'f1': 0.4295499800876145, 'accuracy': 0.8338613861386138, 'precision': 0.46401515151515155, 'recall': 0.4055555555555556, 'mcc': 0.336379329761126}, 0.8: {'f1': 0.41685156738920176, 'accuracy': 0.8338613861386138, 'precision': 0.46401515151515155, 'recall': 0.38472222222222224, 'mcc': 0.3257912787014097}, 0.9: {'f1': 0.41685156738920176, 'accuracy': 0.8338613861386138, 'precision': 0.46401515151515155, 'recall': 0.38472222222222224, 'mcc': 0.3257912787014097}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define Decision Tree model with given parameters\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=params.get('criterion', 'entropy'),\n",
    "        max_depth=params.get('max_depth', None),\n",
    "        min_samples_split=params.get('min_samples_split', 2),\n",
    "        min_samples_leaf=params.get('min_samples_leaf', 1),\n",
    "        max_features=params.get('max_features', None),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize metrics storage for each threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_threshold = {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                             for threshold in thresholds}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, average='binary', zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='binary', zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, average='binary', zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Accumulate metrics for the current threshold\n",
    "            metrics_per_threshold[threshold]['f1'] += f1\n",
    "            metrics_per_threshold[threshold]['accuracy'] += accuracy\n",
    "            metrics_per_threshold[threshold]['precision'] += precision\n",
    "            metrics_per_threshold[threshold]['recall'] += recall\n",
    "            metrics_per_threshold[threshold]['mcc'] += mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Average metrics over all folds\n",
    "    for threshold in thresholds:\n",
    "        metrics_per_threshold[threshold]['f1'] /= successFold\n",
    "        metrics_per_threshold[threshold]['accuracy'] /= successFold\n",
    "        metrics_per_threshold[threshold]['precision'] /= successFold\n",
    "        metrics_per_threshold[threshold]['recall'] /= successFold\n",
    "        metrics_per_threshold[threshold]['mcc'] /= successFold\n",
    "\n",
    "    # Save the results for each threshold\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each threshold\n",
    "        for threshold in thresholds:\n",
    "            fo.write(f\"{threshold},{metrics_per_threshold[threshold]['accuracy']},{metrics_per_threshold[threshold]['precision']},\"\n",
    "                     f\"{metrics_per_threshold[threshold]['recall']},{metrics_per_threshold[threshold]['f1']},{metrics_per_threshold[threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_threshold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    params = {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"max_depth\": 300,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\": 'log2'\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6a1c0",
   "metadata": {},
   "source": [
    "Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c255f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: equal-params-dt-5-folds-Threshold-allKfold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: equal-params-dt-3-folds-Threshold-allKfold.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.5555555555555556, 'accuracy': 0.5789473684210527, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.1685499656158105}, 0.2: {'f1': 0.5555555555555556, 'accuracy': 0.5789473684210527, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.1685499656158105}, 0.30000000000000004: {'f1': 0.5555555555555556, 'accuracy': 0.5789473684210527, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.1685499656158105}, 0.4: {'f1': 0.5555555555555556, 'accuracy': 0.5789473684210527, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.1685499656158105}, 0.5: {'f1': 0.5555555555555556, 'accuracy': 0.5789473684210527, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.1685499656158105}, 0.6: {'f1': 0.5555555555555556, 'accuracy': 0.5789473684210527, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.1685499656158105}, 0.7000000000000001: {'f1': 0.5555555555555556, 'accuracy': 0.5789473684210527, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.1685499656158105}, 0.8: {'f1': 0.5555555555555556, 'accuracy': 0.5789473684210527, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.1685499656158105}, 0.9: {'f1': 0.5555555555555556, 'accuracy': 0.5789473684210527, 'precision': 0.625, 'recall': 0.5, 'mcc': 0.1685499656158105}}, 2: {0.1: {'f1': 0.5882352941176471, 'accuracy': 0.631578947368421, 'precision': 0.7142857142857143, 'recall': 0.5, 'mcc': 0.2875273163926476}, 0.2: {'f1': 0.5882352941176471, 'accuracy': 0.631578947368421, 'precision': 0.7142857142857143, 'recall': 0.5, 'mcc': 0.2875273163926476}, 0.30000000000000004: {'f1': 0.5882352941176471, 'accuracy': 0.631578947368421, 'precision': 0.7142857142857143, 'recall': 0.5, 'mcc': 0.2875273163926476}, 0.4: {'f1': 0.5882352941176471, 'accuracy': 0.631578947368421, 'precision': 0.7142857142857143, 'recall': 0.5, 'mcc': 0.2875273163926476}, 0.5: {'f1': 0.5882352941176471, 'accuracy': 0.631578947368421, 'precision': 0.7142857142857143, 'recall': 0.5, 'mcc': 0.2875273163926476}, 0.6: {'f1': 0.5882352941176471, 'accuracy': 0.631578947368421, 'precision': 0.7142857142857143, 'recall': 0.5, 'mcc': 0.2875273163926476}, 0.7000000000000001: {'f1': 0.625, 'accuracy': 0.6842105263157895, 'precision': 0.8333333333333334, 'recall': 0.5, 'mcc': 0.41773367652300253}, 0.8: {'f1': 0.625, 'accuracy': 0.6842105263157895, 'precision': 0.8333333333333334, 'recall': 0.5, 'mcc': 0.41773367652300253}, 0.9: {'f1': 0.625, 'accuracy': 0.6842105263157895, 'precision': 0.8333333333333334, 'recall': 0.5, 'mcc': 0.41773367652300253}}, 3: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.5: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.6: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.7000000000000001: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.8: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}, 0.9: {'f1': 0.6666666666666666, 'accuracy': 0.6842105263157895, 'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'mcc': 0.36666666666666664}}, 4: {0.1: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}, 0.2: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}, 0.30000000000000004: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}, 0.4: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}, 0.5: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}, 0.6: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}, 0.7000000000000001: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}, 0.8: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}, 0.9: {'f1': 0.9, 'accuracy': 0.8947368421052632, 'precision': 0.8181818181818182, 'recall': 1.0, 'mcc': 0.8090398349558905}}, 5: {0.1: {'f1': 0.8235294117647058, 'accuracy': 0.8333333333333334, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6708203932499369}, 0.2: {'f1': 0.8235294117647058, 'accuracy': 0.8333333333333334, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6708203932499369}, 0.30000000000000004: {'f1': 0.8235294117647058, 'accuracy': 0.8333333333333334, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6708203932499369}, 0.4: {'f1': 0.8235294117647058, 'accuracy': 0.8333333333333334, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6708203932499369}, 0.5: {'f1': 0.8235294117647058, 'accuracy': 0.8333333333333334, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6708203932499369}, 0.6: {'f1': 0.8235294117647058, 'accuracy': 0.8333333333333334, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6708203932499369}, 0.7000000000000001: {'f1': 0.8235294117647058, 'accuracy': 0.8333333333333334, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6708203932499369}, 0.8: {'f1': 0.8235294117647058, 'accuracy': 0.8333333333333334, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6708203932499369}, 0.9: {'f1': 0.8235294117647058, 'accuracy': 0.8333333333333334, 'precision': 0.875, 'recall': 0.7777777777777778, 'mcc': 0.6708203932499369}}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.6153846153846154, 'accuracy': 0.53125, 'precision': 0.5217391304347826, 'recall': 0.75, 'mcc': 0.06950480468569159}, 0.2: {'f1': 0.6153846153846154, 'accuracy': 0.53125, 'precision': 0.5217391304347826, 'recall': 0.75, 'mcc': 0.06950480468569159}, 0.30000000000000004: {'f1': 0.631578947368421, 'accuracy': 0.5625, 'precision': 0.5454545454545454, 'recall': 0.75, 'mcc': 0.13483997249264842}, 0.4: {'f1': 0.631578947368421, 'accuracy': 0.5625, 'precision': 0.5454545454545454, 'recall': 0.75, 'mcc': 0.13483997249264842}, 0.5: {'f1': 0.631578947368421, 'accuracy': 0.5625, 'precision': 0.5454545454545454, 'recall': 0.75, 'mcc': 0.13483997249264842}, 0.6: {'f1': 0.6470588235294118, 'accuracy': 0.625, 'precision': 0.6111111111111112, 'recall': 0.6875, 'mcc': 0.2519763153394848}, 0.7000000000000001: {'f1': 0.6470588235294118, 'accuracy': 0.625, 'precision': 0.6111111111111112, 'recall': 0.6875, 'mcc': 0.2519763153394848}, 0.8: {'f1': 0.6470588235294118, 'accuracy': 0.625, 'precision': 0.6111111111111112, 'recall': 0.6875, 'mcc': 0.2519763153394848}, 0.9: {'f1': 0.6470588235294118, 'accuracy': 0.625, 'precision': 0.6111111111111112, 'recall': 0.6875, 'mcc': 0.2519763153394848}}, 2: {0.1: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}, 0.2: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}, 0.30000000000000004: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}, 0.4: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}, 0.5: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}, 0.6: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}, 0.7000000000000001: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}, 0.8: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}, 0.9: {'f1': 0.7878787878787878, 'accuracy': 0.7741935483870968, 'precision': 0.7647058823529411, 'recall': 0.8125, 'mcc': 0.5481219527349985}}, 3: {0.1: {'f1': 0.7272727272727273, 'accuracy': 0.7096774193548387, 'precision': 0.6666666666666666, 'recall': 0.8, 'mcc': 0.4304142310105583}, 0.2: {'f1': 0.7272727272727273, 'accuracy': 0.7096774193548387, 'precision': 0.6666666666666666, 'recall': 0.8, 'mcc': 0.4304142310105583}, 0.30000000000000004: {'f1': 0.7272727272727273, 'accuracy': 0.7096774193548387, 'precision': 0.6666666666666666, 'recall': 0.8, 'mcc': 0.4304142310105583}, 0.4: {'f1': 0.7272727272727273, 'accuracy': 0.7096774193548387, 'precision': 0.6666666666666666, 'recall': 0.8, 'mcc': 0.4304142310105583}, 0.5: {'f1': 0.7272727272727273, 'accuracy': 0.7096774193548387, 'precision': 0.6666666666666666, 'recall': 0.8, 'mcc': 0.4304142310105583}, 0.6: {'f1': 0.6896551724137931, 'accuracy': 0.7096774193548387, 'precision': 0.7142857142857143, 'recall': 0.6666666666666666, 'mcc': 0.4184137043778615}, 0.7000000000000001: {'f1': 0.6896551724137931, 'accuracy': 0.7096774193548387, 'precision': 0.7142857142857143, 'recall': 0.6666666666666666, 'mcc': 0.4184137043778615}, 0.8: {'f1': 0.6896551724137931, 'accuracy': 0.7096774193548387, 'precision': 0.7142857142857143, 'recall': 0.6666666666666666, 'mcc': 0.4184137043778615}, 0.9: {'f1': 0.6896551724137931, 'accuracy': 0.7096774193548387, 'precision': 0.7142857142857143, 'recall': 0.6666666666666666, 'mcc': 0.4184137043778615}}}\n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 5 folds. Results saved to: larger-params-dt-5-folds-Threshold-allKfold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Decision Tree analysis completed for 3 folds. Results saved to: larger-params-dt-3-folds-Threshold-allKfold.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.3157894736842105, 'accuracy': 0.7868852459016393, 'precision': 0.3333333333333333, 'recall': 0.3, 'mcc': 0.19035966593076642}, 0.2: {'f1': 0.3157894736842105, 'accuracy': 0.7868852459016393, 'precision': 0.3333333333333333, 'recall': 0.3, 'mcc': 0.19035966593076642}, 0.30000000000000004: {'f1': 0.3157894736842105, 'accuracy': 0.7868852459016393, 'precision': 0.3333333333333333, 'recall': 0.3, 'mcc': 0.19035966593076642}, 0.4: {'f1': 0.3157894736842105, 'accuracy': 0.7868852459016393, 'precision': 0.3333333333333333, 'recall': 0.3, 'mcc': 0.19035966593076642}, 0.5: {'f1': 0.3157894736842105, 'accuracy': 0.7868852459016393, 'precision': 0.3333333333333333, 'recall': 0.3, 'mcc': 0.19035966593076642}, 0.6: {'f1': 0.3333333333333333, 'accuracy': 0.8032786885245902, 'precision': 0.375, 'recall': 0.3, 'mcc': 0.22149769358819713}, 0.7000000000000001: {'f1': 0.3333333333333333, 'accuracy': 0.8032786885245902, 'precision': 0.375, 'recall': 0.3, 'mcc': 0.22149769358819713}, 0.8: {'f1': 0.35294117647058826, 'accuracy': 0.819672131147541, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.2573637971418306}, 0.9: {'f1': 0.35294117647058826, 'accuracy': 0.819672131147541, 'precision': 0.42857142857142855, 'recall': 0.3, 'mcc': 0.2573637971418306}}, 2: {0.1: {'f1': 0.4, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.28}, 0.2: {'f1': 0.4, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.28}, 0.30000000000000004: {'f1': 0.4, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.28}, 0.4: {'f1': 0.4, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.28}, 0.5: {'f1': 0.4, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.28}, 0.6: {'f1': 0.4, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.28}, 0.7000000000000001: {'f1': 0.4, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.28}, 0.8: {'f1': 0.4, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.28}, 0.9: {'f1': 0.4, 'accuracy': 0.8, 'precision': 0.4, 'recall': 0.4, 'mcc': 0.28}}, 3: {0.1: {'f1': 0.19047619047619047, 'accuracy': 0.7166666666666667, 'precision': 0.16666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.023338001400466827}, 0.2: {'f1': 0.19047619047619047, 'accuracy': 0.7166666666666667, 'precision': 0.16666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.023338001400466827}, 0.30000000000000004: {'f1': 0.19047619047619047, 'accuracy': 0.7166666666666667, 'precision': 0.16666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.023338001400466827}, 0.4: {'f1': 0.19047619047619047, 'accuracy': 0.7166666666666667, 'precision': 0.16666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.023338001400466827}, 0.5: {'f1': 0.19047619047619047, 'accuracy': 0.7166666666666667, 'precision': 0.16666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.023338001400466827}, 0.6: {'f1': 0.19047619047619047, 'accuracy': 0.7166666666666667, 'precision': 0.16666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.023338001400466827}, 0.7000000000000001: {'f1': 0.25, 'accuracy': 0.8, 'precision': 0.2857142857142857, 'recall': 0.2222222222222222, 'mcc': 0.13812794737179585}, 0.8: {'f1': 0.25, 'accuracy': 0.8, 'precision': 0.2857142857142857, 'recall': 0.2222222222222222, 'mcc': 0.13812794737179585}, 0.9: {'f1': 0.25, 'accuracy': 0.8, 'precision': 0.2857142857142857, 'recall': 0.2222222222222222, 'mcc': 0.13812794737179585}}, 4: {0.1: {'f1': 0.7368421052631579, 'accuracy': 0.9166666666666666, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.6888467201936644}, 0.2: {'f1': 0.7368421052631579, 'accuracy': 0.9166666666666666, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.6888467201936644}, 0.30000000000000004: {'f1': 0.75, 'accuracy': 0.9333333333333333, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.7197193047267257}, 0.4: {'f1': 0.75, 'accuracy': 0.9333333333333333, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.7197193047267257}, 0.5: {'f1': 0.75, 'accuracy': 0.9333333333333333, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.7197193047267257}, 0.6: {'f1': 0.8, 'accuracy': 0.95, 'precision': 1.0, 'recall': 0.6666666666666666, 'mcc': 0.7934920476158722}, 0.7000000000000001: {'f1': 0.8, 'accuracy': 0.95, 'precision': 1.0, 'recall': 0.6666666666666666, 'mcc': 0.7934920476158722}, 0.8: {'f1': 0.8, 'accuracy': 0.95, 'precision': 1.0, 'recall': 0.6666666666666666, 'mcc': 0.7934920476158722}, 0.9: {'f1': 0.8, 'accuracy': 0.95, 'precision': 1.0, 'recall': 0.6666666666666666, 'mcc': 0.7934920476158722}}, 5: {0.1: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.2: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.30000000000000004: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.4: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.5: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.6: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.8: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}, 0.9: {'f1': 0.5, 'accuracy': 0.8666666666666667, 'precision': 0.5714285714285714, 'recall': 0.4444444444444444, 'mcc': 0.42892362604926076}}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.5142857142857142, 'accuracy': 0.8316831683168316, 'precision': 0.47368421052631576, 'recall': 0.5625, 'mcc': 0.41562550831902256}, 0.2: {'f1': 0.5142857142857142, 'accuracy': 0.8316831683168316, 'precision': 0.47368421052631576, 'recall': 0.5625, 'mcc': 0.41562550831902256}, 0.30000000000000004: {'f1': 0.5454545454545454, 'accuracy': 0.8514851485148515, 'precision': 0.5294117647058824, 'recall': 0.5625, 'mcc': 0.4570943724030997}, 0.4: {'f1': 0.5454545454545454, 'accuracy': 0.8514851485148515, 'precision': 0.5294117647058824, 'recall': 0.5625, 'mcc': 0.4570943724030997}, 0.5: {'f1': 0.5454545454545454, 'accuracy': 0.8514851485148515, 'precision': 0.5294117647058824, 'recall': 0.5625, 'mcc': 0.4570943724030997}, 0.6: {'f1': 0.5454545454545454, 'accuracy': 0.8514851485148515, 'precision': 0.5294117647058824, 'recall': 0.5625, 'mcc': 0.4570943724030997}, 0.7000000000000001: {'f1': 0.5454545454545454, 'accuracy': 0.8514851485148515, 'precision': 0.5294117647058824, 'recall': 0.5625, 'mcc': 0.4570943724030997}, 0.8: {'f1': 0.5454545454545454, 'accuracy': 0.8514851485148515, 'precision': 0.5294117647058824, 'recall': 0.5625, 'mcc': 0.4570943724030997}, 0.9: {'f1': 0.5454545454545454, 'accuracy': 0.8514851485148515, 'precision': 0.5294117647058824, 'recall': 0.5625, 'mcc': 0.4570943724030997}}, 2: {0.1: {'f1': 0.2857142857142857, 'accuracy': 0.8, 'precision': 0.3333333333333333, 'recall': 0.25, 'mcc': 0.17459497553883238}, 0.2: {'f1': 0.2857142857142857, 'accuracy': 0.8, 'precision': 0.3333333333333333, 'recall': 0.25, 'mcc': 0.17459497553883238}, 0.30000000000000004: {'f1': 0.2857142857142857, 'accuracy': 0.8, 'precision': 0.3333333333333333, 'recall': 0.25, 'mcc': 0.17459497553883238}, 0.4: {'f1': 0.32, 'accuracy': 0.83, 'precision': 0.4444444444444444, 'recall': 0.25, 'mcc': 0.24400480579822803}, 0.5: {'f1': 0.32, 'accuracy': 0.83, 'precision': 0.4444444444444444, 'recall': 0.25, 'mcc': 0.24400480579822803}, 0.6: {'f1': 0.3333333333333333, 'accuracy': 0.84, 'precision': 0.5, 'recall': 0.25, 'mcc': 0.27348301713730944}, 0.7000000000000001: {'f1': 0.2608695652173913, 'accuracy': 0.83, 'precision': 0.42857142857142855, 'recall': 0.1875, 'mcc': 0.20098688560139094}, 0.8: {'f1': 0.2608695652173913, 'accuracy': 0.83, 'precision': 0.42857142857142855, 'recall': 0.1875, 'mcc': 0.20098688560139094}, 0.9: {'f1': 0.2608695652173913, 'accuracy': 0.83, 'precision': 0.42857142857142855, 'recall': 0.1875, 'mcc': 0.20098688560139094}}, 3: {0.1: {'f1': 0.4444444444444444, 'accuracy': 0.8, 'precision': 0.38095238095238093, 'recall': 0.5333333333333333, 'mcc': 0.3334751320564686}, 0.2: {'f1': 0.4444444444444444, 'accuracy': 0.8, 'precision': 0.38095238095238093, 'recall': 0.5333333333333333, 'mcc': 0.3334751320564686}, 0.30000000000000004: {'f1': 0.4444444444444444, 'accuracy': 0.8, 'precision': 0.38095238095238093, 'recall': 0.5333333333333333, 'mcc': 0.3334751320564686}, 0.4: {'f1': 0.375, 'accuracy': 0.8, 'precision': 0.35294117647058826, 'recall': 0.4, 'mcc': 0.2572174899187587}, 0.5: {'f1': 0.375, 'accuracy': 0.8, 'precision': 0.35294117647058826, 'recall': 0.4, 'mcc': 0.2572174899187587}, 0.6: {'f1': 0.375, 'accuracy': 0.8, 'precision': 0.35294117647058826, 'recall': 0.4, 'mcc': 0.2572174899187587}, 0.7000000000000001: {'f1': 0.375, 'accuracy': 0.8, 'precision': 0.35294117647058826, 'recall': 0.4, 'mcc': 0.2572174899187587}, 0.8: {'f1': 0.375, 'accuracy': 0.8, 'precision': 0.35294117647058826, 'recall': 0.4, 'mcc': 0.2572174899187587}, 0.9: {'f1': 0.375, 'accuracy': 0.8, 'precision': 0.35294117647058826, 'recall': 0.4, 'mcc': 0.2572174899187587}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Decision Tree with Manual Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, params):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define Decision Tree model with given parameters\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=params.get('criterion', 'entropy'),\n",
    "        max_depth=params.get('max_depth', None),\n",
    "        min_samples_split=params.get('min_samples_split', 2),\n",
    "        min_samples_leaf=params.get('min_samples_leaf', 1),\n",
    "        max_features=params.get('max_features', None),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "       # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_fold = {fold+1: {threshold: {'f1': 0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'mcc': 0}\n",
    "                                 for threshold in thresholds}\n",
    "                        for fold in range(n_splits)}\n",
    "    successFold = 0\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "        X_train, X_test = Z[train_index], Z[test_index]\n",
    "        y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "        if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "            print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on test set\n",
    "        y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "        # Calculate metrics for each threshold for this fold\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "            # Calculate metrics for this threshold\n",
    "            f1 = f1_score(y_test, y_pred, average='binary', zero_division=1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='binary', zero_division=1)\n",
    "            recall = recall_score(y_test, y_pred, average='binary', zero_division=1)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "            # Store metrics for the current threshold for this fold\n",
    "            metrics_per_fold[fold+1][threshold]['f1'] = f1\n",
    "            metrics_per_fold[fold+1][threshold]['accuracy'] = accuracy\n",
    "            metrics_per_fold[fold+1][threshold]['precision'] = precision\n",
    "            metrics_per_fold[fold+1][threshold]['recall'] = recall\n",
    "            metrics_per_fold[fold+1][threshold]['mcc'] = mcc\n",
    "\n",
    "        successFold += 1\n",
    "\n",
    "    if successFold == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return params, None\n",
    "\n",
    "    # Save the results for each threshold and fold\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold-allKfold.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        # Write the header\n",
    "        fo.write(\"fold,threshold,accuracy,precision,recall,f1,mcc\\n\")\n",
    "        # Write the data for each fold and each threshold\n",
    "        for fold in range(1, successFold + 1):\n",
    "            for threshold in thresholds:\n",
    "                fo.write(f\"{fold},{threshold},{metrics_per_fold[fold][threshold]['accuracy']},{metrics_per_fold[fold][threshold]['precision']},\"\n",
    "                         f\"{metrics_per_fold[fold][threshold]['recall']},{metrics_per_fold[fold][threshold]['f1']},{metrics_per_fold[fold][threshold]['mcc']}\\n\")\n",
    "\n",
    "    print(f\"Decision Tree analysis completed for {successFold} folds. Results saved to: {outFile}\")\n",
    "    return params, metrics_per_fold\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    params = {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"max_depth\": 300,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\" : 'log2'\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, best_score_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "    best_params_3folds_1, best_score_3folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 3, dim=100, eps=0.3, combination_label=\"equal\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_1}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on equal combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_1}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_1}\")\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, best_score_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "    best_params_3folds_2, best_score_3folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 3, dim=100, eps=0.3, combination_label=\"larger\", params=params)\n",
    "\n",
    "    print(\"Best results for 5-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_5folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_5folds_2}\")\n",
    "\n",
    "    print(\"Best results for 3-fold on larger non-flaky combination:\")\n",
    "    print(f\"Best Parameters: {best_params_3folds_2}\")\n",
    "    print(f\"Best F1 Score: {best_score_3folds_2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6318a53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Decision Tree analysis completed. Results saved to: equal-params-dt-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "      criterion  max_depth  min_samples_split  min_samples_leaf max_features  \\\n",
      "0          gini        NaN                  2                 1         None   \n",
      "1          gini        NaN                  2                 1         None   \n",
      "2          gini        NaN                  2                 1         None   \n",
      "3          gini        NaN                  2                 1         None   \n",
      "4          gini        NaN                  2                 1         None   \n",
      "...         ...        ...                ...               ...          ...   \n",
      "22675   entropy      500.0                 10                10         log2   \n",
      "22676   entropy      500.0                 10                10         log2   \n",
      "22677   entropy      500.0                 10                10         log2   \n",
      "22678   entropy      500.0                 10                10         log2   \n",
      "22679   entropy      500.0                 10                10         log2   \n",
      "\n",
      "       fold  threshold  accuracy  precision    recall        f1       mcc  \n",
      "0         1        0.1  0.578947   0.600000  0.600000  0.600000  0.155556  \n",
      "1         1        0.2  0.578947   0.600000  0.600000  0.600000  0.155556  \n",
      "2         1        0.3  0.578947   0.600000  0.600000  0.600000  0.155556  \n",
      "3         1        0.4  0.578947   0.600000  0.600000  0.600000  0.155556  \n",
      "4         1        0.5  0.578947   0.600000  0.600000  0.600000  0.155556  \n",
      "...     ...        ...       ...        ...       ...       ...       ...  \n",
      "22675     5        0.5  0.555556   0.666667  0.222222  0.333333  0.149071  \n",
      "22676     5        0.6  0.555556   0.666667  0.222222  0.333333  0.149071  \n",
      "22677     5        0.7  0.555556   0.666667  0.222222  0.333333  0.149071  \n",
      "22678     5        0.8  0.555556   0.666667  0.222222  0.333333  0.149071  \n",
      "22679     5        0.9  0.500000   1.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[22680 rows x 12 columns]\n",
      "Starting Decision Tree analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'gini', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 300, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'sqrt'}\n",
      "Training with parameters: {'criterion': 'entropy', 'max_depth': 500, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree analysis completed. Results saved to: larger-params-dt-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "      criterion  max_depth  min_samples_split  min_samples_leaf max_features  \\\n",
      "0          gini        NaN                  2                 1         None   \n",
      "1          gini        NaN                  2                 1         None   \n",
      "2          gini        NaN                  2                 1         None   \n",
      "3          gini        NaN                  2                 1         None   \n",
      "4          gini        NaN                  2                 1         None   \n",
      "...         ...        ...                ...               ...          ...   \n",
      "22675   entropy      500.0                 10                10         log2   \n",
      "22676   entropy      500.0                 10                10         log2   \n",
      "22677   entropy      500.0                 10                10         log2   \n",
      "22678   entropy      500.0                 10                10         log2   \n",
      "22679   entropy      500.0                 10                10         log2   \n",
      "\n",
      "       fold  threshold  accuracy  precision    recall        f1       mcc  \n",
      "0         1        0.1  0.786885        0.2  0.100000  0.133333  0.029109  \n",
      "1         1        0.2  0.786885        0.2  0.100000  0.133333  0.029109  \n",
      "2         1        0.3  0.786885        0.2  0.100000  0.133333  0.029109  \n",
      "3         1        0.4  0.786885        0.2  0.100000  0.133333  0.029109  \n",
      "4         1        0.5  0.786885        0.2  0.100000  0.133333  0.029109  \n",
      "...     ...        ...       ...        ...       ...       ...       ...  \n",
      "22675     5        0.5  0.850000        0.5  0.333333  0.400000  0.326732  \n",
      "22676     5        0.6  0.850000        0.5  0.333333  0.400000  0.326732  \n",
      "22677     5        0.7  0.866667        1.0  0.111111  0.200000  0.309912  \n",
      "22678     5        0.8  0.850000        1.0  0.000000  0.000000  0.000000  \n",
      "22679     5        0.9  0.850000        1.0  0.000000  0.000000  0.000000  \n",
      "\n",
      "[22680 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search Decision Tree with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize DecisionTreeClassifier with current hyperparameter combination\n",
    "        dt_model = DecisionTreeClassifier(\n",
    "            criterion=param_dict['criterion'],\n",
    "            max_depth=param_dict['max_depth'],\n",
    "            min_samples_split=param_dict['min_samples_split'],\n",
    "            min_samples_leaf=param_dict['min_samples_leaf'],\n",
    "            max_features=param_dict['max_features'],\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            dt_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            y_pred_proba = dt_model.predict_proba(X_test)\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'criterion': param_dict['criterion'],\n",
    "                    'max_depth': param_dict['max_depth'],\n",
    "                    'min_samples_split': param_dict['min_samples_split'],\n",
    "                    'min_samples_leaf': param_dict['min_samples_leaf'],\n",
    "                    'max_features': param_dict['max_features'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-dt-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"Decision Tree analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "        'max_depth': [None, 10, 30, 50, 100, 300, 500],  # Maximum depth of each tree\n",
    "        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 5, 10],  # Minimum number of samples required to be at a leaf node\n",
    "        'max_features': [None, 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Decision Tree analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform Decision Tree analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Decision Tree analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00921a6d",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e124ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Random Forest analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Random Forest analysis completed. Results saved to: equal-params-rf-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "       n_estimators criterion  max_depth  min_samples_split  min_samples_leaf  \\\n",
      "0                10      gini         10                  2                 1   \n",
      "1                10      gini         10                  2                 1   \n",
      "2                10      gini         10                  2                 1   \n",
      "3                10      gini         10                  2                 1   \n",
      "4                10      gini         10                  2                 1   \n",
      "...             ...       ...        ...                ...               ...   \n",
      "10795           500   entropy        500                  5                 2   \n",
      "10796           500   entropy        500                  5                 2   \n",
      "10797           500   entropy        500                  5                 2   \n",
      "10798           500   entropy        500                  5                 2   \n",
      "10799           500   entropy        500                  5                 2   \n",
      "\n",
      "       fold  threshold  accuracy  precision    recall        f1       mcc  \n",
      "0         1        0.1  0.578947   0.555556  1.000000  0.714286  0.248452  \n",
      "1         1        0.2  0.736842   0.666667  1.000000  0.800000  0.544331  \n",
      "2         1        0.3  0.684211   0.666667  0.800000  0.727273  0.368035  \n",
      "3         1        0.4  0.684211   0.666667  0.800000  0.727273  0.368035  \n",
      "4         1        0.5  0.789474   0.875000  0.700000  0.777778  0.595543  \n",
      "...     ...        ...       ...        ...       ...       ...       ...  \n",
      "10795     5        0.5  0.722222   0.833333  0.555556  0.666667  0.471405  \n",
      "10796     5        0.6  0.722222   1.000000  0.444444  0.615385  0.534522  \n",
      "10797     5        0.7  0.555556   1.000000  0.111111  0.200000  0.242536  \n",
      "10798     5        0.8  0.500000   1.000000  0.000000  0.000000  0.000000  \n",
      "10799     5        0.9  0.500000   1.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[10800 rows x 12 columns]\n",
      "Starting Random Forest analysis for flaky vs larger non-flaky files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 10, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 50, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 100, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'n_estimators': 300, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 300, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Training with parameters: {'n_estimators': 500, 'max_depth': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n",
      "Random Forest analysis completed. Results saved to: larger-params-rf-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "       n_estimators criterion  max_depth  min_samples_split  min_samples_leaf  \\\n",
      "0                10      gini         10                  2                 1   \n",
      "1                10      gini         10                  2                 1   \n",
      "2                10      gini         10                  2                 1   \n",
      "3                10      gini         10                  2                 1   \n",
      "4                10      gini         10                  2                 1   \n",
      "...             ...       ...        ...                ...               ...   \n",
      "10795           500   entropy        500                  5                 2   \n",
      "10796           500   entropy        500                  5                 2   \n",
      "10797           500   entropy        500                  5                 2   \n",
      "10798           500   entropy        500                  5                 2   \n",
      "10799           500   entropy        500                  5                 2   \n",
      "\n",
      "       fold  threshold  accuracy  precision    recall        f1       mcc  \n",
      "0         1        0.1  0.508197   0.236842  0.900000  0.375000  0.253131  \n",
      "1         1        0.2  0.704918   0.318182  0.700000  0.437500  0.312926  \n",
      "2         1        0.3  0.836066   0.500000  0.300000  0.375000  0.299822  \n",
      "3         1        0.4  0.836066   0.500000  0.300000  0.375000  0.299822  \n",
      "4         1        0.5  0.868852   0.750000  0.300000  0.428571  0.419357  \n",
      "...     ...        ...       ...        ...       ...       ...       ...  \n",
      "10795     5        0.5  0.866667   1.000000  0.111111  0.200000  0.309912  \n",
      "10796     5        0.6  0.866667   1.000000  0.111111  0.200000  0.309912  \n",
      "10797     5        0.7  0.866667   1.000000  0.111111  0.200000  0.309912  \n",
      "10798     5        0.8  0.850000   1.000000  0.000000  0.000000  0.000000  \n",
      "10799     5        0.9  0.850000   1.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[10800 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search Random Forest with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize RandomForestClassifier with current hyperparameter combination\n",
    "        rf_model = RandomForestClassifier(\n",
    "            n_estimators=param_dict['n_estimators'],\n",
    "            criterion=param_dict['criterion'],\n",
    "            max_depth=param_dict['max_depth'],\n",
    "            min_samples_split=param_dict['min_samples_split'],\n",
    "            min_samples_leaf=param_dict['min_samples_leaf'],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            rf_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            y_pred_proba = rf_model.predict_proba(X_test)\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'n_estimators': param_dict['n_estimators'],\n",
    "                    'criterion': param_dict['criterion'],\n",
    "                    'max_depth': param_dict['max_depth'],\n",
    "                    'min_samples_split': param_dict['min_samples_split'],\n",
    "                    'min_samples_leaf': param_dict['min_samples_leaf'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-rf-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"Random Forest analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 300, 500],  # Number of trees\n",
    "        'max_depth': [10, 30, 50, 100, 300, 500],  # Maximum depth of each tree\n",
    "        'min_samples_split': [2, 5],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2],  # Minimum number of samples required to be at a leaf node\n",
    "        'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Random Forest analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Random Forest analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform Random Forest analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Random Forest analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69d231",
   "metadata": {},
   "source": [
    "XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63dba2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting XGBoost analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost analysis completed. Results saved to: equal-params-xgb-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "       eta  max_depth  n_estimators  fold  threshold  accuracy  precision  \\\n",
      "0     0.01          3            50     1        0.1  0.526316   0.526316   \n",
      "1     0.01          3            50     1        0.2  0.526316   0.526316   \n",
      "2     0.01          3            50     1        0.3  0.526316   0.526316   \n",
      "3     0.01          3            50     1        0.4  0.684211   0.700000   \n",
      "4     0.01          3            50     1        0.5  0.736842   0.857143   \n",
      "...    ...        ...           ...   ...        ...       ...        ...   \n",
      "2875  0.50         10           300     5        0.5  0.777778   0.777778   \n",
      "2876  0.50         10           300     5        0.6  0.833333   0.875000   \n",
      "2877  0.50         10           300     5        0.7  0.833333   0.875000   \n",
      "2878  0.50         10           300     5        0.8  0.888889   1.000000   \n",
      "2879  0.50         10           300     5        0.9  0.888889   1.000000   \n",
      "\n",
      "        recall        f1       mcc  \n",
      "0     1.000000  0.689655  0.000000  \n",
      "1     1.000000  0.689655  0.000000  \n",
      "2     1.000000  0.689655  0.000000  \n",
      "3     0.700000  0.700000  0.366667  \n",
      "4     0.600000  0.705882  0.506048  \n",
      "...        ...       ...       ...  \n",
      "2875  0.777778  0.777778  0.555556  \n",
      "2876  0.777778  0.823529  0.670820  \n",
      "2877  0.777778  0.823529  0.670820  \n",
      "2878  0.777778  0.875000  0.797724  \n",
      "2879  0.777778  0.875000  0.797724  \n",
      "\n",
      "[2880 rows x 10 columns]\n",
      "Starting XGBoost analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.01, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.1, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.3, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:28:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 7, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'eta': 0.5, 'max_depth': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost analysis completed. Results saved to: larger-params-xgb-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "       eta  max_depth  n_estimators  fold  threshold  accuracy  precision  \\\n",
      "0     0.01          3            50     1        0.1  0.163934   0.163934   \n",
      "1     0.01          3            50     1        0.2  0.770492   0.300000   \n",
      "2     0.01          3            50     1        0.3  0.868852   0.750000   \n",
      "3     0.01          3            50     1        0.4  0.819672   0.000000   \n",
      "4     0.01          3            50     1        0.5  0.836066   1.000000   \n",
      "...    ...        ...           ...   ...        ...       ...        ...   \n",
      "2875  0.50         10           300     5        0.5  0.850000   0.500000   \n",
      "2876  0.50         10           300     5        0.6  0.850000   0.500000   \n",
      "2877  0.50         10           300     5        0.7  0.850000   0.500000   \n",
      "2878  0.50         10           300     5        0.8  0.866667   1.000000   \n",
      "2879  0.50         10           300     5        0.9  0.866667   1.000000   \n",
      "\n",
      "        recall        f1       mcc  \n",
      "0     1.000000  0.281690  0.000000  \n",
      "1     0.300000  0.300000  0.162745  \n",
      "2     0.300000  0.428571  0.419357  \n",
      "3     0.000000  0.000000 -0.057166  \n",
      "4     0.000000  0.000000  0.000000  \n",
      "...        ...       ...       ...  \n",
      "2875  0.111111  0.181818  0.182018  \n",
      "2876  0.111111  0.181818  0.182018  \n",
      "2877  0.111111  0.181818  0.182018  \n",
      "2878  0.111111  0.200000  0.309912  \n",
      "2879  0.111111  0.200000  0.309912  \n",
      "\n",
      "[2880 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\haha9\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:29:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search XGBoost with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize XGBClassifier with current hyperparameter combination\n",
    "        xgb_model = XGBClassifier(\n",
    "            eta=param_dict['eta'],\n",
    "            max_depth=param_dict['max_depth'],\n",
    "            n_estimators=param_dict['n_estimators'],\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            xgb_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            y_pred_proba = xgb_model.predict_proba(X_test)\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'eta': param_dict['eta'],\n",
    "                    'max_depth': param_dict['max_depth'],\n",
    "                    'n_estimators': param_dict['n_estimators'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-xgb-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"XGBoost analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'eta': [0.01, 0.1, 0.3, 0.5],  # Learning rate\n",
    "        'max_depth': [3, 5, 7, 10],    # Tree depth\n",
    "        'n_estimators': [50, 100, 200, 300],  # Number of boosting rounds\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform XGBoost analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting XGBoost analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform XGBoost analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting XGBoost analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd4d47",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6041d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KNN analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "KNN analysis completed for 5 folds. Results saved to: equal-params-knn-5-folds-Threshold-allKfold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "KNN analysis completed for 3 folds. Results saved to: equal-params-knn-3-folds-Threshold-allKfold.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "Best Parameters: {'n_neighbors': 5, 'metric': 'cosine', 'weights': 'distance'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.7142857142857143, 'accuracy': 0.5789473684210527, 'precision': 0.5555555555555556, 'recall': 1.0, 'mcc': 0.24845199749997662}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.5789473684210527, 'precision': 0.5714285714285714, 'recall': 0.8, 'mcc': 0.15118578920369088}, 0.30000000000000004: {'f1': 0.6363636363636364, 'accuracy': 0.5789473684210527, 'precision': 0.5833333333333334, 'recall': 0.7, 'mcc': 0.14951420452417674}, 0.4: {'f1': 0.631578947368421, 'accuracy': 0.631578947368421, 'precision': 0.6666666666666666, 'recall': 0.6, 'mcc': 0.26666666666666666}, 0.5: {'f1': 0.625, 'accuracy': 0.6842105263157895, 'precision': 0.8333333333333334, 'recall': 0.5, 'mcc': 0.41773367652300253}, 0.6: {'f1': 0.5714285714285714, 'accuracy': 0.6842105263157895, 'precision': 1.0, 'recall': 0.4, 'mcc': 0.4898979485566356}, 0.7000000000000001: {'f1': 0.46153846153846156, 'accuracy': 0.631578947368421, 'precision': 1.0, 'recall': 0.3, 'mcc': 0.4107919181288746}, 0.8: {'f1': 0.3333333333333333, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.32539568672798425}, 0.9: {'f1': 0.18181818181818182, 'accuracy': 0.5263157894736842, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.22360679774997896}}, 2: {0.1: {'f1': 0.6896551724137931, 'accuracy': 0.5263157894736842, 'precision': 0.5263157894736842, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.6956521739130435, 'accuracy': 0.631578947368421, 'precision': 0.6153846153846154, 'recall': 0.8, 'mcc': 0.26257545381445874}, 0.30000000000000004: {'f1': 0.7619047619047619, 'accuracy': 0.7368421052631579, 'precision': 0.7272727272727273, 'recall': 0.8, 'mcc': 0.47193990372426947}, 0.4: {'f1': 0.7777777777777778, 'accuracy': 0.7894736842105263, 'precision': 0.875, 'recall': 0.7, 'mcc': 0.5955432118425306}, 0.5: {'f1': 0.8235294117647058, 'accuracy': 0.8421052631578947, 'precision': 1.0, 'recall': 0.7, 'mcc': 0.724568837309472}, 0.6: {'f1': 0.8235294117647058, 'accuracy': 0.8421052631578947, 'precision': 1.0, 'recall': 0.7, 'mcc': 0.724568837309472}, 0.7000000000000001: {'f1': 0.6666666666666666, 'accuracy': 0.7368421052631579, 'precision': 1.0, 'recall': 0.5, 'mcc': 0.5669467095138409}, 0.8: {'f1': 0.6666666666666666, 'accuracy': 0.7368421052631579, 'precision': 1.0, 'recall': 0.5, 'mcc': 0.5669467095138409}, 0.9: {'f1': 0.46153846153846156, 'accuracy': 0.631578947368421, 'precision': 1.0, 'recall': 0.3, 'mcc': 0.4107919181288746}}, 3: {0.1: {'f1': 0.6923076923076923, 'accuracy': 0.5789473684210527, 'precision': 0.5294117647058824, 'recall': 1.0, 'mcc': 0.32539568672798425}, 0.2: {'f1': 0.72, 'accuracy': 0.631578947368421, 'precision': 0.5625, 'recall': 1.0, 'mcc': 0.4107919181288746}, 0.30000000000000004: {'f1': 0.7619047619047619, 'accuracy': 0.7368421052631579, 'precision': 0.6666666666666666, 'recall': 0.8888888888888888, 'mcc': 0.5060480768510598}, 0.4: {'f1': 0.7368421052631579, 'accuracy': 0.7368421052631579, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.4777777777777778}, 0.5: {'f1': 0.7142857142857143, 'accuracy': 0.7894736842105263, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.629940788348712}, 0.6: {'f1': 0.7142857142857143, 'accuracy': 0.7894736842105263, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.629940788348712}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.6842105263157895, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.45643546458763845}, 0.8: {'f1': 0.36363636363636365, 'accuracy': 0.631578947368421, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.3615507630310936}, 0.9: {'f1': 0.2, 'accuracy': 0.5789473684210527, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24845199749997662}}, 4: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.631578947368421, 'precision': 0.5833333333333334, 'recall': 0.7777777777777778, 'mcc': 0.2875273163926476}, 0.2: {'f1': 0.75, 'accuracy': 0.7894736842105263, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.5865557254410011}, 0.30000000000000004: {'f1': 0.75, 'accuracy': 0.7894736842105263, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.5865557254410011}, 0.4: {'f1': 0.75, 'accuracy': 0.7894736842105263, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.5865557254410011}, 0.5: {'f1': 0.8, 'accuracy': 0.8421052631578947, 'precision': 1.0, 'recall': 0.6666666666666666, 'mcc': 0.7161148740394329}, 0.6: {'f1': 0.7142857142857143, 'accuracy': 0.7894736842105263, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.629940788348712}, 0.7000000000000001: {'f1': 0.7142857142857143, 'accuracy': 0.7894736842105263, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.629940788348712}, 0.8: {'f1': 0.6153846153846154, 'accuracy': 0.7368421052631579, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.5443310539518174}, 0.9: {'f1': 0.5, 'accuracy': 0.6842105263157895, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.45643546458763845}}, 5: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.5, 'precision': 0.5, 'recall': 1.0, 'mcc': 0.0}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.5555555555555556, 'precision': 0.5333333333333333, 'recall': 0.8888888888888888, 'mcc': 0.14907119849998599}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.6111111111111112, 'precision': 0.5833333333333334, 'recall': 0.7777777777777778, 'mcc': 0.2357022603955158}, 0.4: {'f1': 0.7368421052631579, 'accuracy': 0.7222222222222222, 'precision': 0.7, 'recall': 0.7777777777777778, 'mcc': 0.4472135954999579}, 0.5: {'f1': 0.625, 'accuracy': 0.6666666666666666, 'precision': 0.7142857142857143, 'recall': 0.5555555555555556, 'mcc': 0.34188172937891387}, 0.6: {'f1': 0.6666666666666666, 'accuracy': 0.7222222222222222, 'precision': 0.8333333333333334, 'recall': 0.5555555555555556, 'mcc': 0.4714045207910316}, 0.7000000000000001: {'f1': 0.6666666666666666, 'accuracy': 0.7222222222222222, 'precision': 0.8333333333333334, 'recall': 0.5555555555555556, 'mcc': 0.4714045207910316}, 0.8: {'f1': 0.7142857142857143, 'accuracy': 0.7777777777777778, 'precision': 1.0, 'recall': 0.5555555555555556, 'mcc': 0.6201736729460423}, 0.9: {'f1': 0.2, 'accuracy': 0.5555555555555556, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.24253562503633297}}}\n",
      "Best results for 3-fold on equal combination:\n",
      "Best Parameters: {'n_neighbors': 5, 'metric': 'cosine', 'weights': 'distance'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.6666666666666666, 'accuracy': 0.5625, 'precision': 0.5384615384615384, 'recall': 0.875, 'mcc': 0.16012815380508713}, 0.2: {'f1': 0.65, 'accuracy': 0.5625, 'precision': 0.5416666666666666, 'recall': 0.8125, 'mcc': 0.14433756729740646}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.59375, 'precision': 0.5652173913043478, 'recall': 0.8125, 'mcc': 0.20851441405707474}, 0.4: {'f1': 0.7272727272727273, 'accuracy': 0.71875, 'precision': 0.7058823529411765, 'recall': 0.75, 'mcc': 0.4383570037596047}, 0.5: {'f1': 0.6666666666666666, 'accuracy': 0.6875, 'precision': 0.7142857142857143, 'recall': 0.625, 'mcc': 0.3779644730092272}, 0.6: {'f1': 0.5925925925925926, 'accuracy': 0.65625, 'precision': 0.7272727272727273, 'recall': 0.5, 'mcc': 0.3289758474798845}, 0.7000000000000001: {'f1': 0.48, 'accuracy': 0.59375, 'precision': 0.6666666666666666, 'recall': 0.375, 'mcc': 0.20851441405707474}, 0.8: {'f1': 0.5, 'accuracy': 0.625, 'precision': 0.75, 'recall': 0.375, 'mcc': 0.2886751345948129}, 0.9: {'f1': 0.21052631578947367, 'accuracy': 0.53125, 'precision': 0.6666666666666666, 'recall': 0.125, 'mcc': 0.10721125348377948}}, 2: {0.1: {'f1': 0.7567567567567568, 'accuracy': 0.7096774193548387, 'precision': 0.6666666666666666, 'recall': 0.875, 'mcc': 0.43652669512362646}, 0.2: {'f1': 0.6666666666666666, 'accuracy': 0.6774193548387096, 'precision': 0.7142857142857143, 'recall': 0.625, 'mcc': 0.3598357857649609}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.6774193548387096, 'precision': 0.7142857142857143, 'recall': 0.625, 'mcc': 0.3598357857649609}, 0.4: {'f1': 0.6428571428571429, 'accuracy': 0.6774193548387096, 'precision': 0.75, 'recall': 0.5625, 'mcc': 0.3719171526308684}, 0.5: {'f1': 0.6666666666666666, 'accuracy': 0.7096774193548387, 'precision': 0.8181818181818182, 'recall': 0.5625, 'mcc': 0.44824996408592194}, 0.6: {'f1': 0.64, 'accuracy': 0.7096774193548387, 'precision': 0.8888888888888888, 'recall': 0.5, 'mcc': 0.4770842982214229}, 0.7000000000000001: {'f1': 0.6086956521739131, 'accuracy': 0.7096774193548387, 'precision': 1.0, 'recall': 0.4375, 'mcc': 0.5229125165837972}, 0.8: {'f1': 0.47619047619047616, 'accuracy': 0.6451612903225806, 'precision': 1.0, 'recall': 0.3125, 'mcc': 0.4246038878042234}, 0.9: {'f1': 0.4, 'accuracy': 0.6129032258064516, 'precision': 1.0, 'recall': 0.25, 'mcc': 0.37267799624996495}}, 3: {0.1: {'f1': 0.6818181818181818, 'accuracy': 0.5483870967741935, 'precision': 0.5172413793103449, 'recall': 1.0, 'mcc': 0.2542738138578039}, 0.2: {'f1': 0.7368421052631579, 'accuracy': 0.6774193548387096, 'precision': 0.6086956521739131, 'recall': 0.9333333333333333, 'mcc': 0.4235215118674525}, 0.30000000000000004: {'f1': 0.6857142857142857, 'accuracy': 0.6451612903225806, 'precision': 0.6, 'recall': 0.8, 'mcc': 0.3133397807202561}, 0.4: {'f1': 0.7058823529411765, 'accuracy': 0.6774193548387096, 'precision': 0.631578947368421, 'recall': 0.8, 'mcc': 0.3719171526308684}, 0.5: {'f1': 0.7096774193548387, 'accuracy': 0.7096774193548387, 'precision': 0.6875, 'recall': 0.7333333333333333, 'mcc': 0.42083333333333334}, 0.6: {'f1': 0.6896551724137931, 'accuracy': 0.7096774193548387, 'precision': 0.7142857142857143, 'recall': 0.6666666666666666, 'mcc': 0.4184137043778615}, 0.7000000000000001: {'f1': 0.6153846153846154, 'accuracy': 0.6774193548387096, 'precision': 0.7272727272727273, 'recall': 0.5333333333333333, 'mcc': 0.36121113610807304}, 0.8: {'f1': 0.5833333333333334, 'accuracy': 0.6774193548387096, 'precision': 0.7777777777777778, 'recall': 0.4666666666666667, 'mcc': 0.3761626197515065}, 0.9: {'f1': 0.42105263157894735, 'accuracy': 0.6451612903225806, 'precision': 1.0, 'recall': 0.26666666666666666, 'mcc': 0.3975231959999626}}}\n",
      "Starting KNN analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN analysis completed for 5 folds. Results saved to: larger-params-knn-5-folds-Threshold-allKfold.csv\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "KNN analysis completed for 3 folds. Results saved to: larger-params-knn-3-folds-Threshold-allKfold.csv\n",
      "Best results for 5-fold on larger non-flaky combination:\n",
      "Best Parameters: {'n_neighbors': 5, 'metric': 'cosine', 'weights': 'distance'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.6923076923076923, 'accuracy': 0.8688524590163934, 'precision': 0.5625, 'recall': 0.9, 'mcc': 0.6419456570298772}, 0.2: {'f1': 0.7058823529411765, 'accuracy': 0.9180327868852459, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.674156495167981}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.9180327868852459, 'precision': 1.0, 'recall': 0.5, 'mcc': 0.6748015581318281}, 0.4: {'f1': 0.46153846153846156, 'accuracy': 0.8852459016393442, 'precision': 1.0, 'recall': 0.3, 'mcc': 0.51360792775061}, 0.5: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}, 0.6: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}, 0.7000000000000001: {'f1': 0.3333333333333333, 'accuracy': 0.8688524590163934, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.4157900382791817}, 0.8: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}, 0.9: {'f1': 0.18181818181818182, 'accuracy': 0.8524590163934426, 'precision': 1.0, 'recall': 0.1, 'mcc': 0.291547594742265}}, 2: {0.1: {'f1': 0.4827586206896552, 'accuracy': 0.75, 'precision': 0.3684210526315789, 'recall': 0.7, 'mcc': 0.36853106738124597}, 0.2: {'f1': 0.631578947368421, 'accuracy': 0.8833333333333333, 'precision': 0.6666666666666666, 'recall': 0.6, 'mcc': 0.5636018619766345}, 0.30000000000000004: {'f1': 0.6666666666666666, 'accuracy': 0.9, 'precision': 0.75, 'recall': 0.6, 'mcc': 0.6139406135149205}, 0.4: {'f1': 0.7058823529411765, 'accuracy': 0.9166666666666666, 'precision': 0.8571428571428571, 'recall': 0.6, 'mcc': 0.6733270173082295}, 0.5: {'f1': 0.625, 'accuracy': 0.9, 'precision': 0.8333333333333334, 'recall': 0.5, 'mcc': 0.5962847939999439}, 0.6: {'f1': 0.6666666666666666, 'accuracy': 0.9166666666666666, 'precision': 1.0, 'recall': 0.5, 'mcc': 0.674199862463242}, 0.7000000000000001: {'f1': 0.5714285714285714, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.4, 'mcc': 0.5976143046671968}, 0.8: {'f1': 0.3333333333333333, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.41522739926869984}, 0.9: {'f1': 0.3333333333333333, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.2, 'mcc': 0.41522739926869984}}, 3: {0.1: {'f1': 0.37037037037037035, 'accuracy': 0.7166666666666667, 'precision': 0.2777777777777778, 'recall': 0.5555555555555556, 'mcc': 0.2342673936849873}, 0.2: {'f1': 0.3333333333333333, 'accuracy': 0.8, 'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'mcc': 0.21568627450980393}, 0.30000000000000004: {'f1': 0.2857142857142857, 'accuracy': 0.8333333333333334, 'precision': 0.4, 'recall': 0.2222222222222222, 'mcc': 0.21110016546037455}, 0.4: {'f1': 0.3333333333333333, 'accuracy': 0.8666666666666667, 'precision': 0.6666666666666666, 'recall': 0.2222222222222222, 'mcc': 0.33195449253833836}, 0.5: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.6: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.7000000000000001: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.8: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}, 0.9: {'f1': 0.0, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0, 'mcc': 0.0}}, 4: {0.1: {'f1': 0.631578947368421, 'accuracy': 0.8833333333333333, 'precision': 0.6, 'recall': 0.6666666666666666, 'mcc': 0.5636018619766345}, 0.2: {'f1': 0.5714285714285714, 'accuracy': 0.9, 'precision': 0.8, 'recall': 0.4444444444444444, 'mcc': 0.5488604301969738}, 0.30000000000000004: {'f1': 0.6153846153846154, 'accuracy': 0.9166666666666666, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.6362090102803518}, 0.4: {'f1': 0.6153846153846154, 'accuracy': 0.9166666666666666, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.6362090102803518}, 0.5: {'f1': 0.6153846153846154, 'accuracy': 0.9166666666666666, 'precision': 1.0, 'recall': 0.4444444444444444, 'mcc': 0.6362090102803518}, 0.6: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.7000000000000001: {'f1': 0.5, 'accuracy': 0.9, 'precision': 1.0, 'recall': 0.3333333333333333, 'mcc': 0.5461186812727502}, 0.8: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.9: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}}, 5: {0.1: {'f1': 0.5, 'accuracy': 0.7666666666666667, 'precision': 0.3684210526315789, 'recall': 0.7777777777777778, 'mcc': 0.4164129963551078}, 0.2: {'f1': 0.6, 'accuracy': 0.8666666666666667, 'precision': 0.5454545454545454, 'recall': 0.6666666666666666, 'mcc': 0.5247346970015024}, 0.30000000000000004: {'f1': 0.75, 'accuracy': 0.9333333333333333, 'precision': 0.8571428571428571, 'recall': 0.6666666666666666, 'mcc': 0.7197193047267257}, 0.4: {'f1': 0.6666666666666666, 'accuracy': 0.9166666666666666, 'precision': 0.8333333333333334, 'recall': 0.5555555555555556, 'mcc': 0.6379053716127601}, 0.5: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.6: {'f1': 0.36363636363636365, 'accuracy': 0.8833333333333333, 'precision': 1.0, 'recall': 0.2222222222222222, 'mcc': 0.4420433223684922}, 0.7000000000000001: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.8: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}, 0.9: {'f1': 0.2, 'accuracy': 0.8666666666666667, 'precision': 1.0, 'recall': 0.1111111111111111, 'mcc': 0.3099115966531633}}}\n",
      "Best results for 3-fold on larger non-flaky combination:\n",
      "Best Parameters: {'n_neighbors': 5, 'metric': 'cosine', 'weights': 'distance'}\n",
      "Best F1 Score: {1: {0.1: {'f1': 0.48, 'accuracy': 0.7425742574257426, 'precision': 0.35294117647058826, 'recall': 0.75, 'mcc': 0.3795160510317786}, 0.2: {'f1': 0.3225806451612903, 'accuracy': 0.7920792079207921, 'precision': 0.3333333333333333, 'recall': 0.3125, 'mcc': 0.20006981225702639}, 0.30000000000000004: {'f1': 0.4, 'accuracy': 0.8514851485148515, 'precision': 0.5555555555555556, 'recall': 0.3125, 'mcc': 0.34019081159274195}, 0.4: {'f1': 0.3333333333333333, 'accuracy': 0.8415841584158416, 'precision': 0.5, 'recall': 0.25, 'mcc': 0.27438044751954294}, 0.5: {'f1': 0.3, 'accuracy': 0.8613861386138614, 'precision': 0.75, 'recall': 0.1875, 'mcc': 0.3290126407424865}, 0.6: {'f1': 0.3, 'accuracy': 0.8613861386138614, 'precision': 0.75, 'recall': 0.1875, 'mcc': 0.3290126407424865}, 0.7000000000000001: {'f1': 0.2222222222222222, 'accuracy': 0.8613861386138614, 'precision': 1.0, 'recall': 0.125, 'mcc': 0.32760224712787356}, 0.8: {'f1': 0.11764705882352941, 'accuracy': 0.8514851485148515, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23048861143232216}, 0.9: {'f1': 0.11764705882352941, 'accuracy': 0.8514851485148515, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23048861143232216}}, 2: {0.1: {'f1': 0.45714285714285713, 'accuracy': 0.81, 'precision': 0.42105263157894735, 'recall': 0.5, 'mcc': 0.3448758089772117}, 0.2: {'f1': 0.42424242424242425, 'accuracy': 0.81, 'precision': 0.4117647058823529, 'recall': 0.4375, 'mcc': 0.3107997263725734}, 0.30000000000000004: {'f1': 0.42857142857142855, 'accuracy': 0.84, 'precision': 0.5, 'recall': 0.375, 'mcc': 0.3424747597107866}, 0.4: {'f1': 0.46153846153846156, 'accuracy': 0.86, 'precision': 0.6, 'recall': 0.375, 'mcc': 0.40006613209931935}, 0.5: {'f1': 0.2857142857142857, 'accuracy': 0.85, 'precision': 0.6, 'recall': 0.1875, 'mcc': 0.2753443958769674}, 0.6: {'f1': 0.3, 'accuracy': 0.86, 'precision': 0.75, 'recall': 0.1875, 'mcc': 0.3285086098506883}, 0.7000000000000001: {'f1': 0.21052631578947367, 'accuracy': 0.85, 'precision': 0.6666666666666666, 'recall': 0.125, 'mcc': 0.24305102621022315}, 0.8: {'f1': 0.11764705882352941, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23028309323591917}, 0.9: {'f1': 0.11764705882352941, 'accuracy': 0.85, 'precision': 1.0, 'recall': 0.0625, 'mcc': 0.23028309323591917}}, 3: {0.1: {'f1': 0.43636363636363634, 'accuracy': 0.69, 'precision': 0.3, 'recall': 0.8, 'mcc': 0.3429971702850177}, 0.2: {'f1': 0.5581395348837209, 'accuracy': 0.81, 'precision': 0.42857142857142855, 'recall': 0.8, 'mcc': 0.48651277256732783}, 0.30000000000000004: {'f1': 0.5405405405405406, 'accuracy': 0.83, 'precision': 0.45454545454545453, 'recall': 0.6666666666666666, 'mcc': 0.4529612688257838}, 0.4: {'f1': 0.5517241379310345, 'accuracy': 0.87, 'precision': 0.5714285714285714, 'recall': 0.5333333333333333, 'mcc': 0.4761937332961372}, 0.5: {'f1': 0.4166666666666667, 'accuracy': 0.86, 'precision': 0.5555555555555556, 'recall': 0.3333333333333333, 'mcc': 0.3571871456175624}, 0.6: {'f1': 0.4, 'accuracy': 0.88, 'precision': 0.8, 'recall': 0.26666666666666666, 'mcc': 0.41762016803210306}, 0.7000000000000001: {'f1': 0.42105263157894735, 'accuracy': 0.89, 'precision': 1.0, 'recall': 0.26666666666666666, 'mcc': 0.485912657903775}, 0.8: {'f1': 0.23529411764705882, 'accuracy': 0.87, 'precision': 1.0, 'recall': 0.13333333333333333, 'mcc': 0.3400680204068024}, 0.9: {'f1': 0.23529411764705882, 'accuracy': 0.87, 'precision': 1.0, 'recall': 0.13333333333333333, 'mcc': 0.3400680204068024}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search KNN with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize KNeighborsClassifier with current hyperparameter combination\n",
    "        knn_model = KNeighborsClassifier(\n",
    "            n_neighbors=param_dict['n_neighbors'],\n",
    "            weights=param_dict['weights'],\n",
    "            algorithm=param_dict['algorithm'],\n",
    "            leaf_size=param_dict['leaf_size'],\n",
    "            p=param_dict['p'],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            knn_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            if hasattr(knn_model, \"predict_proba\"):\n",
    "                y_pred_proba = knn_model.predict_proba(X_test)\n",
    "            else:\n",
    "                # If predict_proba is not available, use distance-based probabilities\n",
    "                distances, indices = knn_model.kneighbors(X_test)\n",
    "                weights = knn_model._get_weights(distances)\n",
    "                y_pred_proba = np.zeros((X_test.shape[0], 2))\n",
    "                for i, neighbors in enumerate(indices):\n",
    "                    neighbor_labels = y_train[neighbors]\n",
    "                    if weights is None:\n",
    "                        proba = np.bincount(neighbor_labels, minlength=2) / knn_model.n_neighbors\n",
    "                    else:\n",
    "                        proba = np.bincount(neighbor_labels, weights=weights[i], minlength=2) / weights[i].sum()\n",
    "                    y_pred_proba[i] = proba\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'n_neighbors': param_dict['n_neighbors'],\n",
    "                    'weights': param_dict['weights'],\n",
    "                    'algorithm': param_dict['algorithm'],\n",
    "                    'leaf_size': param_dict['leaf_size'],\n",
    "                    'p': param_dict['p'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-knn-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"KNN analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9,11,15,20],           # Number of neighbors to use\n",
    "        'weights': ['uniform', 'distance'],    # Weight function used in prediction\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute the nearest neighbors\n",
    "        'leaf_size': [30, 50],                 # Leaf size passed to BallTree or KDTree\n",
    "        'p': [1, 2],                           # Power parameter for the Minkowski metric\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform KNN analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting KNN analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform KNN analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting KNN analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc8ceb",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed90c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SVM analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'sigmoid'}\n",
      "SVM analysis completed. Results saved to: equal-params-svm-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on equal combination:\n",
      "          C   kernel  fold  threshold  accuracy  precision    recall  \\\n",
      "0      0.01   linear     1        0.1  0.526316   0.526316  1.000000   \n",
      "1      0.01   linear     1        0.2  0.526316   0.526316  1.000000   \n",
      "2      0.01   linear     1        0.3  0.526316   0.526316  1.000000   \n",
      "3      0.01   linear     1        0.4  0.421053   0.470588  0.800000   \n",
      "4      0.01   linear     1        0.5  0.526316   0.545455  0.600000   \n",
      "..      ...      ...   ...        ...       ...        ...       ...   \n",
      "895  100.00  sigmoid     5        0.5  0.444444   0.454545  0.555556   \n",
      "896  100.00  sigmoid     5        0.6  0.500000   1.000000  0.000000   \n",
      "897  100.00  sigmoid     5        0.7  0.500000   1.000000  0.000000   \n",
      "898  100.00  sigmoid     5        0.8  0.500000   1.000000  0.000000   \n",
      "899  100.00  sigmoid     5        0.9  0.500000   1.000000  0.000000   \n",
      "\n",
      "           f1       mcc  \n",
      "0    0.689655  0.000000  \n",
      "1    0.689655  0.000000  \n",
      "2    0.689655  0.000000  \n",
      "3    0.592593 -0.325396  \n",
      "4    0.571429  0.044947  \n",
      "..        ...       ...  \n",
      "895  0.500000 -0.113961  \n",
      "896  0.000000  0.000000  \n",
      "897  0.000000  0.000000  \n",
      "898  0.000000  0.000000  \n",
      "899  0.000000  0.000000  \n",
      "\n",
      "[900 rows x 9 columns]\n",
      "Starting SVM analysis for flaky vs larger non-flaky files...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 254\n",
      "Total number of documents: 301\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 0.01, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 10.0, 'kernel': 'sigmoid'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'linear'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'poly'}\n",
      "Training with parameters: {'C': 100.0, 'kernel': 'sigmoid'}\n",
      "SVM analysis completed. Results saved to: larger-params-svm-5-folds-Threshold-allKfold-wogridsearch.csv\n",
      "Best results for 5-fold on larger combination:\n",
      "          C   kernel  fold  threshold  accuracy  precision  recall        f1  \\\n",
      "0      0.01   linear     1        0.1  0.229508   0.175439     1.0  0.298507   \n",
      "1      0.01   linear     1        0.2  0.868852   1.000000     0.2  0.333333   \n",
      "2      0.01   linear     1        0.3  0.852459   1.000000     0.1  0.181818   \n",
      "3      0.01   linear     1        0.4  0.852459   1.000000     0.1  0.181818   \n",
      "4      0.01   linear     1        0.5  0.836066   1.000000     0.0  0.000000   \n",
      "..      ...      ...   ...        ...       ...        ...     ...       ...   \n",
      "895  100.00  sigmoid     5        0.5  0.850000   1.000000     0.0  0.000000   \n",
      "896  100.00  sigmoid     5        0.6  0.850000   1.000000     0.0  0.000000   \n",
      "897  100.00  sigmoid     5        0.7  0.850000   1.000000     0.0  0.000000   \n",
      "898  100.00  sigmoid     5        0.8  0.850000   1.000000     0.0  0.000000   \n",
      "899  100.00  sigmoid     5        0.9  0.850000   1.000000     0.0  0.000000   \n",
      "\n",
      "          mcc  \n",
      "0    0.117303  \n",
      "1    0.415790  \n",
      "2    0.291548  \n",
      "3    0.291548  \n",
      "4    0.000000  \n",
      "..        ...  \n",
      "895  0.000000  \n",
      "896  0.000000  \n",
      "897  0.000000  \n",
      "898  0.000000  \n",
      "899  0.000000  \n",
      "\n",
      "[900 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search SVM with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize SVM with current hyperparameter combination\n",
    "        svm_model = SVC(\n",
    "            C=param_dict['C'],\n",
    "            kernel=param_dict['kernel'],\n",
    "            probability=True,  # Enable probability estimates\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            try:\n",
    "                svm_model.fit(X_train, y_train)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to train SVM with parameters {param_dict} on fold {fold+1}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            try:\n",
    "                y_pred_proba = svm_model.predict_proba(X_test)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to predict probabilities with SVM on fold {fold+1}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'C': param_dict['C'],\n",
    "                    'kernel': param_dict['kernel'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-svm-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"SVM analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization parameter\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # Kernel types\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform SVM analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting SVM analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform SVM analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting SVM analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74136b4",
   "metadata": {},
   "source": [
    "NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0281b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unlance without adjustment\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e823f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Naive Bayes analysis for flaky vs smaller non-flaky files (47 each)...\n",
      "Number of flaky documents: 47\n",
      "Number of non-flaky documents: 47\n",
      "Total number of documents: 94\n",
      "Training with parameters: {'alpha': 0.001}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 186\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Perform Naive Bayes analysis for the first combination (flaky vs smaller non-flaky)\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Naive Bayes analysis for flaky vs smaller non-flaky files (47 each)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m best_params_5folds_1, df_results_5folds_1 \u001b[38;5;241m=\u001b[39m flastThreshold(\n\u001b[0;32m    187\u001b[0m     outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, \u001b[38;5;241m5\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, combination_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_grid\u001b[38;5;241m=\u001b[39mparam_grid)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest results for 5-fold on equal combination:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_results_5folds_1)\n",
      "Cell \u001b[1;32mIn[5], line 120\u001b[0m, in \u001b[0;36mflastThreshold\u001b[1;34m(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m nb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Predict probabilities on test set\u001b[39;00m\n\u001b[0;32m    123\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m nb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:759\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    757\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count(X, Y)\n\u001b[0;32m    760\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:881\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    880\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 881\u001b[0m     check_non_negative(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultinomialNB (input X)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1689\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1689\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from itertools import product\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints, dim=0, eps=0.3):\n",
    "    \"\"\"Performs vectorization using CountVectorizer with optional dimensionality reduction.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z_full = countVec.fit_transform(dataPoints)\n",
    "    if eps == 0:\n",
    "        Z = Z_full\n",
    "    else:\n",
    "        if dim <= 0:\n",
    "            from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "            dim = johnson_lindenstrauss_min_dim(Z_full.shape[0], eps=eps)\n",
    "        srp = SparseRandomProjection(n_components=dim)\n",
    "        Z = srp.fit_transform(Z_full)\n",
    "    return Z\n",
    "\n",
    "###############################################################################\n",
    "# Manual Grid Search Naive Bayes with Cross-Validation\n",
    "\n",
    "def flastThreshold(outDir, flakyZip, nonFlakyZip, extractDir, n_splits, dim, eps, combination_label, param_grid):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Extract the zip files\n",
    "    flakyDir = os.path.join(extractDir, 'flaky')\n",
    "    nonFlakyDir = os.path.join(extractDir, 'nonFlaky')\n",
    "    os.makedirs(flakyDir, exist_ok=True)\n",
    "    os.makedirs(nonFlakyDir, exist_ok=True)\n",
    "    \n",
    "    extract_zip(flakyZip, flakyDir)\n",
    "    extract_zip(nonFlakyZip, nonFlakyDir)\n",
    "\n",
    "    dataPointsFlaky = getDataPoints(flakyDir)\n",
    "    dataPointsNonFlaky = getDataPoints(nonFlakyDir)\n",
    "    dataPoints = dataPointsFlaky + dataPointsNonFlaky\n",
    "\n",
    "    print(f\"Number of flaky documents: {len(dataPointsFlaky)}\")\n",
    "    print(f\"Number of non-flaky documents: {len(dataPointsNonFlaky)}\")\n",
    "    print(f\"Total number of documents: {len(dataPoints)}\")\n",
    "    \n",
    "    if len(dataPoints) == 0:\n",
    "        raise ValueError(\"No documents available for vectorization. Please check the input directories.\")\n",
    "\n",
    "    # Vectorization\n",
    "    Z = flastVectorization(dataPoints, dim=dim, eps=eps)\n",
    "    dataLabelsList = np.array([1]*len(dataPointsFlaky) + [0]*len(dataPointsNonFlaky))\n",
    "    vecTime = time.perf_counter() - v0\n",
    "\n",
    "    # Define StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize storage for metrics per fold and threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_per_combination = []\n",
    "\n",
    "    # Manually iterate over all combinations of hyperparameters\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Convert params from tuple to dictionary\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {param_dict}\")\n",
    "        \n",
    "        # Initialize MultinomialNB with current hyperparameter combination\n",
    "        nb_model = MultinomialNB(\n",
    "            alpha=param_dict['alpha']\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(Z, dataLabelsList)):\n",
    "            X_train, X_test = Z[train_index], Z[test_index]\n",
    "            y_train, y_test = dataLabelsList[train_index], dataLabelsList[test_index]\n",
    "\n",
    "            if sum(y_train) == 0 or sum(y_test) == 0:\n",
    "                print(f\"Skipping fold {fold+1} due to no positive samples in train or test set\")\n",
    "                continue\n",
    "\n",
    "            # Train the model\n",
    "            nb_model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict probabilities on test set\n",
    "            y_pred_proba = nb_model.predict_proba(X_test)\n",
    "\n",
    "            # Calculate metrics for each threshold\n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "                # Calculate metrics for this threshold\n",
    "                f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "                metrics_per_combination.append({\n",
    "                    'alpha': param_dict['alpha'],\n",
    "                    'fold': fold + 1,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1,\n",
    "                    'mcc': mcc\n",
    "                })\n",
    "\n",
    "    if len(metrics_per_combination) == 0:\n",
    "        print(\"No valid folds. Exiting.\")\n",
    "        return param_dict, None\n",
    "\n",
    "    # Save the results for each combination, threshold, and fold\n",
    "    df_results = pd.DataFrame(metrics_per_combination)\n",
    "    outFile = f\"{combination_label}-params-nb-{n_splits}-folds-Threshold-allKfold-wogridsearch.csv\"\n",
    "    df_results.to_csv(os.path.join(outDir, outFile), index=False)\n",
    "\n",
    "    print(f\"Naive Bayes analysis completed. Results saved to: {outFile}\")\n",
    "    return param_dict, df_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0],  # Additive smoothing parameter\n",
    "    }\n",
    "\n",
    "    # Parameters setup for the first combination\n",
    "    flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "    nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "    largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "    # Create separate result directories for equal and larger non-flaky combinations\n",
    "    outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "    outDirLarger = \"results/larger_nonflaky/\"\n",
    "    os.makedirs(outDirEqual, exist_ok=True)\n",
    "    os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "    # Create separate extract directories for each combination to avoid file confusion\n",
    "    extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "    extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "    os.makedirs(extractDirEqual, exist_ok=True)\n",
    "    os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "    # Perform Naive Bayes analysis for the first combination (flaky vs smaller non-flaky)\n",
    "    print(\"Starting Naive Bayes analysis for flaky vs smaller non-flaky files (47 each)...\")\n",
    "    best_params_5folds_1, df_results_5folds_1 = flastThreshold(\n",
    "        outDirEqual, flakyZip, nonFlakyZip, extractDirEqual, 5, dim=100, eps=0.3, combination_label=\"equal\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on equal combination:\")\n",
    "    print(df_results_5folds_1)\n",
    "\n",
    "    # Perform Naive Bayes analysis for the second combination (flaky vs larger non-flaky)\n",
    "    print(\"Starting Naive Bayes analysis for flaky vs larger non-flaky files...\")\n",
    "    best_params_5folds_2, df_results_5folds_2 = flastThreshold(\n",
    "        outDirLarger, flakyZip, largerNonFlakyZip, extractDirLarger, 5, dim=100, eps=0.3, combination_label=\"larger\", param_grid=param_grid)\n",
    "    \n",
    "    print(\"Best results for 5-fold on larger combination:\")\n",
    "    print(df_results_5folds_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bb0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
