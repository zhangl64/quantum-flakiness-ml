{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a42537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flaky documents (equal combination): 45\n",
      "Number of non-flaky documents (equal combination): 45\n",
      "Total number of documents (equal combination): 90\n",
      "************SAHPE od DATA: (90, 7563)\n",
      "Number of flaky documents (larger combination): 45\n",
      "Number of non-flaky documents (larger combination): 254\n",
      "Total number of documents (larger combination): 299\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score, f1_score,matthews_corrcoef, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "###############################################################################\n",
    "# Utility functions\n",
    "\n",
    "def extract_zip(zip_file, extract_to):\n",
    "    \"\"\"Extracts a zip file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def getDataPoints(path):\n",
    "    \"\"\"Collects content of all .py files within the given directory.\"\"\"\n",
    "    dataPointsList = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "        return dataPointsList\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for dataPointName in files:\n",
    "            if dataPointName.endswith(\".py\"):  # Only consider Python files\n",
    "                file_path = os.path.join(root, dataPointName)\n",
    "                with open(file_path, encoding=\"utf-8\") as fileIn:\n",
    "                    dp = fileIn.read().strip()\n",
    "                    if dp:  # Ensure the document is not empty\n",
    "                        dataPointsList.append(dp)\n",
    "                    else:\n",
    "                        print(f\"Empty file: {file_path}\")\n",
    "    \n",
    "    if len(dataPointsList) == 0:\n",
    "        print(f\"No valid documents found in directory: {path}\")\n",
    "    \n",
    "    return dataPointsList\n",
    "\n",
    "def flastVectorization(dataPoints):\n",
    "    \"\"\"Performs vectorization using CountVectorizer.\"\"\"\n",
    "    countVec = CountVectorizer(stop_words=None)  # No stop word removal\n",
    "    Z = countVec.fit_transform(dataPoints)\n",
    "    return Z\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Data Extraction and Vectorization\n",
    "\n",
    "# Parameters setup\n",
    "flakyZip = \"compressedDataset/flaky_files.zip\"\n",
    "nonFlakyZip = \"compressedDataset/reduced_nonflaky_files.zip\"\n",
    "largerNonFlakyZip = \"compressedDataset/all_nonflaky_files.zip\"\n",
    "\n",
    "# Create directories\n",
    "outDirEqual = \"results/equal_flaky_nonflaky/\"\n",
    "outDirLarger = \"results/larger_nonflaky/\"\n",
    "os.makedirs(outDirEqual, exist_ok=True)\n",
    "os.makedirs(outDirLarger, exist_ok=True)\n",
    "\n",
    "extractDirEqual = \"extracted/equal_flaky_nonflaky/\"\n",
    "extractDirLarger = \"extracted/larger_nonflaky/\"\n",
    "os.makedirs(extractDirEqual, exist_ok=True)\n",
    "os.makedirs(extractDirLarger, exist_ok=True)\n",
    "\n",
    "# Extract and read data once for equal combination\n",
    "flakyDirEqual = os.path.join(extractDirEqual, 'flaky')\n",
    "nonFlakyDirEqual = os.path.join(extractDirEqual, 'nonFlaky')\n",
    "os.makedirs(flakyDirEqual, exist_ok=True)\n",
    "os.makedirs(nonFlakyDirEqual, exist_ok=True)\n",
    "\n",
    "extract_zip(flakyZip, flakyDirEqual)\n",
    "extract_zip(nonFlakyZip, nonFlakyDirEqual)\n",
    "\n",
    "dataPointsFlakyEqual = getDataPoints(flakyDirEqual)\n",
    "dataPointsNonFlakyEqual = getDataPoints(nonFlakyDirEqual)\n",
    "dataPointsEqual = dataPointsFlakyEqual + dataPointsNonFlakyEqual\n",
    "\n",
    "# Print the number of datasets for equal combination\n",
    "print(f\"Number of flaky documents (equal combination): {len(dataPointsFlakyEqual)}\")\n",
    "print(f\"Number of non-flaky documents (equal combination): {len(dataPointsNonFlakyEqual)}\")\n",
    "print(f\"Total number of documents (equal combination): {len(dataPointsEqual)}\")\n",
    "\n",
    "dataLabelsListEqual = np.array([1]*len(dataPointsFlakyEqual) + [0]*len(dataPointsNonFlakyEqual))\n",
    "\n",
    "# Vectorize data once\n",
    "Z_equal = flastVectorization(dataPointsEqual)\n",
    "\n",
    "print(\"************SAHPE od DATA:\", Z_equal.shape)\n",
    "### After the split, PCA should happen\n",
    "### MCC -> make sure way score weighted\n",
    "\n",
    "# Extract and read data once for larger non-flaky combination\n",
    "flakyDirLarger = os.path.join(extractDirLarger, 'flaky')\n",
    "nonFlakyDirLarger = os.path.join(extractDirLarger, 'nonFlaky')\n",
    "os.makedirs(flakyDirLarger, exist_ok=True)\n",
    "os.makedirs(nonFlakyDirLarger, exist_ok=True)\n",
    "\n",
    "extract_zip(flakyZip, flakyDirLarger)\n",
    "extract_zip(largerNonFlakyZip, nonFlakyDirLarger)\n",
    "\n",
    "dataPointsFlakyLarger = getDataPoints(flakyDirLarger)\n",
    "dataPointsNonFlakyLarger = getDataPoints(nonFlakyDirLarger)\n",
    "dataPointsLarger = dataPointsFlakyLarger + dataPointsNonFlakyLarger\n",
    "\n",
    "# Print the number of datasets for larger combination\n",
    "print(f\"Number of flaky documents (larger combination): {len(dataPointsFlakyLarger)}\")\n",
    "print(f\"Number of non-flaky documents (larger combination): {len(dataPointsNonFlakyLarger)}\")\n",
    "print(f\"Total number of documents (larger combination): {len(dataPointsLarger)}\")\n",
    "\n",
    "dataLabelsListLarger = np.array([1]*len(dataPointsFlakyLarger) + [0]*len(dataPointsNonFlakyLarger))\n",
    "\n",
    "Z_larger = flastVectorization(dataPointsLarger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304d035",
   "metadata": {},
   "source": [
    "## KNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "540d06d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting KNN analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "90\n",
      "[18, 36, 54, 72, 90]\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "280 fits failed out of a total of 700.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "140 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 731, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=72 must be strictly less than min(n_samples, n_features)=72 with svd_solver='arpack'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "140 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 724, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=90 must be between 1 and min(n_samples, n_features)=72 with svd_solver='arpack'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.71333333 0.74       0.68785714        nan        nan 0.74555556\n",
      " 0.78222222 0.73285714        nan        nan 0.78142857 0.80833333\n",
      " 0.8247619         nan        nan 0.80577201 0.80396825 0.81666667\n",
      "        nan        nan 0.75666667 0.76507937 0.75              nan\n",
      "        nan 0.80222222 0.80396825 0.81666667        nan        nan\n",
      " 0.81666667 0.76428571 0.75619048        nan        nan 0.79666667\n",
      " 0.76       0.79285714        nan        nan 0.78055556 0.75833333\n",
      " 0.79333333        nan        nan 0.82666667 0.76       0.81666667\n",
      "        nan        nan 0.86666667 0.75333333 0.69166667        nan\n",
      "        nan 0.80142857 0.79545455 0.78333333        nan        nan\n",
      " 0.85833333 0.925      0.91428571        nan        nan 0.83333333\n",
      " 0.80555556 0.79722222        nan        nan 0.80952381 0.84188312\n",
      " 0.86              nan        nan 0.82571429 0.84642857 0.87878788\n",
      "        nan        nan 0.79777778 0.80142857 0.8984127         nan\n",
      "        nan 0.81555556 0.82233766 0.90555556        nan        nan\n",
      " 0.66928571 0.8297619  0.90952381        nan        nan 0.72031746\n",
      " 0.85920635 0.92698413        nan        nan 0.71833333 0.89333333\n",
      " 0.82666667        nan        nan 0.74142857 0.89365079 0.86666667\n",
      "        nan        nan 0.88       0.86666667 0.92666667        nan\n",
      "        nan 0.85       0.86031746 0.91666667        nan        nan\n",
      " 0.79333333 0.86       0.9               nan        nan 0.85\n",
      " 0.88095238 0.90952381        nan        nan 0.93333333 0.85\n",
      " 0.9               nan        nan 0.87666667 0.9047619  0.96\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.82771284 0.82725654 0.83628004        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.83045571 0.8441831\n",
      " 0.86378828        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.80616607 0.83205895 0.81687765        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.82060061 0.84178259 0.81884712        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.83409252 0.81824802\n",
      " 0.8083784         nan        nan 1.         1.         1.\n",
      "        nan        nan 0.78866411 0.79574194 0.77609787        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.80384615 0.80727318 0.80028233        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.88732211 0.91269417\n",
      " 0.91925847        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.87375085 0.91406763 0.90075228        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.8226455  0.87646541 0.8887045         nan        nan 1.\n",
      " 1.         1.                nan        nan 0.86325251 0.8825091\n",
      " 0.92929388        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.89361675 0.8899704  0.91328342        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.88459893 0.89873615 0.90984962        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.90861345 0.92357257\n",
      " 0.92181818        nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.55555556 0.6        0.53333333        nan        nan 0.64444444\n",
      " 0.68888889 0.6               nan        nan 0.57777778 0.48888889\n",
      " 0.44444444        nan        nan 0.66666667 0.6        0.55555556\n",
      "        nan        nan 0.55555556 0.51111111 0.42222222        nan\n",
      "        nan 0.64444444 0.62222222 0.57777778        nan        nan\n",
      " 0.53333333 0.51111111 0.4               nan        nan 0.62222222\n",
      " 0.62222222 0.55555556        nan        nan 0.53333333 0.53333333\n",
      " 0.44444444        nan        nan 0.62222222 0.6        0.55555556\n",
      "        nan        nan 0.57777778 0.57777778 0.46666667        nan\n",
      "        nan 0.64444444 0.62222222 0.57777778        nan        nan\n",
      " 0.42222222 0.48888889 0.4               nan        nan 0.57777778\n",
      " 0.6        0.57777778        nan        nan 0.55555556 0.6\n",
      " 0.48888889        nan        nan 0.62222222 0.64444444 0.53333333\n",
      "        nan        nan 0.57777778 0.6        0.51111111        nan\n",
      "        nan 0.62222222 0.68888889 0.57777778        nan        nan\n",
      " 0.46666667 0.57777778 0.48888889        nan        nan 0.57777778\n",
      " 0.68888889 0.6               nan        nan 0.46666667 0.48888889\n",
      " 0.4               nan        nan 0.57777778 0.6        0.51111111\n",
      "        nan        nan 0.42222222 0.48888889 0.4               nan\n",
      "        nan 0.53333333 0.57777778 0.53333333        nan        nan\n",
      " 0.4        0.42222222 0.35555556        nan        nan 0.53333333\n",
      " 0.53333333 0.48888889        nan        nan 0.24444444 0.26666667\n",
      " 0.15555556        nan        nan 0.48888889 0.53333333 0.44444444\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.76111111 0.81666667 0.75              nan        nan 1.\n",
      " 1.         1.                nan        nan 0.70555556 0.71666667\n",
      " 0.6               nan        nan 1.         1.         1.\n",
      "        nan        nan 0.66666667 0.61666667 0.50555556        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.60555556 0.62222222 0.47222222        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.63333333 0.61666667\n",
      " 0.44444444        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.58888889 0.60555556 0.45              nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.5        0.47222222 0.47222222        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.78333333 0.86666667\n",
      " 0.80555556        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.72222222 0.75555556 0.67777778        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.63888889 0.72222222 0.58888889        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.61111111 0.60555556\n",
      " 0.57222222        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.58888889 0.57222222 0.46111111        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.52777778 0.53888889 0.38333333        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.34444444 0.37222222\n",
      " 0.25555556        nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.66666667 0.68888889 0.64444444        nan        nan 0.71111111\n",
      " 0.74444444 0.68888889        nan        nan 0.7        0.68888889\n",
      " 0.67777778        nan        nan 0.74444444 0.72222222 0.71111111\n",
      "        nan        nan 0.68888889 0.67777778 0.64444444        nan\n",
      "        nan 0.74444444 0.73333333 0.72222222        nan        nan\n",
      " 0.7        0.67777778 0.63333333        nan        nan 0.73333333\n",
      " 0.71111111 0.7               nan        nan 0.7        0.67777778\n",
      " 0.66666667        nan        nan 0.74444444 0.7        0.71111111\n",
      "        nan        nan 0.74444444 0.68888889 0.63333333        nan\n",
      "        nan 0.74444444 0.72222222 0.7               nan        nan\n",
      " 0.66666667 0.71111111 0.66666667        nan        nan 0.72222222\n",
      " 0.72222222 0.71111111        nan        nan 0.7        0.73333333\n",
      " 0.68888889        nan        nan 0.73333333 0.75555556 0.71111111\n",
      "        nan        nan 0.71111111 0.71111111 0.71111111        nan\n",
      "        nan 0.73333333 0.75555556 0.74444444        nan        nan\n",
      " 0.62222222 0.73333333 0.71111111        nan        nan 0.67777778\n",
      " 0.78888889 0.76666667        nan        nan 0.64444444 0.71111111\n",
      " 0.65555556        nan        nan 0.68888889 0.75555556 0.71111111\n",
      "        nan        nan 0.67777778 0.7        0.67777778        nan\n",
      "        nan 0.71111111 0.73333333 0.73333333        nan        nan\n",
      " 0.65555556 0.66666667 0.65555556        nan        nan 0.72222222\n",
      " 0.72222222 0.71111111        nan        nan 0.61111111 0.61111111\n",
      " 0.56666667        nan        nan 0.71111111 0.73333333 0.71111111\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.8        0.82222222 0.8               nan        nan 1.\n",
      " 1.         1.                nan        nan 0.77777778 0.79166667\n",
      " 0.75              nan        nan 1.         1.         1.\n",
      "        nan        nan 0.75       0.74444444 0.69444444        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.73611111 0.75277778 0.68611111        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.75277778 0.73888889\n",
      " 0.66944444        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.71388889 0.725      0.65833333        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.68888889 0.68055556 0.67777778        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.84166667 0.89166667\n",
      " 0.86666667        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.80833333 0.84166667 0.8               nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.75       0.80833333 0.75555556        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.75555556 0.76111111\n",
      " 0.76388889        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.75833333 0.75       0.70833333        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.72777778 0.73611111 0.66944444        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.65277778 0.66666667\n",
      " 0.61388889        nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.61568627 0.64250672 0.59001548        nan        nan 0.68410045\n",
      " 0.71896408 0.65354489        nan        nan 0.6473361  0.59444947\n",
      " 0.56831502        nan        nan 0.71507937 0.67127595 0.65085111\n",
      "        nan        nan 0.62627383 0.59674603 0.52579186        nan\n",
      "        nan 0.70302423 0.6884188  0.66799397        nan        nan\n",
      " 0.62689076 0.60557207 0.51474359        nan        nan 0.68864514\n",
      " 0.67543565 0.64397436        nan        nan 0.61242339 0.615376\n",
      " 0.54991675        nan        nan 0.69523855 0.65829279 0.65085111\n",
      "        nan        nan 0.67785714 0.63464912 0.55251885        nan\n",
      "        nan 0.70531181 0.67897436 0.65230769        nan        nan\n",
      " 0.54275528 0.6163084  0.52571429        nan        nan 0.66967464\n",
      " 0.67452991 0.65884364        nan        nan 0.64       0.66701357\n",
      " 0.59901677        nan        nan 0.69544534 0.70151907 0.63260073\n",
      "        nan        nan 0.65323565 0.66012146 0.61921689        nan\n",
      "        nan 0.68705353 0.72714286 0.68244631        nan        nan\n",
      " 0.54209761 0.66540616 0.61677489        nan        nan 0.6331746\n",
      " 0.74850652 0.7084127         nan        nan 0.5601379  0.62380952\n",
      " 0.53047619        nan        nan 0.64355742 0.69888889 0.63275156\n",
      "        nan        nan 0.55844156 0.61619048 0.53377289        nan\n",
      "        nan 0.64117647 0.67222222 0.65758673        nan        nan\n",
      " 0.52556777 0.53714286 0.49054945        nan        nan 0.65230769\n",
      " 0.65119048 0.61413753        nan        nan 0.34952381 0.39174825\n",
      " 0.23944056        nan        nan 0.62564103 0.65952381 0.5958042\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.79219046 0.82150893 0.78959045        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.7607997  0.77485573\n",
      " 0.70436663        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.72725313 0.70568371 0.6183973         nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.69536008 0.71447615 0.59316783        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.71868922 0.70213168\n",
      " 0.57097472        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.67309841 0.68657634 0.56743385        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.61548546 0.59453563 0.59355299        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.83182491 0.88882775\n",
      " 0.85801998        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.78994175 0.82632964 0.76903503        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.71895743 0.78958618 0.70209505        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.71284276 0.71505751\n",
      " 0.70302161        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.70826821 0.69417514 0.60928248        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.65879881 0.66001893 0.53110654        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.49362713 0.51339831\n",
      " 0.39265964        nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************SHAPE of DATA after PCA: (90, 36)\n",
      "Best Parameters: {'knn__metric': 'euclidean', 'knn__n_neighbors': 7, 'knn__weights': 'distance', 'pca__n_components': 36}\n",
      "Best F1 Score: 0.7485065227170491\n",
      "KNN analysis completed for 5-folds. Results saved to: equal-params-knn-5-folds.csv\n",
      "90\n",
      "[18, 36, 54, 72, 90]\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "Fitting 3 folds for each of 140 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "168 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "84 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 724, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=72 must be between 1 and min(n_samples, n_features)=60 with svd_solver='arpack'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "84 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 724, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=90 must be between 1 and min(n_samples, n_features)=60 with svd_solver='arpack'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.69674688 0.65857672 0.7027417         nan        nan 0.70039683\n",
      " 0.67243867 0.74494949        nan        nan 0.66323872 0.73439153\n",
      " 0.74404762        nan        nan 0.70923521 0.71587302 0.73747086\n",
      "        nan        nan 0.70196078 0.7037037  0.69642857        nan\n",
      "        nan 0.77700078 0.75135975 0.76723277        nan        nan\n",
      " 0.76147186 0.76719577 0.75              nan        nan 0.77705628\n",
      " 0.79177489 0.80477855        nan        nan 0.71767677 0.72525253\n",
      " 0.75555556        nan        nan 0.77272727 0.81818182 0.82575758\n",
      "        nan        nan 0.71693122 0.7797619  0.7797619         nan\n",
      "        nan 0.77056277 0.79112554 0.81969697        nan        nan\n",
      " 0.75198413 0.85714286 0.875             nan        nan 0.76147186\n",
      " 0.83116883 0.83080808        nan        nan 0.77189477 0.82777778\n",
      " 0.82407407        nan        nan 0.75396825 0.83205128 0.83048433\n",
      "        nan        nan 0.68492063 0.75883838 0.83333333        nan\n",
      "        nan 0.70598291 0.76816239 0.84444444        nan        nan\n",
      " 0.72402597 0.84497354 0.91666667        nan        nan 0.75193325\n",
      " 0.8505291  0.89469697        nan        nan 0.76161616 0.87037037\n",
      " 0.84867725        nan        nan 0.79444444 0.88636364 0.87407407\n",
      "        nan        nan 0.76851852 0.88571429 0.8968254         nan\n",
      "        nan 0.81666667 0.91534392 0.87830688        nan        nan\n",
      " 0.76666667 0.86666667 0.88888889        nan        nan 0.85541126\n",
      " 0.89166667 0.91666667        nan        nan 0.78571429 0.85714286\n",
      " 0.86666667        nan        nan 0.8        0.82575758 0.91666667\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.82563582 0.84053093 0.84563153        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.80700855 0.85690236\n",
      " 0.85042735        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.81190093 0.80814815 0.78333333        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.79230769 0.83731765 0.82222222        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.75188406 0.80988917\n",
      " 0.82044997        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.77156177 0.7611532  0.77760057        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.79692696 0.83105742 0.8379085         nan        nan 1.\n",
      " 1.         1.                nan        nan 0.85300979 0.9389868\n",
      " 0.97              nan        nan 1.         1.         1.\n",
      "        nan        nan 0.83615137 0.89824561 0.92806268        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.85454545 0.90215311 0.90701891        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.8379892  0.92854031\n",
      " 0.89444444        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.87295534 0.94074074 0.86491228        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.89810625 0.96078431 0.95833333        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.94871795 0.94871795\n",
      " 0.94444444        nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.66666667 0.6        0.53333333        nan        nan 0.64444444\n",
      " 0.6        0.53333333        nan        nan 0.6        0.53333333\n",
      " 0.44444444        nan        nan 0.62222222 0.57777778 0.53333333\n",
      "        nan        nan 0.57777778 0.53333333 0.46666667        nan\n",
      "        nan 0.62222222 0.55555556 0.53333333        nan        nan\n",
      " 0.6        0.55555556 0.48888889        nan        nan 0.62222222\n",
      " 0.62222222 0.57777778        nan        nan 0.53333333 0.48888889\n",
      " 0.48888889        nan        nan 0.55555556 0.6        0.55555556\n",
      "        nan        nan 0.53333333 0.44444444 0.44444444        nan\n",
      "        nan 0.62222222 0.53333333 0.51111111        nan        nan\n",
      " 0.46666667 0.37777778 0.42222222        nan        nan 0.6\n",
      " 0.53333333 0.53333333        nan        nan 0.64444444 0.55555556\n",
      " 0.48888889        nan        nan 0.66666667 0.57777778 0.51111111\n",
      "        nan        nan 0.62222222 0.53333333 0.46666667        nan\n",
      "        nan 0.64444444 0.57777778 0.51111111        nan        nan\n",
      " 0.53333333 0.62222222 0.51111111        nan        nan 0.6\n",
      " 0.66666667 0.57777778        nan        nan 0.42222222 0.46666667\n",
      " 0.4               nan        nan 0.48888889 0.53333333 0.48888889\n",
      "        nan        nan 0.42222222 0.37777778 0.4               nan\n",
      "        nan 0.48888889 0.48888889 0.48888889        nan        nan\n",
      " 0.4        0.33333333 0.26666667        nan        nan 0.53333333\n",
      " 0.42222222 0.33333333        nan        nan 0.22222222 0.2\n",
      " 0.17777778        nan        nan 0.44444444 0.44444444 0.37777778\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.81111111 0.81111111 0.67777778        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.72222222 0.67777778\n",
      " 0.53333333        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.7        0.6        0.47777778        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.67777778 0.61111111 0.5               nan        nan 1.\n",
      " 1.         1.                nan        nan 0.61111111 0.51111111\n",
      " 0.48888889        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.6        0.47777778 0.51111111        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.47777778 0.43333333 0.45555556        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.76666667 0.84444444\n",
      " 0.72222222        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.68888889 0.68888889 0.56666667        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.63333333 0.61111111 0.53333333        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.6        0.56666667\n",
      " 0.46666667        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.57777778 0.42222222 0.42222222        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.47777778 0.38888889 0.3               nan        nan 1.\n",
      " 1.         1.                nan        nan 0.27777778 0.24444444\n",
      " 0.22222222        nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.67777778 0.64444444 0.65555556        nan        nan 0.67777778\n",
      " 0.65555556 0.67777778        nan        nan 0.64444444 0.66666667\n",
      " 0.64444444        nan        nan 0.67777778 0.67777778 0.67777778\n",
      "        nan        nan 0.66666667 0.65555556 0.63333333        nan\n",
      "        nan 0.72222222 0.68888889 0.68888889        nan        nan\n",
      " 0.71111111 0.7        0.66666667        nan        nan 0.72222222\n",
      " 0.73333333 0.72222222        nan        nan 0.66666667 0.65555556\n",
      " 0.66666667        nan        nan 0.7        0.73333333 0.72222222\n",
      "        nan        nan 0.67777778 0.66666667 0.66666667        nan\n",
      "        nan 0.72222222 0.7        0.7               nan        nan\n",
      " 0.66666667 0.65555556 0.67777778        nan        nan 0.71111111\n",
      " 0.71111111 0.71111111        nan        nan 0.72222222 0.72222222\n",
      " 0.68888889        nan        nan 0.72222222 0.73333333 0.7\n",
      "        nan        nan 0.66666667 0.68888889 0.68888889        nan\n",
      "        nan 0.68888889 0.71111111 0.71111111        nan        nan\n",
      " 0.66666667 0.75555556 0.73333333        nan        nan 0.7\n",
      " 0.77777778 0.75555556        nan        nan 0.64444444 0.7\n",
      " 0.66666667        nan        nan 0.67777778 0.73333333 0.71111111\n",
      "        nan        nan 0.65555556 0.66666667 0.67777778        nan\n",
      "        nan 0.68888889 0.72222222 0.71111111        nan        nan\n",
      " 0.64444444 0.64444444 0.61111111        nan        nan 0.72222222\n",
      " 0.68888889 0.64444444        nan        nan 0.56666667 0.56666667\n",
      " 0.56666667        nan        nan 0.66666667 0.67777778 0.66666667\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.81666667 0.82777778 0.77222222        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.77222222 0.78333333\n",
      " 0.72222222        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.76666667 0.72222222 0.67222222        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.75       0.74444444 0.69444444        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.70555556 0.69444444\n",
      " 0.68888889        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.71111111 0.66666667 0.68333333        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.67777778 0.67222222 0.68333333        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.81666667 0.89444444\n",
      " 0.85              nan        nan 1.         1.         1.\n",
      "        nan        nan 0.77777778 0.80555556 0.76111111        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.76111111 0.77222222 0.73888889        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.73888889 0.76111111\n",
      " 0.70555556        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.74444444 0.69444444 0.67777778        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.71111111 0.68333333 0.63888889        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.62777778 0.61111111\n",
      " 0.6               nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.67498966 0.62293956 0.60167993        nan        nan 0.6688639\n",
      " 0.63159446 0.61965812        nan        nan 0.62477106 0.61210728\n",
      " 0.54896794        nan        nan 0.659888   0.63679864 0.61379201\n",
      "        nan        nan 0.62333333 0.59888889 0.54872564        nan\n",
      "        nan 0.69020486 0.63553114 0.62037962        nan        nan\n",
      " 0.66765694 0.63697318 0.58749329        nan        nan 0.688771\n",
      " 0.69329797 0.66658704        nan        nan 0.61109212 0.58307692\n",
      " 0.59333333        nan        nan 0.64434948 0.69230769 0.66109253\n",
      "        nan        nan 0.60440613 0.56310935 0.56310935        nan\n",
      "        nan 0.68611848 0.63014763 0.61196581        nan        nan\n",
      " 0.56804763 0.511563   0.55194508        nan        nan 0.66765694\n",
      " 0.64335664 0.63736264        nan        nan 0.70058103 0.66082662\n",
      " 0.6031746         nan        nan 0.7066837  0.67581781 0.61904762\n",
      "        nan        nan 0.65057471 0.62261035 0.58666667        nan\n",
      "        nan 0.67301587 0.65374588 0.62024691        nan        nan\n",
      " 0.60627379 0.71030651 0.6557971         nan        nan 0.66160372\n",
      " 0.74191145 0.69930881        nan        nan 0.53076923 0.6031746\n",
      " 0.53737374        nan        nan 0.59428571 0.66220736 0.62095238\n",
      "        nan        nan 0.51851852 0.52727273 0.55266955        nan\n",
      "        nan 0.59555556 0.63592446 0.62626263        nan        nan\n",
      " 0.50723104 0.47878788 0.39589169        nan        nan 0.65156177\n",
      " 0.56811594 0.46446563        nan        nan 0.31872294 0.30322967\n",
      " 0.28201754        nan        nan 0.56       0.56039136 0.50234442\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.8158293  0.82539775 0.74915622        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.76111111 0.75506073\n",
      " 0.64417989        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.75046323 0.68459596 0.58690284        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.73051948 0.70351474 0.61524423        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.67398513 0.62357821\n",
      " 0.6036921         nan        nan 1.         1.         1.\n",
      "        nan        nan 0.67399267 0.58463397 0.61568987        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.59710764 0.56880554 0.58975571        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.80683012 0.8883915\n",
      " 0.82629371        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.7544963  0.77674706 0.69376256        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.72601399 0.72797488 0.66467899        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.69605442 0.70306147\n",
      " 0.60719577        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.69353528 0.56998051 0.55907029        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.62103469 0.54609929 0.44013579        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.41962688 0.36605546\n",
      " 0.3407477         nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************SHAPE of DATA after PCA: (90, 36)\n",
      "Best Parameters: {'knn__metric': 'euclidean', 'knn__n_neighbors': 7, 'knn__weights': 'distance', 'pca__n_components': 36}\n",
      "Best F1 Score: 0.7419114516815667\n",
      "KNN analysis completed for 3-folds. Results saved to: equal-params-knn-3-folds.csv\n",
      "\n",
      "Best results for KNN 5-fold on equal combination:\n",
      "Best Parameters: {'knn__metric': 'euclidean', 'knn__n_neighbors': 7, 'knn__weights': 'distance', 'pca__n_components': 36}\n",
      "Best F1 Score: 0.7485065227170491\n",
      "\n",
      "Best results for KNN 3-fold on equal combination:\n",
      "Best Parameters: {'knn__metric': 'euclidean', 'knn__n_neighbors': 7, 'knn__weights': 'distance', 'pca__n_components': 36}\n",
      "Best F1 Score: 0.7419114516815667\n",
      "\n",
      "Starting KNN analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "299\n",
      "[60, 120, 180, 240, 300]\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "140 fits failed out of a total of 700.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "112 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 724, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=295 must be between 1 and min(n_samples, n_features)=239 with svd_solver='arpack'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 724, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=295 must be between 1 and min(n_samples, n_features)=240 with svd_solver='arpack'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.59424242 0.67090909 0.66       0.69333333        nan 0.72825397\n",
      " 0.83333333 0.84       0.84              nan 0.62       0.7\n",
      " 0.66666667 0.73333333        nan 0.79095238 0.82       0.87\n",
      " 0.87              nan 0.78333333 0.83333333 0.8        0.8\n",
      "        nan 0.84285714 0.85       0.88333333 0.88333333        nan\n",
      " 0.83333333 0.8        0.8        0.8               nan 0.84285714\n",
      " 0.85       0.93333333 0.93333333        nan 0.9        1.\n",
      " 1.         1.                nan 0.9        0.93333333 0.9\n",
      " 1.                nan 0.9        1.         1.         1.\n",
      "        nan 0.96       1.         1.         1.                nan\n",
      " 1.         1.         1.         1.                nan 1.\n",
      " 1.         1.         1.                nan 0.65833333 0.38888889\n",
      " 0.71428571 0.74761905        nan 0.71428571 0.56761905 0.89333333\n",
      " 0.89333333        nan 0.71666667 0.76666667 0.83333333 0.83333333\n",
      "        nan 0.72761905 0.83333333 1.         1.                nan\n",
      " 0.61666667 0.9        0.8        0.8               nan 0.78666667\n",
      " 1.         1.         1.                nan 0.77       0.8\n",
      " 0.8        0.8               nan 0.88333333 1.         1.\n",
      " 1.                nan 0.93333333 0.8        0.8        0.8\n",
      "        nan 0.93333333 1.         1.         1.                nan\n",
      " 1.         1.         1.         1.                nan 1.\n",
      " 1.         1.         1.                nan 1.         1.\n",
      " 1.         1.                nan 1.         1.         1.\n",
      " 1.                nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.84391151 0.93175155 0.91747412 0.90200264        nan 1.\n",
      " 1.         1.         1.                nan 0.90467965 0.91308768\n",
      " 0.85443153 0.85538391        nan 1.         1.         1.\n",
      " 1.                nan 0.89860623 0.95424837 0.9447619  0.94559524\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.88627451 0.95746606 0.94461538 0.94825175        nan 1.\n",
      " 1.         1.         1.                nan 0.90028011 1.\n",
      " 1.         1.                nan 1.         1.         1.\n",
      " 1.                nan 0.975      1.         1.         1.\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 1.         1.         1.         1.                nan 1.\n",
      " 1.         1.         1.                nan 0.84667495 0.92160267\n",
      " 0.91936508 0.91994987        nan 1.         1.         1.\n",
      " 1.                nan 0.89399711 0.94248366 0.94380952 0.94380952\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.86574675 0.95892857 0.90515873 0.91050061        nan 1.\n",
      " 1.         1.         1.                nan 0.82470588 0.89888889\n",
      " 0.82888889 0.84555556        nan 1.         1.         1.\n",
      " 1.                nan 0.86030303 0.875      0.895      0.895\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.91666667 1.         1.         1.                nan 1.\n",
      " 1.         1.         1.                nan 1.         1.\n",
      " 1.         1.                nan 1.         1.         1.\n",
      " 1.                nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.37777778 0.42222222 0.31111111 0.33333333        nan 0.51111111\n",
      " 0.51111111 0.42222222 0.42222222        nan 0.28888889 0.28888889\n",
      " 0.24444444 0.28888889        nan 0.46666667 0.44444444 0.44444444\n",
      " 0.44444444        nan 0.31111111 0.26666667 0.22222222 0.22222222\n",
      "        nan 0.44444444 0.4        0.4        0.4               nan\n",
      " 0.24444444 0.17777778 0.17777778 0.17777778        nan 0.4\n",
      " 0.4        0.4        0.4               nan 0.15555556 0.08888889\n",
      " 0.08888889 0.08888889        nan 0.4        0.33333333 0.26666667\n",
      " 0.26666667        nan 0.11111111 0.04444444 0.02222222 0.02222222\n",
      "        nan 0.35555556 0.22222222 0.2        0.2               nan\n",
      " 0.         0.         0.         0.                nan 0.24444444\n",
      " 0.2        0.17777778 0.17777778        nan 0.33333333 0.2\n",
      " 0.17777778 0.2               nan 0.42222222 0.31111111 0.31111111\n",
      " 0.33333333        nan 0.26666667 0.22222222 0.17777778 0.17777778\n",
      "        nan 0.35555556 0.33333333 0.31111111 0.31111111        nan\n",
      " 0.22222222 0.11111111 0.11111111 0.11111111        nan 0.31111111\n",
      " 0.22222222 0.24444444 0.24444444        nan 0.2        0.06666667\n",
      " 0.06666667 0.06666667        nan 0.35555556 0.2        0.2\n",
      " 0.2               nan 0.11111111 0.04444444 0.04444444 0.08888889\n",
      "        nan 0.28888889 0.17777778 0.17777778 0.22222222        nan\n",
      " 0.08888889 0.06666667 0.08888889 0.08888889        nan 0.24444444\n",
      " 0.2        0.22222222 0.22222222        nan 0.         0.\n",
      " 0.         0.                nan 0.2        0.13333333 0.13333333\n",
      " 0.13333333        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.65       0.60555556 0.54444444 0.54444444        nan 1.\n",
      " 1.         1.         1.                nan 0.57222222 0.48333333\n",
      " 0.41111111 0.41666667        nan 1.         1.         1.\n",
      " 1.                nan 0.43333333 0.37777778 0.31666667 0.32222222\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.36666667 0.29444444 0.22777778 0.23333333        nan 1.\n",
      " 1.         1.         1.                nan 0.3        0.18888889\n",
      " 0.17777778 0.18888889        nan 1.         1.         1.\n",
      " 1.                nan 0.17222222 0.10555556 0.08333333 0.08333333\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.06666667 0.03333333 0.03888889 0.03888889        nan 1.\n",
      " 1.         1.         1.                nan 0.61111111 0.55555556\n",
      " 0.48333333 0.48888889        nan 1.         1.         1.\n",
      " 1.                nan 0.45555556 0.38888889 0.30555556 0.31111111\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.37222222 0.28888889 0.24444444 0.25555556        nan 1.\n",
      " 1.         1.         1.                nan 0.31666667 0.15555556\n",
      " 0.14444444 0.15              nan 1.         1.         1.\n",
      " 1.                nan 0.23888889 0.09444444 0.10555556 0.11666667\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.13333333 0.07777778 0.08888889 0.08888889        nan 1.\n",
      " 1.         1.         1.                nan 0.05555556 0.\n",
      " 0.         0.                nan 1.         1.         1.\n",
      " 1.                nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.85960452 0.87621469 0.87288136 0.87621469        nan 0.89288136\n",
      " 0.90293785 0.89954802 0.89954802        nan 0.86621469 0.87615819\n",
      " 0.86949153 0.87621469        nan 0.89960452 0.89954802 0.90621469\n",
      " 0.90621469        nan 0.88293785 0.88288136 0.87954802 0.87954802\n",
      "        nan 0.89966102 0.89960452 0.90293785 0.90293785        nan\n",
      " 0.87627119 0.87288136 0.87288136 0.87288136        nan 0.89299435\n",
      " 0.89960452 0.90632768 0.90632768        nan 0.86949153 0.86282486\n",
      " 0.86282486 0.86282486        nan 0.89966102 0.89632768 0.88627119\n",
      " 0.88960452        nan 0.86282486 0.85615819 0.85282486 0.85282486\n",
      "        nan 0.89966102 0.88288136 0.87954802 0.87954802        nan\n",
      " 0.84949153 0.84949153 0.84949153 0.84949153        nan 0.88621469\n",
      " 0.87954802 0.87621469 0.87621469        nan 0.86288136 0.83937853\n",
      " 0.85949153 0.86282486        nan 0.88293785 0.86610169 0.88954802\n",
      " 0.89288136        nan 0.86960452 0.87282486 0.86960452 0.86960452\n",
      "        nan 0.87966102 0.88954802 0.89632768 0.89632768        nan\n",
      " 0.86282486 0.86282486 0.86288136 0.86288136        nan 0.88293785\n",
      " 0.88288136 0.88627119 0.88627119        nan 0.86615819 0.85615819\n",
      " 0.85615819 0.85615819        nan 0.89293785 0.87954802 0.87954802\n",
      " 0.87954802        nan 0.86282486 0.85282486 0.85282486 0.85949153\n",
      "        nan 0.88954802 0.87621469 0.87621469 0.88288136        nan\n",
      " 0.86282486 0.85949153 0.86282486 0.86282486        nan 0.88621469\n",
      " 0.87954802 0.88288136 0.88288136        nan 0.84949153 0.84949153\n",
      " 0.84949153 0.84949153        nan 0.87954802 0.86954802 0.86954802\n",
      " 0.86954802        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.92891562 0.93394003 0.92390865 0.92223501        nan 1.\n",
      " 1.         1.         1.                nan 0.92641911 0.91471409\n",
      " 0.90048815 0.90132497        nan 1.         1.         1.\n",
      " 1.                nan 0.90718271 0.90300209 0.89380404 0.89464086\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.89631799 0.8912901  0.88125523 0.88209205        nan 1.\n",
      " 1.         1.         1.                nan 0.88878661 0.87791841\n",
      " 0.87624826 0.87791492        nan 1.         1.         1.\n",
      " 1.                nan 0.87458159 0.86538006 0.86203278 0.86203278\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.85952929 0.85451534 0.85535216 0.85535216        nan 1.\n",
      " 1.         1.         1.                nan 0.92473849 0.9255788\n",
      " 0.91554045 0.91637727        nan 1.         1.         1.\n",
      " 1.                nan 0.90969317 0.90385286 0.89214784 0.89298466\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.89632497 0.89046722 0.882106   0.88377615        nan 1.\n",
      " 1.         1.         1.                nan 0.88712343 0.86956416\n",
      " 0.8670537  0.86789052        nan 1.         1.         1.\n",
      " 1.                nan 0.87875523 0.86203626 0.86287308 0.86454672\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.86705718 0.86119944 0.86287308 0.86287308        nan 1.\n",
      " 1.         1.         1.                nan 0.85785914 0.84949791\n",
      " 0.84949791 0.84949791        nan 1.         1.         1.\n",
      " 1.                nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.43880629 0.5043956  0.41736264 0.44556777        nan 0.59325397\n",
      " 0.62072103 0.56043956 0.56043956        nan 0.38725275 0.40559441\n",
      " 0.35431235 0.41282051        nan 0.58278388 0.57450549 0.58681319\n",
      " 0.58681319        nan 0.43114219 0.38918415 0.3358042  0.3358042\n",
      "        nan 0.57093407 0.54285714 0.54798535 0.54798535        nan\n",
      " 0.36121212 0.2758042  0.2758042  0.2758042         nan 0.52807692\n",
      " 0.54285714 0.55567766 0.55567766        nan 0.24909091 0.15272727\n",
      " 0.15272727 0.15272727        nan 0.54593407 0.48554779 0.4048951\n",
      " 0.40853147        nan 0.17636364 0.08       0.04       0.04\n",
      "        nan 0.51008991 0.35272727 0.32       0.32              nan\n",
      " 0.         0.         0.         0.                nan 0.38545455\n",
      " 0.32       0.29272727 0.29272727        nan 0.42368024 0.24832945\n",
      " 0.25272727 0.2830303         nan 0.52159017 0.38874459 0.4440293\n",
      " 0.46380952        nan 0.3783683  0.34242424 0.28848485 0.28848485\n",
      "        nan 0.46666667 0.46686647 0.46853147 0.46853147        nan\n",
      " 0.32354312 0.18909091 0.18545455 0.18545455        nan 0.43463203\n",
      " 0.34853147 0.39090909 0.39090909        nan 0.28711289 0.11272727\n",
      " 0.11272727 0.11272727        nan 0.48728605 0.32545455 0.32545455\n",
      " 0.32545455        nan 0.17939394 0.08       0.08       0.14\n",
      "        nan 0.42554779 0.29272727 0.29272727 0.35272727        nan\n",
      " 0.14       0.1        0.14       0.14              nan 0.38545455\n",
      " 0.31272727 0.35272727 0.35272727        nan 0.         0.\n",
      " 0.         0.                nan 0.32545455 0.21272727 0.21272727\n",
      " 0.21272727        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.73344271 0.73343414 0.68272801 0.67816927        nan 1.\n",
      " 1.         1.         1.                nan 0.70035425 0.62872561\n",
      " 0.5512365  0.55704042        nan 1.         1.         1.\n",
      " 1.                nan 0.57912707 0.53275523 0.46768064 0.47326134\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.50244925 0.43683635 0.35630489 0.36333542        nan 1.\n",
      " 1.         1.         1.                nan 0.43654088 0.30739693\n",
      " 0.2925132  0.30674245        nan 1.         1.         1.\n",
      " 1.                nan 0.28558359 0.18656728 0.15047705 0.15047705\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.12469636 0.06429587 0.07401247 0.07401247        nan 1.\n",
      " 1.         1.         1.                nan 0.70901242 0.69217384\n",
      " 0.63221087 0.63719403        nan 1.         1.         1.\n",
      " 1.                nan 0.60064295 0.54490288 0.45653722 0.46265967\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.51572986 0.43407815 0.37922367 0.393161          nan 1.\n",
      " 1.         1.         1.                nan 0.45476524 0.25396591\n",
      " 0.2400203  0.24950748        nan 1.         1.         1.\n",
      " 1.                nan 0.36817559 0.16294317 0.18168514 0.20273778\n",
      "        nan 1.         1.         1.         1.                nan\n",
      " 0.22881924 0.1387229  0.15977553 0.15977553        nan 1.\n",
      " 1.         1.         1.                nan 0.10473794 0.\n",
      " 0.         0.                nan 1.         1.         1.\n",
      " 1.                nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************SHAPE of DATA after PCA: (299, 118)\n",
      "Best Parameters: {'knn__metric': 'cosine', 'knn__n_neighbors': 3, 'knn__weights': 'distance', 'pca__n_components': 118}\n",
      "Best F1 Score: 0.6207210333526123\n",
      "KNN analysis completed for 5-folds. Results saved to: larger-params-knn-5-folds.csv\n",
      "299\n",
      "[60, 120, 180, 240, 300]\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "Fitting 3 folds for each of 140 candidates, totalling 420 fits\n",
      "************SHAPE of DATA after PCA: (299, 59)\n",
      "Best Parameters: {'knn__metric': 'cosine', 'knn__n_neighbors': 3, 'knn__weights': 'distance', 'pca__n_components': 59}\n",
      "Best F1 Score: 0.6214934490796559\n",
      "KNN analysis completed for 3-folds. Results saved to: larger-params-knn-3-folds.csv\n",
      "\n",
      "Best results for KNN 5-fold on larger combination:\n",
      "Best Parameters: {'knn__metric': 'cosine', 'knn__n_neighbors': 3, 'knn__weights': 'distance', 'pca__n_components': 118}\n",
      "Best F1 Score: 0.6207210333526123\n",
      "\n",
      "Best results for KNN 3-fold on larger combination:\n",
      "Best Parameters: {'knn__metric': 'cosine', 'knn__n_neighbors': 3, 'knn__weights': 'distance', 'pca__n_components': 59}\n",
      "Best F1 Score: 0.6214934490796559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "168 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "56 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 724, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=236 must be between 1 and min(n_samples, n_features)=199 with svd_solver='arpack'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 724, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=236 must be between 1 and min(n_samples, n_features)=200 with svd_solver='arpack'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "56 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 724, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=295 must be between 1 and min(n_samples, n_features)=199 with svd_solver='arpack'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 474, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 549, in _fit\n",
      "    return self._fit_truncated(X, n_components, xp)\n",
      "  File \"/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 724, in _fit_truncated\n",
      "    raise ValueError(\n",
      "ValueError: n_components=295 must be between 1 and min(n_samples, n_features)=200 with svd_solver='arpack'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.70138889 0.625      0.66305916        nan        nan 0.78354978\n",
      " 0.71957672 0.77272727        nan        nan 0.80952381 0.91666667\n",
      " 0.91666667        nan        nan 0.75631313 0.7979798  0.85185185\n",
      "        nan        nan 0.75925926 0.88888889 0.91666667        nan\n",
      "        nan 0.72390572 0.85185185 0.85555556        nan        nan\n",
      " 0.84722222 1.         1.                nan        nan 0.85833333\n",
      " 0.94444444 0.94444444        nan        nan 0.88888889 0.66666667\n",
      " 0.66666667        nan        nan 0.875      0.93333333 0.91666667\n",
      "        nan        nan 1.         1.         1.                nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 1.         1.         1.                nan        nan 1.\n",
      " 1.         1.                nan        nan 0.64814815 0.68333333\n",
      " 0.68809524        nan        nan 0.67045455 0.82222222 0.89166667\n",
      "        nan        nan 0.68055556 0.77777778 0.83333333        nan\n",
      "        nan 0.76388889 1.         1.                nan        nan\n",
      " 0.62962963 0.66666667 0.69444444        nan        nan 0.7962963\n",
      " 0.83333333 0.83333333        nan        nan 0.64285714 0.33333333\n",
      " 0.33333333        nan        nan 0.83333333 0.83333333 0.77777778\n",
      "        nan        nan 0.94444444 1.         1.                nan\n",
      "        nan 0.95238095 1.         1.                nan        nan\n",
      " 1.         1.         1.                nan        nan 1.\n",
      " 1.         1.                nan        nan 1.         1.\n",
      " 1.                nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.81971014 0.86967963 0.87394958        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.92046784 0.94583333\n",
      " 0.92745098        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.8956229  0.97777778 0.95238095        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.91904762 1.         1.                nan        nan 1.\n",
      " 1.         1.                nan        nan 0.91071429 0.96296296\n",
      " 0.96666667        nan        nan 1.         1.         1.\n",
      "        nan        nan 1.         1.         1.                nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 1.         1.         1.                nan        nan 1.\n",
      " 1.         1.                nan        nan 0.86287879 0.8898226\n",
      " 0.89499389        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.86959064 0.96296296 0.95238095        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.8745098  0.93939394 0.96969697        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.86111111 0.95238095\n",
      " 0.95238095        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.94444444 1.         1.                nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 1.         1.         1.                nan        nan 1.\n",
      " 1.         1.                nan        nan 1.         1.\n",
      " 1.                nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.51111111 0.4        0.35555556        nan        nan 0.53333333\n",
      " 0.42222222 0.42222222        nan        nan 0.37777778 0.33333333\n",
      " 0.33333333        nan        nan 0.46666667 0.44444444 0.44444444\n",
      "        nan        nan 0.26666667 0.26666667 0.31111111        nan\n",
      "        nan 0.42222222 0.44444444 0.46666667        nan        nan\n",
      " 0.26666667 0.11111111 0.13333333        nan        nan 0.42222222\n",
      " 0.24444444 0.26666667        nan        nan 0.15555556 0.02222222\n",
      " 0.02222222        nan        nan 0.35555556 0.2        0.2\n",
      "        nan        nan 0.06666667 0.02222222 0.02222222        nan\n",
      "        nan 0.31111111 0.15555556 0.15555556        nan        nan\n",
      " 0.02222222 0.02222222 0.02222222        nan        nan 0.2\n",
      " 0.13333333 0.13333333        nan        nan 0.33333333 0.28888889\n",
      " 0.24444444        nan        nan 0.4        0.35555556 0.33333333\n",
      "        nan        nan 0.26666667 0.15555556 0.2               nan\n",
      "        nan 0.35555556 0.24444444 0.28888889        nan        nan\n",
      " 0.2        0.11111111 0.13333333        nan        nan 0.31111111\n",
      " 0.2        0.22222222        nan        nan 0.13333333 0.02222222\n",
      " 0.02222222        nan        nan 0.22222222 0.11111111 0.11111111\n",
      "        nan        nan 0.13333333 0.02222222 0.02222222        nan\n",
      "        nan 0.24444444 0.11111111 0.11111111        nan        nan\n",
      " 0.06666667 0.04444444 0.04444444        nan        nan 0.15555556\n",
      " 0.13333333 0.13333333        nan        nan 0.         0.\n",
      " 0.                nan        nan 0.08888889 0.08888889 0.08888889\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.66666667 0.6        0.53333333        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.46666667 0.36666667\n",
      " 0.37777778        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.37777778 0.28888889 0.24444444        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.31111111 0.18888889 0.17777778        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.28888889 0.14444444\n",
      " 0.15555556        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.12222222 0.07777778 0.08888889        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.03333333 0.02222222 0.02222222        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.63333333 0.54444444\n",
      " 0.47777778        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.44444444 0.32222222 0.3               nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.35555556 0.14444444 0.2               nan        nan 1.\n",
      " 1.         1.                nan        nan 0.24444444 0.1\n",
      " 0.1               nan        nan 1.         1.         1.\n",
      "        nan        nan 0.2        0.11111111 0.11111111        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.07777778 0.04444444 0.04444444        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.01111111 0.\n",
      " 0.                nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.89292929 0.87276094 0.87612795        nan        nan 0.90292929\n",
      " 0.88279461 0.89282828        nan        nan 0.89292929 0.89622896\n",
      " 0.89622896        nan        nan 0.89626263 0.89956229 0.90622896\n",
      "        nan        nan 0.87616162 0.88619529 0.89289562        nan\n",
      "        nan 0.88956229 0.90622896 0.90956229        nan        nan\n",
      " 0.88286195 0.86619529 0.86952862        nan        nan 0.8996633\n",
      " 0.88289562 0.88626263        nan        nan 0.86952862 0.84946128\n",
      " 0.84946128        nan        nan 0.89296296 0.87622896 0.87622896\n",
      "        nan        nan 0.85949495 0.85282828 0.85282828        nan\n",
      "        nan 0.89622896 0.87289562 0.87289562        nan        nan\n",
      " 0.85282828 0.85282828 0.85282828        nan        nan 0.87956229\n",
      " 0.86952862 0.86952862        nan        nan 0.86962963 0.87282828\n",
      " 0.86952862        nan        nan 0.87962963 0.88956229 0.89292929\n",
      "        nan        nan 0.86956229 0.86619529 0.87289562        nan\n",
      "        nan 0.88299663 0.88626263 0.89296296        nan        nan\n",
      " 0.85946128 0.85619529 0.85956229        nan        nan 0.87962963\n",
      " 0.87292929 0.8762963         nan        nan 0.85282828 0.84612795\n",
      " 0.84279461        nan        nan 0.86956229 0.86286195 0.85952862\n",
      "        nan        nan 0.86616162 0.85282828 0.85282828        nan\n",
      "        nan 0.88286195 0.86619529 0.86619529        nan        nan\n",
      " 0.85949495 0.85616162 0.85616162        nan        nan 0.87286195\n",
      " 0.86952862 0.86952862        nan        nan 0.84949495 0.84949495\n",
      " 0.84949495        nan        nan 0.86286195 0.86286195 0.86286195\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.92806533 0.92640704 0.91804858        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.91302345 0.90130653\n",
      " 0.90131491        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.89963149 0.89126466 0.88291457        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.89128978 0.87788945 0.87622278        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.88792295 0.86953936\n",
      " 0.87120603        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.86786432 0.8611809  0.86284757        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.85449749 0.85283082 0.85283082        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.92974874 0.92138191\n",
      " 0.9130067         nan        nan 1.         1.         1.\n",
      "        nan        nan 0.90634003 0.89460637 0.89128978        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.89463149 0.86786432 0.87789782        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.87958124 0.86285595\n",
      " 0.86285595        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.8779062  0.86618928 0.86618928        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.86118928 0.85616415 0.85616415        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.85117253 0.84949749\n",
      " 0.84949749        nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.57713885 0.47567126 0.45476745        nan        nan 0.62149345\n",
      " 0.50766284 0.53718745        nan        nan 0.51515152 0.48405104\n",
      " 0.48405104        nan        nan 0.57469342 0.56399639 0.58109041\n",
      "        nan        nan 0.37573099 0.3973064  0.45773525        nan\n",
      "        nan 0.52655678 0.58109041 0.59886818        nan        nan\n",
      " 0.38808374 0.19852941 0.23120915        nan        nan 0.55623188\n",
      " 0.37751241 0.41019215        nan        nan 0.25609162 0.04166667\n",
      " 0.04166667        nan        nan 0.49739963 0.32287582 0.32404541\n",
      "        nan        nan 0.12009804 0.04166667 0.04166667        nan\n",
      "        nan 0.45721925 0.26797386 0.26797386        nan        nan\n",
      " 0.04166667 0.04166667 0.04166667        nan        nan 0.32989336\n",
      " 0.23120915 0.23120915        nan        nan 0.43650794 0.40248447\n",
      " 0.35677831        nan        nan 0.49832776 0.48066834 0.47658276\n",
      "        nan        nan 0.37717482 0.25925926 0.32163743        nan\n",
      "        nan 0.47826087 0.39181287 0.44736842        nan        nan\n",
      " 0.28703704 0.18954248 0.22073157        nan        nan 0.43796992\n",
      " 0.32163743 0.35087719        nan        nan 0.20855615 0.04166667\n",
      " 0.04166667        nan        nan 0.33472428 0.19199346 0.18981481\n",
      "        nan        nan 0.20039683 0.04166667 0.04166667        nan\n",
      "        nan 0.36383573 0.19444444 0.19444444        nan        nan\n",
      " 0.12009804 0.07843137 0.07843137        nan        nan 0.26388889\n",
      " 0.23120915 0.23120915        nan        nan 0.         0.\n",
      " 0.                nan        nan 0.16176471 0.16176471 0.16176471\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/gimdongchan/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.7350486  0.70898729 0.66082603        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.6143613  0.52123746\n",
      " 0.52943262        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.52157598 0.42877163 0.36855037        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.45794431 0.30357143 0.29075092        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.42211777 0.23902486\n",
      " 0.25227273        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.20823756 0.13824885 0.15412186        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.06060606 0.04166667 0.04166667        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.72951567 0.67389793\n",
      " 0.61623071        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.58382464 0.45781119 0.44677545        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.49858156 0.2284529  0.3153794         nan        nan 1.\n",
      " 1.         1.                nan        nan 0.37510443 0.17128015\n",
      " 0.17128015        nan        nan 1.         1.         1.\n",
      "        nan        nan 0.32818157 0.18929817 0.18929817        nan\n",
      "        nan 1.         1.         1.                nan        nan\n",
      " 0.14160342 0.07843137 0.07843137        nan        nan 1.\n",
      " 1.         1.                nan        nan 0.02150538 0.\n",
      " 0.                nan        nan 1.         1.         1.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def mcc_scorer(estimator, X, y_true):\n",
    "    \"\"\"\n",
    "    Custom scorer function for Matthews Correlation Coefficient.\n",
    "    \"\"\"\n",
    "    y_pred = estimator.predict(X)\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "def runKNN(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "    \n",
    "    # Define the pipeline with PCA and KNN\n",
    "    pipeline = Pipeline([\n",
    "        ('pca', PCA()),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    dataset_length = Z.shape[0] \n",
    "    print (dataset_length)\n",
    "    \n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        \n",
    "        'pca__n_components': [(math.floor(dataset_length / 5)) * i for i in range(1, 6)],  \n",
    "        'knn__n_neighbors': [3, 5, 7, 9, 11, 15, 20],\n",
    "        'knn__metric': ['cosine', 'euclidean'],\n",
    "        'knn__weights': ['uniform', 'distance'],\n",
    "    }\n",
    "    \n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),  \n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "        'mcc': mcc_scorer, #MCC score custom function\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Perform GridSearchCV with the pipeline\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=skf, \n",
    "        scoring=scoring, \n",
    "        refit='f1', \n",
    "        verbose=1, \n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    # Fit the GridSearchCV on data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "    \n",
    "    \n",
    "    pca_model = grid_search.best_estimator_.named_steps['pca']\n",
    "    transformed_data = pca_model.transform(Z)\n",
    "\n",
    "    # Print the shape of the data after PCA\n",
    "    print(f\"************SHAPE of DATA after PCA: {transformed_data.shape}\")\n",
    "    \n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    \n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "    \n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-knn-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"pca_n_components,n_neighbors,metric,weights,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['pca__n_components']},{param['knn__n_neighbors']},{param['knn__metric']},{param['knn__weights']},{accuracy},{precision},{recall},{f1},{preparationTime}\\n\")\n",
    "    \n",
    "    print(f\"KNN analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run KNN on equal combination\n",
    "print(\"\\nStarting KNN analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_knn_equal, best_score_5folds_knn_equal = runKNN(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_knn_equal, best_score_3folds_knn_equal = runKNN(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for KNN 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_knn_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_knn_equal}\")\n",
    "\n",
    "print(\"\\nBest results for KNN 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_knn_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_knn_equal}\")\n",
    "\n",
    "# Run KNN on larger non-flaky combination\n",
    "print(\"\\nStarting KNN analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_knn_larger, best_score_5folds_knn_larger = runKNN(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_knn_larger, best_score_3folds_knn_larger = runKNN(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for KNN 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_knn_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_knn_larger}\")\n",
    "\n",
    "print(\"\\nBest results for KNN 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_knn_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_knn_larger}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1a814",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a410e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# SVM with GridSearchCV\n",
    "\n",
    "def runSVM(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define the SVM model\n",
    "    svm = SVC()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization parameter\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # Kernel types\n",
    "    }\n",
    "\n",
    "    # Custom scoring functions (without MCC)\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-svm-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"C,kernel,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['C']},{param['kernel']},{accuracy},{precision},{recall},{f1},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"SVM analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4436c1",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba4000e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting SVM analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7834279325765394\n",
      "SVM analysis completed for 5-folds. Results saved to: equal-params-svm-5-folds.csv\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7422003284072249\n",
      "SVM analysis completed for 3-folds. Results saved to: equal-params-svm-3-folds.csv\n",
      "\n",
      "Best results for SVM 5-fold on equal combination:\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7834279325765394\n",
      "\n",
      "Best results for SVM 3-fold on equal combination:\n",
      "Best Parameters: {'C': 100.0, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.7422003284072249\n",
      "\n",
      "Starting SVM analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.5901648351648352\n",
      "SVM analysis completed for 5-folds. Results saved to: larger-params-svm-5-folds.csv\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.6675450153711023\n",
      "SVM analysis completed for 3-folds. Results saved to: larger-params-svm-3-folds.csv\n",
      "\n",
      "Best results for SVM 5-fold on larger combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.5901648351648352\n",
      "\n",
      "Best results for SVM 3-fold on larger combination:\n",
      "Best Parameters: {'C': 0.01, 'kernel': 'linear'}\n",
      "Best F1 Score: 0.6675450153711023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def runSVM(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define the SVM model\n",
    "    svm = SVC()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization parameter\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # Kernel types\n",
    "    }\n",
    "\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-svm-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"C,kernel,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['C']},{param['kernel']},{accuracy},{precision},{recall},{f1},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"SVM analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run SVM on equal combination\n",
    "print(\"\\nStarting SVM analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_svm_equal, best_score_5folds_svm_equal = runSVM(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_svm_equal, best_score_3folds_svm_equal = runSVM(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_svm_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_svm_equal}\")\n",
    "\n",
    "print(\"\\nBest results for SVM 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_svm_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_svm_equal}\")\n",
    "\n",
    "# Run SVM on larger non-flaky combination\n",
    "print(\"\\nStarting SVM analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_svm_larger, best_score_5folds_svm_larger = runSVM(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_svm_larger, best_score_3folds_svm_larger = runSVM(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for SVM 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_svm_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_svm_larger}\")\n",
    "\n",
    "print(\"\\nBest results for SVM 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_svm_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_svm_larger}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2dd8f",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "554dd8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting NB analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'alpha': 0.01}\n",
      "Best F1 Score: 0.7342533936651584\n",
      "Naive Bayes analysis completed for 5-folds. Results saved to: equal-params-nb-5-folds.csv\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Parameters: {'alpha': 0.001}\n",
      "Best F1 Score: 0.7428735632183908\n",
      "Naive Bayes analysis completed for 3-folds. Results saved to: equal-params-nb-3-folds.csv\n",
      "\n",
      "Best results for NB 5-fold on equal combination:\n",
      "Best Parameters: {'alpha': 0.01}\n",
      "Best F1 Score: 0.7342533936651584\n",
      "\n",
      "Best results for NB 3-fold on equal combination:\n",
      "Best Parameters: {'alpha': 0.001}\n",
      "Best F1 Score: 0.7428735632183908\n",
      "\n",
      "Starting NB analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'alpha': 0.001}\n",
      "Best F1 Score: 0.6996031746031746\n",
      "Naive Bayes analysis completed for 5-folds. Results saved to: larger-params-nb-5-folds.csv\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Parameters: {'alpha': 0.1}\n",
      "Best F1 Score: 0.7162068965517241\n",
      "Naive Bayes analysis completed for 3-folds. Results saved to: larger-params-nb-3-folds.csv\n",
      "\n",
      "Best results for NB 5-fold on larger combination:\n",
      "Best Parameters: {'alpha': 0.001}\n",
      "Best F1 Score: 0.6996031746031746\n",
      "\n",
      "Best results for NB 3-fold on larger combination:\n",
      "Best Parameters: {'alpha': 0.1}\n",
      "Best F1 Score: 0.7162068965517241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "def runNB(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define the NB model\n",
    "    nb = MultinomialNB()\n",
    "\n",
    "    # Parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0], \n",
    "    }\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(nb, param_grid, cv=skf, scoring=scoring, refit='f1', verbose=1, return_train_score=True)\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for f1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-nb-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"alpha,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['alpha']},{accuracy},{precision},{recall},{f1},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"Naive Bayes analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run NB on equal combination\n",
    "print(\"\\nStarting NB analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_nb_equal, best_score_5folds_nb_equal = runNB(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_nb_equal, best_score_3folds_nb_equal = runNB(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for NB 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_nb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_nb_equal}\")\n",
    "\n",
    "print(\"\\nBest results for NB 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_nb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_nb_equal}\")\n",
    "\n",
    "# Run NB on larger non-flaky combination\n",
    "print(\"\\nStarting NB analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_nb_larger, best_score_5folds_nb_larger = runNB(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_nb_larger, best_score_3folds_nb_larger = runNB(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for NB 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_nb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_nb_larger}\")\n",
    "\n",
    "print(\"\\nBest results for NB 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_nb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_nb_larger}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8185e97",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1b2a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGBoost analysis for flaky vs smaller non-flaky files (equal combination)...\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best Parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best F1 Score: 0.8720367094206104\n",
      "XGBoost analysis completed for 5-folds. Results saved to: equal-params-xgb-5-folds.csv\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "Best Parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "Best F1 Score: 0.8780172413793105\n",
      "XGBoost analysis completed for 3-folds. Results saved to: equal-params-xgb-3-folds.csv\n",
      "\n",
      "Best results for XGBoost 5-fold on equal combination:\n",
      "Best Parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best F1 Score: 0.8720367094206104\n",
      "\n",
      "Best results for XGBoost 3-fold on equal combination:\n",
      "Best Parameters: {'eta': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
      "Best F1 Score: 0.8780172413793105\n",
      "\n",
      "Starting XGBoost analysis for flaky vs larger non-flaky files (larger combination)...\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best Parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best F1 Score: 0.858235294117647\n",
      "XGBoost analysis completed for 5-folds. Results saved to: larger-params-xgb-5-folds.csv\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "Best Parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 50}\n",
      "Best F1 Score: 0.8724867724867725\n",
      "XGBoost analysis completed for 3-folds. Results saved to: larger-params-xgb-3-folds.csv\n",
      "\n",
      "Best results for XGBoost 5-fold on larger combination:\n",
      "Best Parameters: {'eta': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best F1 Score: 0.858235294117647\n",
      "\n",
      "Best results for XGBoost 3-fold on larger combination:\n",
      "Best Parameters: {'eta': 0.5, 'max_depth': 5, 'n_estimators': 50}\n",
      "Best F1 Score: 0.8724867724867725\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def runXGB(Z, dataLabelsList, outDir, n_splits, combination_label):\n",
    "    v0 = time.perf_counter()\n",
    "\n",
    "    # Define XGBoost model\n",
    "    xgb_model = XGBClassifier(eval_metric=\"logloss\")\n",
    "\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'eta': [0.01, 0.1, 0.3, 0.5],  # Learning rate\n",
    "        'max_depth': [3, 5, 7, 10],    # Tree depth\n",
    "        'n_estimators': [50, 100, 200, 300],  # Number of boosting rounds\n",
    "    }\n",
    "\n",
    "    # Custom scoring functions (without MCC)\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, zero_division=1),  # Handle undefined precision\n",
    "        'recall': make_scorer(recall_score, zero_division=1),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, zero_division=1),  # Handle undefined F1 score\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform GridSearchCV with multiple scoring metrics\n",
    "    grid_search = GridSearchCV(\n",
    "        xgb_model, param_grid, cv=skf, scoring=scoring,\n",
    "        refit='f1', verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the GridSearchCV on training data\n",
    "    grid_search.fit(Z, dataLabelsList)\n",
    "\n",
    "    # Get the best parameters and the best score for F1\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "\n",
    "    # Save the results\n",
    "    outFile = f\"{combination_label}-params-xgb-{n_splits}-folds.csv\"\n",
    "    with open(os.path.join(outDir, outFile), \"w\") as fo:\n",
    "        fo.write(\"eta,max_depth,n_estimators,accuracy,precision,recall,f1,preparationTime\\n\")\n",
    "        for idx, param in enumerate(grid_search.cv_results_['params']):\n",
    "            accuracy = grid_search.cv_results_['mean_test_accuracy'][idx]\n",
    "            precision = grid_search.cv_results_['mean_test_precision'][idx]\n",
    "            recall = grid_search.cv_results_['mean_test_recall'][idx]\n",
    "            f1 = grid_search.cv_results_['mean_test_f1'][idx]\n",
    "            preparationTime = (time.perf_counter() - v0) / len(dataLabelsList)  \n",
    "            fo.write(f\"{param['eta']},{param['max_depth']},{param['n_estimators']},{accuracy},{precision},{recall},{f1},{preparationTime}\\n\")\n",
    "\n",
    "    print(f\"XGBoost analysis completed for {n_splits}-folds. Results saved to: {outFile}\")\n",
    "    return best_params, best_score\n",
    "\n",
    "# Run XGBoost on equal combination\n",
    "print(\"\\nStarting XGBoost analysis for flaky vs smaller non-flaky files (equal combination)...\")\n",
    "best_params_5folds_xgb_equal, best_score_5folds_xgb_equal = runXGB(Z_equal, dataLabelsListEqual, outDirEqual, 5, \"equal\")\n",
    "best_params_3folds_xgb_equal, best_score_3folds_xgb_equal = runXGB(Z_equal, dataLabelsListEqual, outDirEqual, 3, \"equal\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for XGBoost 5-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_xgb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_xgb_equal}\")\n",
    "\n",
    "print(\"\\nBest results for XGBoost 3-fold on equal combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_xgb_equal}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_xgb_equal}\")\n",
    "\n",
    "# Run XGBoost on larger non-flaky combination\n",
    "print(\"\\nStarting XGBoost analysis for flaky vs larger non-flaky files (larger combination)...\")\n",
    "best_params_5folds_xgb_larger, best_score_5folds_xgb_larger = runXGB(Z_larger, dataLabelsListLarger, outDirLarger, 5, \"larger\")\n",
    "best_params_3folds_xgb_larger, best_score_3folds_xgb_larger = runXGB(Z_larger, dataLabelsListLarger, outDirLarger, 3, \"larger\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest results for XGBoost 5-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_5folds_xgb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_5folds_xgb_larger}\")\n",
    "\n",
    "print(\"\\nBest results for XGBoost 3-fold on larger combination:\")\n",
    "print(f\"Best Parameters: {best_params_3folds_xgb_larger}\")\n",
    "print(f\"Best F1 Score: {best_score_3folds_xgb_larger}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f670af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeed817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
